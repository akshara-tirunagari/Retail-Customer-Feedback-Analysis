{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zx9efiiBP7wu"
      },
      "source": [
        "# **GROCERY STORE REVIEW ANALYSIS**\n",
        "### [*Target, Trader Joe's, Safeway, Fry's*]\n",
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRCCTWhIP7wv"
      },
      "source": [
        "\n",
        "## Executive Summary of Project\n",
        "Our project aims to analyze Yelp reviews and ratings of grocery stores to uncover key factors influencing customer satisfaction and business performance. By leveraging machine learning and unstructured data analytics, we will extract actionable insights to help grocery store managers optimize customer experience, marketing strategies, and operational efficiency.\n",
        "\n",
        "## Data Sources & Filtering Criteria\n",
        "\n",
        "We have compiled publicly available Yelp data, including:\n",
        "\n",
        "- To ensure relevant analysis, we filtered and selected reviews specifically from grocery stores such as Target, Fry’s, Safeway, and Trader Joe’s within Arizona State. This approach allows us to gain localized insights into customer preferences, service quality, and areas for improvement.\n",
        "\n",
        "---\n",
        "\n",
        "# 1. Loading & Cleaning Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:22:34.742894Z",
          "iopub.status.busy": "2025-03-04T02:22:34.742731Z",
          "iopub.status.idle": "2025-03-04T02:22:40.440660Z",
          "shell.execute_reply": "2025-03-04T02:22:40.439973Z",
          "shell.execute_reply.started": "2025-03-04T02:22:34.742877Z"
        },
        "id": "yDFVQ6cTiCUf",
        "jupyter": {
          "outputs_hidden": true
        },
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "!pip install textblob\n",
        "!pip install seaborn --quiet\n",
        "!pip install wordcloud --quiet\n",
        "!pip install s3fs --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:22:40.442423Z",
          "iopub.status.busy": "2025-03-04T02:22:40.442119Z",
          "iopub.status.idle": "2025-03-04T02:22:41.527105Z",
          "shell.execute_reply": "2025-03-04T02:22:41.526482Z",
          "shell.execute_reply.started": "2025-03-04T02:22:40.442400Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "iKlma6zjP7ww"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "from collections import Counter\n",
        "from textblob import TextBlob\n",
        "import boto3\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from wordcloud import WordCloud\n",
        "import re\n",
        "import matplotlib.dates as mdates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:22:41.528276Z",
          "iopub.status.busy": "2025-03-04T02:22:41.527825Z",
          "iopub.status.idle": "2025-03-04T02:22:41.531233Z",
          "shell.execute_reply": "2025-03-04T02:22:41.530703Z",
          "shell.execute_reply.started": "2025-03-04T02:22:41.528256Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "_atf7lKnP7ww"
      },
      "outputs": [],
      "source": [
        "bucket_name = \"S3\"\n",
        "file_key = \"Grocery_Store_Arizona .csv\"  # Change to .xlsx if your file is in Excel format\n",
        "\n",
        "# Construct the S3 file path\n",
        "s3_file_path = f\"s3://amazon-sagemaker-058264306111-us-east-1-e23504aef6c5/dzd_5l5kah6gnsnq3r/cameadxdckbu07/dev/\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:22:41.532090Z",
          "iopub.status.busy": "2025-03-04T02:22:41.531863Z",
          "iopub.status.idle": "2025-03-04T02:22:42.462190Z",
          "shell.execute_reply": "2025-03-04T02:22:42.461658Z",
          "shell.execute_reply.started": "2025-03-04T02:22:41.532073Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "pu8UT3F2P7ww"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('Grocery_Store_Arizona .csv')\n",
        "df.head()  # Display the first few rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T03:22:06.061277Z",
          "iopub.status.busy": "2025-03-04T03:22:06.060928Z",
          "iopub.status.idle": "2025-03-04T03:22:06.087234Z",
          "shell.execute_reply": "2025-03-04T03:22:06.086665Z",
          "shell.execute_reply.started": "2025-03-04T03:22:06.061256Z"
        },
        "id": "gfwY3BzzlD7P",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Display basic information about the dataset\n",
        "print(\"Dataset Overview:\\n\", df.info())\n",
        "print(\"\\nFirst 5 rows:\\n\", df.head())\n",
        "# Column Latitude, longitude, and review_date are in the wrong datatype."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:22:42.483715Z",
          "iopub.status.busy": "2025-03-04T02:22:42.483450Z",
          "iopub.status.idle": "2025-03-04T02:22:42.497211Z",
          "shell.execute_reply": "2025-03-04T02:22:42.496661Z",
          "shell.execute_reply.started": "2025-03-04T02:22:42.483694Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "KmSnK1RFP7ww"
      },
      "outputs": [],
      "source": [
        "# Convert latitude and longitude to float (if they are not already)\n",
        "df['latitude'] = pd.to_numeric(df['latitude'], errors='coerce')\n",
        "df['longitude'] = pd.to_numeric(df['longitude'], errors='coerce')\n",
        "\n",
        "# Convert review_date to datetime format\n",
        "df['review_date'] = pd.to_datetime(df['review_date'], errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:22:42.499329Z",
          "iopub.status.busy": "2025-03-04T02:22:42.499067Z",
          "iopub.status.idle": "2025-03-04T02:22:42.508651Z",
          "shell.execute_reply": "2025-03-04T02:22:42.508148Z",
          "shell.execute_reply.started": "2025-03-04T02:22:42.499310Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "ZsJT5PQaP7ww"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()\n",
        "# Attributes and hours columns have missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:22:42.509543Z",
          "iopub.status.busy": "2025-03-04T02:22:42.509281Z",
          "iopub.status.idle": "2025-03-04T02:22:42.649835Z",
          "shell.execute_reply": "2025-03-04T02:22:42.649325Z",
          "shell.execute_reply.started": "2025-03-04T02:22:42.509523Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "vJvTM_c8P7ww"
      },
      "outputs": [],
      "source": [
        "df.duplicated().sum()\n",
        "# There are 6372 duplicated values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFdOkOFJP7ww"
      },
      "source": [
        "---\n",
        "\n",
        "# 2. Summary Statistics of the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:22:42.652102Z",
          "iopub.status.busy": "2025-03-04T02:22:42.651917Z",
          "iopub.status.idle": "2025-03-04T02:22:42.659427Z",
          "shell.execute_reply": "2025-03-04T02:22:42.658905Z",
          "shell.execute_reply.started": "2025-03-04T02:22:42.652083Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "uvMSulr6P7ww"
      },
      "outputs": [],
      "source": [
        "# Identify categorical and continuous columns\n",
        "categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
        "continuous_columns = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "\n",
        "# Exclude non-relevant categorical columns (IDs and text data)\n",
        "excluded_categorical = ['business_id', 'review_id', 'review_text', 'review_user_id', 'checkin_dates', 'attributes', 'categories', 'hours']\n",
        "categorical_columns = [col for col in categorical_columns if col not in excluded_categorical]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:22:42.660328Z",
          "iopub.status.busy": "2025-03-04T02:22:42.660081Z",
          "iopub.status.idle": "2025-03-04T02:22:43.527539Z",
          "shell.execute_reply": "2025-03-04T02:22:43.526985Z",
          "shell.execute_reply.started": "2025-03-04T02:22:42.660309Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "8zi37KfkP7wx"
      },
      "outputs": [],
      "source": [
        "# Plot histograms for categorical columns\n",
        "for col in categorical_columns:\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    sns.countplot(y=df[col], order=df[col].value_counts().index)\n",
        "    plt.title(f\"Distribution of {col}\")\n",
        "    plt.xlabel(\"Count\")\n",
        "    plt.ylabel(col)\n",
        "    plt.show()\n",
        "# All categorical columns are intact."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:22:43.528586Z",
          "iopub.status.busy": "2025-03-04T02:22:43.528287Z",
          "iopub.status.idle": "2025-03-04T02:22:44.840535Z",
          "shell.execute_reply": "2025-03-04T02:22:44.839940Z",
          "shell.execute_reply.started": "2025-03-04T02:22:43.528566Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "qzRsalZ0P7wx"
      },
      "outputs": [],
      "source": [
        "# Plot boxplots for continuous columns to check for outliers\n",
        "for col in continuous_columns:\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    sns.boxplot(x=df[col])\n",
        "    plt.title(f\"Boxplot of {col}\")\n",
        "    plt.xlabel(col)\n",
        "    plt.show()\n",
        "# Data has outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:22:44.841852Z",
          "iopub.status.busy": "2025-03-04T02:22:44.841569Z",
          "iopub.status.idle": "2025-03-04T02:22:44.900607Z",
          "shell.execute_reply": "2025-03-04T02:22:44.900052Z",
          "shell.execute_reply.started": "2025-03-04T02:22:44.841832Z"
        },
        "id": "Q_uyTS1QlGcu",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Basic statistics displayed as a DataFrame\n",
        "summary_stats = df.describe(include='all')\n",
        "display(summary_stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:22:44.901634Z",
          "iopub.status.busy": "2025-03-04T02:22:44.901356Z",
          "iopub.status.idle": "2025-03-04T02:22:45.070283Z",
          "shell.execute_reply": "2025-03-04T02:22:45.069745Z",
          "shell.execute_reply.started": "2025-03-04T02:22:44.901615Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "js5BmM5eP7wx"
      },
      "outputs": [],
      "source": [
        "# Ensure 'review_text' is a string\n",
        "df['review_text'] = df['review_text'].astype(str)\n",
        "\n",
        "# Number of reviews\n",
        "num_reviews = df.shape[0]\n",
        "\n",
        "# Tokenizing the review text\n",
        "df['tokenized_review'] = df['review_text'].apply(lambda x: x.split())\n",
        "\n",
        "# Total number of tokens (words)\n",
        "total_tokens = sum(df['tokenized_review'].apply(len))\n",
        "\n",
        "# Number of unique words (vocabulary size)\n",
        "unique_words = set(word for review in df['tokenized_review'] for word in review)\n",
        "vocabulary_size = len(unique_words)\n",
        "\n",
        "# Average review length (words per review)\n",
        "average_review_length = total_tokens / num_reviews\n",
        "\n",
        "# Number of unique customers\n",
        "num_unique_customers = df['review_user_id'].nunique()\n",
        "\n",
        "# Number of unique businesses\n",
        "num_unique_businesses = df['business_id'].nunique()\n",
        "\n",
        "# Number of unique regions (cities)\n",
        "num_unique_regions = df['city'].nunique()\n",
        "\n",
        "# Average stars per review\n",
        "avg_stars_per_review = df['business_stars'].mean()\n",
        "\n",
        "# Average votes per review (sum of useful, funny, and cool votes)\n",
        "df['total_votes'] = df[['useful', 'funny', 'cool']].sum(axis=1)\n",
        "avg_votes_per_review = df['total_votes'].mean()\n",
        "\n",
        "# Create summary statistics dataframe\n",
        "summary_stats = pd.DataFrame({\n",
        "    \"Metric\": [\n",
        "        \"Number of Reviews\",\n",
        "        \"Total Tokens\",\n",
        "        \"Vocabulary Size\",\n",
        "        \"Average Review Length\",\n",
        "        \"Unique Customers\",\n",
        "        \"Unique Businesses\",\n",
        "        \"Unique Regions\",\n",
        "        \"Average Stars per Review\",\n",
        "        \"Average Votes per Review\"\n",
        "    ],\n",
        "    \"Value\": [\n",
        "        num_reviews,\n",
        "        total_tokens,\n",
        "        vocabulary_size,\n",
        "        average_review_length,\n",
        "        num_unique_customers,\n",
        "        num_unique_businesses,\n",
        "        num_unique_regions,\n",
        "        avg_stars_per_review,\n",
        "        avg_votes_per_review\n",
        "    ]\n",
        "})\n",
        "\n",
        "# Display the summary statistics\n",
        "display(summary_stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:22:45.071241Z",
          "iopub.status.busy": "2025-03-04T02:22:45.070982Z",
          "iopub.status.idle": "2025-03-04T02:22:47.179319Z",
          "shell.execute_reply": "2025-03-04T02:22:47.178757Z",
          "shell.execute_reply.started": "2025-03-04T02:22:45.071222Z"
        },
        "id": "h9THtaqzlxIf",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Word Cloud for most common words in reviews\n",
        "text = ' '.join(df['review_text'].dropna())\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Most Common Words in Reviews\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:22:47.180255Z",
          "iopub.status.busy": "2025-03-04T02:22:47.179993Z",
          "iopub.status.idle": "2025-03-04T02:22:47.332649Z",
          "shell.execute_reply": "2025-03-04T02:22:47.332100Z",
          "shell.execute_reply.started": "2025-03-04T02:22:47.180237Z"
        },
        "id": "kkTbKuzel3Ju",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Distribution of Review Ratings\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.countplot(x=df['review_stars'], palette='viridis')\n",
        "plt.title(\"Distribution of Review Ratings\")\n",
        "plt.xlabel(\"Review Stars\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMQiC5PRP7wx"
      },
      "source": [
        "---\n",
        "\n",
        "# 3. Data Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFaigO59P7wx"
      },
      "source": [
        "## (a) Suitability of the Selected Data for Business Questions  \n",
        "The dataset includes detailed reviews, customer interactions, business information, and location details. This makes it useful for answering business questions about customer satisfaction, performance, and regional preferences. Specifically:  \n",
        "- Customer Behavior Analysis: The review texts, star ratings, and votes (useful, funny, cool) allow in-depth analysis of customer feelings. This helps businesses understand how satisfied customers are and where they can improve.  \n",
        "- Business Performance Evaluation: The dataset features business names, star ratings, and review counts, giving insights into how businesses perform based on customer feedback.  \n",
        "- Geographical Insights: The dataset covers various cities and regions, helping businesses find performance trends and regional preferences.  \n",
        "- User Engagement Trends: The dataset tracks review dates, check-in dates, and review counts, which help analyze trends in customer visits and engagement over time.  \n",
        "Overall, this dataset is very suitable for gaining insights related to customer satisfaction, business performance, and regional trends.  \n",
        "\n",
        "## (b) Sample Size Appropriateness  \n",
        "The dataset includes 8,000 reviews, which is a solid sample size for analysis. We chose 8,000 rows to process the data easily and to gain a clear overview of the analysis. This size allows us to run efficient calculations while still capturing important insights.\n",
        "\n",
        "This sample size is suitable for understanding customer feelings and business performance across different locations. However, if certain businesses or regions have fewer reviews, it could limit how well we can generalize findings for those specific cases.\n",
        "\n",
        "## (c) Potential Biases in the Data  \n",
        "Even though the dataset is useful, it may have biases in several ways:  \n",
        "- Review Bias: People who leave reviews often have strong opinions, either very positive or very negative. This can lead to an overrepresentation of unhappy or very happy customers, while neutral comments may be missing.  \n",
        "- Geographical Bias: The dataset focuses on specific locations (e.g., Arizona), which might not represent customer behavior in other states or regions.  \n",
        "- Business Selection Bias: It may mainly include larger or more popular grocery stores, leaving smaller, less-reviewed stores less visible.  \n",
        "- Time-Based Bias: If the data isn’t evenly spread over time, some businesses might look better or worse due to seasonal changes or outside events.  \n",
        "- Fake/Influenced Reviews: Some businesses may try to boost their ratings by encouraging positive feedback, which can lead to inflated ratings.  \n",
        "\n",
        "## (d) Potential Challenges in Processing the Data  \n",
        "There are several challenges when working with this dataset:  \n",
        "- Text Data Complexity: Review text needs cleaning and organizing (like removing common words and breaking them into parts) to get clear insights. Variations in language and slang can make sentiment analysis harder.  \n",
        "- Data Cleaning Issues: Some areas may have missing data, which needs filling in or removing. Inconsistent formats (like review dates) may need fixing. Duplicate or spam reviews can confuse the analysis.  \n",
        "- Outlier Management: The data shows outliers in star ratings, votes, and review counts, which can skew results. Proper methods (like changing data distributions) may be necessary to address this.  \n",
        "- Regional and Business Distributions: Some businesses or regions might have too few reviews, making it difficult to draw broad conclusions. Normalization techniques (like weighting reviews) may help with fair comparisons.\n",
        "\n",
        "---                                                                                                                        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bUDrREYP7wy"
      },
      "source": [
        "# 4. Preliminary Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:22:47.337869Z",
          "iopub.status.busy": "2025-03-04T02:22:47.337634Z",
          "iopub.status.idle": "2025-03-04T02:22:47.370545Z",
          "shell.execute_reply": "2025-03-04T02:22:47.370012Z",
          "shell.execute_reply.started": "2025-03-04T02:22:47.337849Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "ICXiZkZ-P7wy"
      },
      "outputs": [],
      "source": [
        "# Download NLTK stopwords if not already available\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:22:47.371477Z",
          "iopub.status.busy": "2025-03-04T02:22:47.371228Z",
          "iopub.status.idle": "2025-03-04T02:22:54.765362Z",
          "shell.execute_reply": "2025-03-04T02:22:54.764788Z",
          "shell.execute_reply.started": "2025-03-04T02:22:47.371460Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "g31PW7I5P7wy"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    text = \" \".join([word for word in text.split() if word not in stop_words])  # Remove stopwords\n",
        "    return text\n",
        "\n",
        "# Apply preprocessing\n",
        "df['cleaned_review_text'] = df['review_text'].apply(preprocess_text)\n",
        "\n",
        "# Sentiment Analysis\n",
        "def get_sentiment(text):\n",
        "    return TextBlob(str(text)).sentiment.polarity\n",
        "df['sentiment_score'] = df['review_text'].apply(get_sentiment)\n",
        "\n",
        "df['subjectivity'] = df['cleaned_review_text'].apply(lambda text: TextBlob(text).sentiment.subjectivity)\n",
        "\n",
        "# Classify sentiment based on polarity score\n",
        "df['sentiment'] = df['sentiment_score'].apply(lambda x: 'Positive' if x > 0 else ('Negative' if x < 0 else 'Neutral'))\n",
        "\n",
        "# Count sentiment distribution\n",
        "sentiment_counts = df['sentiment'].value_counts()\n",
        "\n",
        "# Display sentiment analysis results\n",
        "sentiment_summary = df[['review_text', 'sentiment_score', 'subjectivity', 'sentiment']].head(10)\n",
        "display(sentiment_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:22:54.769355Z",
          "iopub.status.busy": "2025-03-04T02:22:54.769026Z",
          "iopub.status.idle": "2025-03-04T02:22:54.905656Z",
          "shell.execute_reply": "2025-03-04T02:22:54.905107Z",
          "shell.execute_reply.started": "2025-03-04T02:22:54.769333Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "y6cfozdoP7wy"
      },
      "outputs": [],
      "source": [
        "# Plot sentiment distribution\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values, palette=\"coolwarm\")\n",
        "plt.title(\"Sentiment Distribution of Reviews\")\n",
        "plt.xlabel(\"Sentiment\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rn16QGqGP7wy"
      },
      "source": [
        "---\n",
        "\n",
        "## 4.1 Sentiment Trends & Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:22:54.908322Z",
          "iopub.status.busy": "2025-03-04T02:22:54.907827Z",
          "iopub.status.idle": "2025-03-04T02:22:55.098630Z",
          "shell.execute_reply": "2025-03-04T02:22:55.098112Z",
          "shell.execute_reply.started": "2025-03-04T02:22:54.908302Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "DQ7kfWrPP7wy"
      },
      "outputs": [],
      "source": [
        "# Sentiment trend over time\n",
        "df['review_date'] = pd.to_datetime(df['review_date'], errors='coerce')  # Ensure correct datetime format\n",
        "sentiment_trend = df.groupby(df['review_date'].dt.to_period(\"M\"))['sentiment_score'].mean()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sentiment_trend.plot(marker=\"o\", linestyle=\"-\", color=\"blue\")\n",
        "plt.title(\"Sentiment Trend Over Time\")\n",
        "plt.xlabel(\"Date (Month)\")\n",
        "plt.ylabel(\"Average Polarity Score\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:22:55.099518Z",
          "iopub.status.busy": "2025-03-04T02:22:55.099272Z",
          "iopub.status.idle": "2025-03-04T02:22:55.331043Z",
          "shell.execute_reply": "2025-03-04T02:22:55.330515Z",
          "shell.execute_reply.started": "2025-03-04T02:22:55.099500Z"
        },
        "id": "rcXpYJ7Dl7ba",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Sentiment distribution\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.histplot(df['sentiment_score'], bins=20, kde=True, color='blue')\n",
        "plt.title(\"Sentiment Score Distribution\")\n",
        "plt.xlabel(\"Sentiment Score\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:22:55.331970Z",
          "iopub.status.busy": "2025-03-04T02:22:55.331707Z",
          "iopub.status.idle": "2025-03-04T02:22:55.344164Z",
          "shell.execute_reply": "2025-03-04T02:22:55.343640Z",
          "shell.execute_reply.started": "2025-03-04T02:22:55.331954Z"
        },
        "id": "V_X0dBvZmcdX",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Data quality evaluation\n",
        "missing_values = df.isnull().sum()\n",
        "print(\"\\nMissing Values per Column:\\n\", missing_values[missing_values > 0])\n",
        "\n",
        "print(\"\\nData Quality Observations:\")\n",
        "print(\"- The dataset contains\", df.shape[0], \"rows and\", df.shape[1], \"columns.\")\n",
        "print(\"- Sentiment analysis shows a general polarity distribution among reviews.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6JwU7Q-P7wy"
      },
      "source": [
        "## Interpretation\n",
        "\n",
        "### 1. Sentiment Trend Over Time  \n",
        "- The sentiment polarity fluctuates over the years, showing **ups and downs in customer satisfaction**.\n",
        "- There are **notable spikes and dips**, indicating periods of **higher positivity and negativity**.\n",
        "- From **2015 onward**, sentiment scores appear to **stabilize** but with occasional **negative outliers**.\n",
        "- This suggests that **external factors** (such as changes in store policies, economic trends, or major events) might have influenced customer sentiment.\n",
        "\n",
        "### 2. Sentiment Score Distribution  \n",
        "- The sentiment scores follow a **normal distribution**, centering around **a slightly positive polarity (~0.2)**.\n",
        "- Most reviews fall between **-0.25 and 0.5**, meaning that customers tend to express **neutral to slightly positive sentiments**.\n",
        "- There are **few extreme negative or positive reviews**, suggesting that **customers generally remain balanced in their feedback**.\n",
        "\n",
        "### 3. Data Quality Evaluation  \n",
        "- **Missing Values**:  \n",
        "  - **10 missing values in `attributes`**  \n",
        "  - **64 missing values in `hours`**  \n",
        "  - The missing data is **minimal** and **should not significantly impact analysis**.\n",
        "- **Dataset Composition**:  \n",
        "  - The dataset contains **8,000 rows** and **29 columns**, which is **sufficient for analysis**.\n",
        "- **Observations**:  \n",
        "  - Sentiment analysis indicates a **general polarity distribution**, meaning customer reviews **vary but lean slightly positive overall**.\n",
        "  - Ensuring proper handling of missing values (e.g., imputation or exclusion) will improve data integrity.\n",
        "\n",
        "### **Key Takeaways:**\n",
        "- **Customer sentiment has fluctuated significantly over time**, likely influenced by external events or business changes.\n",
        "- **Overall sentiment is slightly positive**, with most customers providing **neutral to positive feedback**.\n",
        "- **Data quality is reliable**, with only a small portion of missing values that can be addressed.\n",
        "- **Next Steps**:  \n",
        "  - Investigate the reasons behind **sentiment fluctuations over time**.\n",
        "  - Address **missing values** where necessary.\n",
        "  - Further analyze **extreme sentiment scores** (both highly positive and negative) to identify potential improvement areas.\n",
        "\n",
        "These insights help businesses **track customer sentiment trends**, identify potential areas of concern, and ensure a **high-quality dataset for further analysis**.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## 4.2 Review Analysis\n",
        "\n",
        "# (a) Target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:22:55.346538Z",
          "iopub.status.busy": "2025-03-04T02:22:55.346334Z",
          "iopub.status.idle": "2025-03-04T02:22:56.266991Z",
          "shell.execute_reply": "2025-03-04T02:22:56.266459Z",
          "shell.execute_reply.started": "2025-03-04T02:22:55.346519Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "XMyPyg7dP7wy"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Filter reviews for Target\n",
        "target_reviews = df[df[\"name\"] == \"Target\"]\n",
        "\n",
        "# Skip if no data\n",
        "if target_reviews.empty:\n",
        "    print(\"No reviews found for Target.\")\n",
        "else:\n",
        "    # Create subplots\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "    fig.suptitle(\"Review Analysis for Target\", fontsize=16)\n",
        "\n",
        "    # Histogram of review stars\n",
        "    sns.histplot(target_reviews[\"review_stars\"], bins=5, kde=True, ax=axes[0, 0])\n",
        "    axes[0, 0].set_title(\"Distribution of Review Ratings\")\n",
        "\n",
        "    # Review length distribution\n",
        "    target_reviews[\"review_length\"] = target_reviews[\"cleaned_review_text\"].apply(lambda x: len(str(x).split()))\n",
        "    sns.histplot(target_reviews[\"review_length\"], bins=20, kde=True, ax=axes[0, 1])\n",
        "    axes[0, 1].set_title(\"Distribution of Review Lengths\")\n",
        "\n",
        "    # Review count per user\n",
        "    sns.histplot(target_reviews[\"review_user_id\"].value_counts(), bins=20, kde=True, ax=axes[1, 0])\n",
        "    axes[1, 0].set_title(\"Review Count per User\")\n",
        "\n",
        "    # Useful votes distribution\n",
        "    sns.histplot(target_reviews[\"useful\"], bins=20, kde=True, ax=axes[1, 1])\n",
        "    axes[1, 1].set_title(\"Distribution of Useful Votes\")\n",
        "\n",
        "    # Adjust layout and show plot\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1I23R8MdP7wy"
      },
      "source": [
        "## Interpretation\n",
        "\n",
        "### 1. Distribution of Review Ratings  \n",
        "- The reviews for **Target** are **positively skewed**, with a significant number of **4-star and 5-star ratings**.\n",
        "- There are fewer **1-star and 2-star reviews**, but they are still present, indicating some customer dissatisfaction.\n",
        "\n",
        "### 2. Distribution of Review Lengths  \n",
        "- Most reviews contain **fewer than 50 words**, suggesting that customers prefer to leave **short and concise feedback**.\n",
        "- There are a few **longer reviews** exceeding 100 words, indicating detailed experiences, but they are rare.\n",
        "\n",
        "### 3. Review Count per User  \n",
        "- The majority of users **leave only 1-5 reviews**, suggesting that most reviewers are **casual** rather than frequent contributors.\n",
        "- A few users have **left more than 10 reviews**, likely reflecting **repeat customers** or active Yelp users.\n",
        "\n",
        "### 4. Distribution of Useful Votes  \n",
        "- Most reviews have received **0 to 2 useful votes**, showing that customers primarily engage with a small number of reviews.\n",
        "- A few reviews received **more than 5 useful votes**, indicating that **some detailed or insightful reviews** stand out.\n",
        "\n",
        "### **Key Takeaways:**\n",
        "- **Customer Satisfaction**: Target has **predominantly high ratings**, but a **small portion of negative reviews** still exist.\n",
        "- **Review Behavior**: Most reviews are **short**, and **only a few users contribute multiple reviews**.\n",
        "- **Engagement**: Only a small subset of reviews are considered highly **useful** by other users.\n",
        "\n",
        "These insights help **Target** improve its **customer engagement and response strategies** by addressing concerns raised in lower-rated reviews and encouraging more detailed feedback.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# (b) Trader Joe's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:22:56.269216Z",
          "iopub.status.busy": "2025-03-04T02:22:56.269046Z",
          "iopub.status.idle": "2025-03-04T02:22:57.133516Z",
          "shell.execute_reply": "2025-03-04T02:22:57.132971Z",
          "shell.execute_reply.started": "2025-03-04T02:22:56.269200Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "9KMyGqPWP7wy"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Filter reviews for Trader Joe’s\n",
        "trader_joes_reviews = df[df[\"name\"] == \"Trader Joe's\"]\n",
        "\n",
        "# Skip if no data\n",
        "if trader_joes_reviews.empty:\n",
        "    print(\"No reviews found for Trader Joe’s.\")\n",
        "else:\n",
        "    # Create subplots\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "    fig.suptitle(\"Review Analysis for Trader Joe’s\", fontsize=16)\n",
        "\n",
        "    # Histogram of review stars\n",
        "    sns.histplot(trader_joes_reviews[\"review_stars\"], bins=5, kde=True, ax=axes[0, 0])\n",
        "    axes[0, 0].set_title(\"Distribution of Review Ratings\")\n",
        "\n",
        "    # Review length distribution\n",
        "    trader_joes_reviews[\"review_length\"] = trader_joes_reviews[\"cleaned_review_text\"].apply(lambda x: len(str(x).split()))\n",
        "    sns.histplot(trader_joes_reviews[\"review_length\"], bins=20, kde=True, ax=axes[0, 1])\n",
        "    axes[0, 1].set_title(\"Distribution of Review Lengths\")\n",
        "\n",
        "    # Review count per user\n",
        "    sns.histplot(trader_joes_reviews[\"review_user_id\"].value_counts(), bins=20, kde=True, ax=axes[1, 0])\n",
        "    axes[1, 0].set_title(\"Review Count per User\")\n",
        "\n",
        "    # Useful votes distribution\n",
        "    sns.histplot(trader_joes_reviews[\"useful\"], bins=20, kde=True, ax=axes[1, 1])\n",
        "    axes[1, 1].set_title(\"Distribution of Useful Votes\")\n",
        "\n",
        "    # Adjust layout and show plot\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIAw5wepP7wy"
      },
      "source": [
        "## Interpretation\n",
        "\n",
        "### 1. Distribution of Review Ratings  \n",
        "- **Trader Joe’s** has **overwhelmingly positive reviews**, with a high concentration of **4-star and 5-star ratings**.\n",
        "- **Very few 1-star and 2-star reviews**, indicating **strong customer satisfaction**.\n",
        "- The **peak at 5 stars** suggests that customers generally have a very positive shopping experience.\n",
        "\n",
        "### 2. Distribution of Review Lengths  \n",
        "- Most reviews are **between 20-80 words**, indicating that customers **express their thoughts in moderate detail**.\n",
        "- A few longer reviews (above **100 words**) suggest that some customers provide detailed feedback, but they are rare.\n",
        "\n",
        "### 3. Review Count per User  \n",
        "- The majority of users **leave only 1-5 reviews**, indicating **occasional engagement**.\n",
        "- A few highly engaged users have written **more than 10 reviews**, which might indicate **loyal or regular customers**.\n",
        "\n",
        "### 4. Distribution of Useful Votes  \n",
        "- Most reviews received **0-2 useful votes**, suggesting that while many people read reviews, they rarely mark them as useful.\n",
        "- Some detailed reviews received **higher useful votes (>5)**, indicating that certain reviews were considered **helpful and informative**.\n",
        "\n",
        "### **Key Takeaways:**\n",
        "- **Strong Customer Satisfaction**: Trader Joe’s **dominates in positive ratings**, with very few negative reviews.\n",
        "- **Moderate Review Detail**: Reviews are **concise but informative**, with only a few long-form reviews.\n",
        "- **Engagement & Loyalty**: A **small subset of users contribute frequently**, reflecting potential **brand loyalty**.\n",
        "- **Opportunities for Improvement**: Encouraging **more detailed reviews and useful votes** can help future customers make informed decisions.\n",
        "\n",
        "These insights can help **Trader Joe’s** further enhance customer experience by **addressing minor concerns and leveraging highly-rated products/services**.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# (c) Safeway"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:22:57.135724Z",
          "iopub.status.busy": "2025-03-04T02:22:57.135538Z",
          "iopub.status.idle": "2025-03-04T02:22:58.006718Z",
          "shell.execute_reply": "2025-03-04T02:22:58.006214Z",
          "shell.execute_reply.started": "2025-03-04T02:22:57.135707Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "4lzmeR8pP7wy"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Filter reviews for Safeway\n",
        "safeway_reviews = df[df[\"name\"] == \"Safeway\"]\n",
        "\n",
        "# Skip if no data\n",
        "if safeway_reviews.empty:\n",
        "    print(\"No reviews found for Safeway.\")\n",
        "else:\n",
        "    # Create subplots\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "    fig.suptitle(\"Review Analysis for Safeway\", fontsize=16)\n",
        "\n",
        "    # Histogram of review stars\n",
        "    sns.histplot(safeway_reviews[\"review_stars\"], bins=5, kde=True, ax=axes[0, 0])\n",
        "    axes[0, 0].set_title(\"Distribution of Review Ratings\")\n",
        "\n",
        "    # Review length distribution\n",
        "    safeway_reviews[\"review_length\"] = safeway_reviews[\"cleaned_review_text\"].apply(lambda x: len(str(x).split()))\n",
        "    sns.histplot(safeway_reviews[\"review_length\"], bins=20, kde=True, ax=axes[0, 1])\n",
        "    axes[0, 1].set_title(\"Distribution of Review Lengths\")\n",
        "\n",
        "    # Review count per user\n",
        "    sns.histplot(safeway_reviews[\"review_user_id\"].value_counts(), bins=20, kde=True, ax=axes[1, 0])\n",
        "    axes[1, 0].set_title(\"Review Count per User\")\n",
        "\n",
        "    # Useful votes distribution\n",
        "    sns.histplot(safeway_reviews[\"useful\"], bins=20, kde=True, ax=axes[1, 1])\n",
        "    axes[1, 1].set_title(\"Distribution of Useful Votes\")\n",
        "\n",
        "    # Adjust layout and show plot\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPy3nPMpP7wz"
      },
      "source": [
        "## Interpretation\n",
        "\n",
        "### 1. Distribution of Review Ratings  \n",
        "- **Safeway has a mixed distribution of ratings**, with significant peaks at **1-star, 3-star, and 4-star ratings**.\n",
        "- The **large number of 1-star reviews** suggests **many dissatisfied customers**.\n",
        "- A high count of **4-star and 5-star reviews** shows that many customers are still satisfied.\n",
        "- The **variation in ratings** suggests **inconsistency in customer experience**.\n",
        "\n",
        "### 2. Distribution of Review Lengths  \n",
        "- Most reviews are **short**, typically under **50 words**, indicating that customers tend to leave **brief feedback**.\n",
        "- Some longer reviews (above **100 words**) exist but are **relatively rare**.\n",
        "\n",
        "### 3. Review Count per User  \n",
        "- The majority of users **leave only one review**, which suggests **occasional engagement**.\n",
        "- A small subset of users has contributed **more than 25 reviews**, possibly reflecting **loyal customers or frequent reviewers**.\n",
        "\n",
        "### 4. Distribution of Useful Votes  \n",
        "- Most reviews received **0-2 useful votes**, meaning customer engagement with reviews is **low**.\n",
        "- A few reviews received **higher useful votes (>5)**, indicating that **some reviews were particularly insightful or informative**.\n",
        "\n",
        "### **Key Takeaways:**\n",
        "- **Inconsistent Customer Experience**: The **high volume of 1-star and 4-star reviews** indicates a **divided opinion** among customers.\n",
        "- **Short Reviews**: Customers **do not elaborate much**, making it harder to gain detailed insights from textual feedback.\n",
        "- **Low Review Engagement**: Reviews receive **few useful votes**, meaning customers **may not rely heavily on reviews for decision-making**.\n",
        "- **Areas for Improvement**: Addressing **frequent complaints from 1-star reviews** and encouraging **more detailed customer feedback** could help improve overall customer satisfaction.\n",
        "\n",
        "These insights can help **Safeway** identify inconsistencies in service quality and work on improving the overall customer experience.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# (d) Fry's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:22:58.008857Z",
          "iopub.status.busy": "2025-03-04T02:22:58.008687Z",
          "iopub.status.idle": "2025-03-04T02:22:59.090230Z",
          "shell.execute_reply": "2025-03-04T02:22:59.089703Z",
          "shell.execute_reply.started": "2025-03-04T02:22:58.008841Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "1as5HpewP7wz"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Filter reviews for Fry’s\n",
        "frys_reviews = df[df[\"name\"] == \"Fry's\"]\n",
        "\n",
        "# Skip if no data\n",
        "if frys_reviews.empty:\n",
        "    print(\"No reviews found for Fry’s.\")\n",
        "else:\n",
        "    # Create subplots\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "    fig.suptitle(\"Review Analysis for Fry’s\", fontsize=16)\n",
        "\n",
        "    # Histogram of review stars\n",
        "    sns.histplot(frys_reviews[\"review_stars\"], bins=5, kde=True, ax=axes[0, 0])\n",
        "    axes[0, 0].set_title(\"Distribution of Review Ratings\")\n",
        "\n",
        "    # Review length distribution\n",
        "    frys_reviews[\"review_length\"] = frys_reviews[\"cleaned_review_text\"].apply(lambda x: len(str(x).split()))\n",
        "    sns.histplot(frys_reviews[\"review_length\"], bins=20, kde=True, ax=axes[0, 1])\n",
        "    axes[0, 1].set_title(\"Distribution of Review Lengths\")\n",
        "\n",
        "    # Review count per user\n",
        "    sns.histplot(frys_reviews[\"review_user_id\"].value_counts(), bins=20, kde=True, ax=axes[1, 0])\n",
        "    axes[1, 0].set_title(\"Review Count per User\")\n",
        "\n",
        "    # Useful votes distribution\n",
        "    sns.histplot(frys_reviews[\"useful\"], bins=20, kde=True, ax=axes[1, 1])\n",
        "    axes[1, 1].set_title(\"Distribution of Useful Votes\")\n",
        "\n",
        "    # Adjust layout and show plot\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7_DtEumP7wz"
      },
      "source": [
        "## Interpretation\n",
        "\n",
        "### 1. Distribution of Review Ratings  \n",
        "- **Fry’s has a polarized rating distribution**, with **high counts for both 1-star and 5-star reviews**.\n",
        "- The presence of **many 1-star reviews** suggests **customer dissatisfaction with certain aspects of the store**.\n",
        "- The **moderate number of 3-star and 4-star reviews** indicates that some customers had an **average experience**.\n",
        "- **Inconsistent service or product quality** may be leading to these **varied customer experiences**.\n",
        "\n",
        "### 2. Distribution of Review Lengths  \n",
        "- Most reviews are **short**, typically under **50 words**, meaning customers provide **brief feedback**.\n",
        "- A small percentage of reviews exceed **100 words**, which may offer **more detailed insights into customer experiences**.\n",
        "\n",
        "### 3. Review Count per User  \n",
        "- The majority of users have written **only one review**, suggesting **occasional engagement** rather than **repeat reviewing**.\n",
        "- A few users have contributed **multiple reviews**, indicating **repeat customers** or **active Yelp users**.\n",
        "\n",
        "### 4. Distribution of Useful Votes  \n",
        "- Most reviews received **0-2 useful votes**, meaning customer engagement with reviews is **low**.\n",
        "- Some reviews received **higher useful votes (>5)**, indicating that **certain reviews provided meaningful or insightful content**.\n",
        "\n",
        "### **Key Takeaways:**\n",
        "- **Customer Experience is Divided**: A **high number of 1-star reviews** suggests frequent **negative experiences**, while **many 5-star reviews** show strong customer loyalty.\n",
        "- **Brief Reviews**: Customers tend to **leave short feedback**, which may limit deeper insights into their experiences.\n",
        "- **Low Review Engagement**: Most reviews receive **few useful votes**, suggesting that reviews are not heavily relied upon for decision-making.\n",
        "- **Opportunities for Improvement**: Fry’s should **analyze common issues in 1-star reviews** to identify **recurring problems** and enhance customer satisfaction.\n",
        "\n",
        "By addressing **negative customer experiences**, Fry’s can work on **improving service quality** and creating a **more consistent shopping experience**.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# 5. Proposed Solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:22:59.092476Z",
          "iopub.status.busy": "2025-03-04T02:22:59.092306Z",
          "iopub.status.idle": "2025-03-04T02:22:59.096749Z",
          "shell.execute_reply": "2025-03-04T02:22:59.096296Z",
          "shell.execute_reply.started": "2025-03-04T02:22:59.092459Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "ZmwT32CmP7wz"
      },
      "outputs": [],
      "source": [
        "df.name.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:22:59.097665Z",
          "iopub.status.busy": "2025-03-04T02:22:59.097420Z",
          "iopub.status.idle": "2025-03-04T02:22:59.124646Z",
          "shell.execute_reply": "2025-03-04T02:22:59.124102Z",
          "shell.execute_reply.started": "2025-03-04T02:22:59.097648Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "d9Zp5Nu5P7wz"
      },
      "outputs": [],
      "source": [
        "trader_joes_reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aswU8VclP7wz"
      },
      "source": [
        "## Interpretation\n",
        "\n",
        "To analyze the dataset and gain useful business insights, I suggest using a mix of machine learning models and techniques for analyzing unstructured data. This will help us understand customer sentiment, predict trends, and make better business decisions. Here’s how we can approach this:\n",
        "\n",
        "### 1. Machine Learning Models for Sentiment Classification\n",
        "   We will use supervised machine learning methods to categorize reviews as Positive, Neutral, or Negative based on text features.\n",
        "   \n",
        "#### Traditional ML Models:  \n",
        "- Logistic Regression: A simple and effective starting model for sentiment classification, suitable for features extracted using TF-IDF or Bag-of-Words.\n",
        "- Support Vector Machine (SVM): Good for text classification in high-dimensional spaces, and works well with TF-IDF data.\n",
        "- Random Forest: Helps analyze which features are important for determining sentiment and is robust against noisy data.\n",
        "- Multilayer Perceptron (MLP - Neural Network): Can learn complex patterns in text data and performs well when trained on word embeddings like Word2Vec or GloVe.\n",
        "\n",
        "### 2. Deep Learning Approaches\n",
        "- Recurrent Neural Networks (RNN) / LSTM:\n",
        "     LSTM (Long Short-Term Memory) is effective for sentiment analysis because it maintains the context of words in a sequence. It works well wit pre-trained embeddings like GloVe or FastText.\n",
        "- Transformer-Based Models (BERT, DistilBERT):\n",
        "     BERT (Bidirectional Encoder Representations from Transformers) is currently very effective for text classification and sentiment analysis. Fine-tuning BERT on customer reviews can lead to high accuracy in detecting sentiment.\n",
        "\n",
        "### 3. Unstructured Data Analytics Techniques  \n",
        "- Text Preprocessing:\n",
        "     This includes breaking down text into individual words, reducing words to their base form, and removing common words, punctuation, numbers, and special characters.\n",
        "- Feature Extraction:\n",
        "     We’ll use TF-IDF (Term Frequency-Inverse Document Frequency) to determine keyword importance, Bag-of-Words as a basic representation, and Word2Vec or GloVe embeddings for deep learning models.\n",
        "- Topic Modeling (Latent Dirichlet Allocation - LDA):  \n",
        "     This helps us identify the main topics in customer reviews, giving businesses insight into what customers frequently talk about.\n",
        "- Named Entity Recognition (NER):  \n",
        "     This identifies entities such as business names, locations, product mentions, and staff names in reviews. It assists in analyzing customer feedback on specific topics.\n",
        "- Sentiment Trend Analysis:\n",
        "     We will track sentiment changes over time to spot trends, helping businesses monitor improvements or declines in service.\n",
        "\n",
        "### 4. Predictive Analytics for Customer Satisfaction\n",
        "We will use regression models (like Linear Regression and XGBoost) to predict business star ratings based on review sentiment. We will also build churn prediction models to estimate whether a customer is likely to keep visiting or stop coming to a business.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-24T01:28:57.423160Z",
          "iopub.status.busy": "2025-02-24T01:28:57.422819Z",
          "iopub.status.idle": "2025-02-24T01:28:57.426189Z",
          "shell.execute_reply": "2025-02-24T01:28:57.425613Z",
          "shell.execute_reply.started": "2025-02-24T01:28:57.423136Z"
        },
        "id": "9QSJaexvP7wz"
      },
      "source": [
        "### 5.1 Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:22:59.128582Z",
          "iopub.status.busy": "2025-03-04T02:22:59.128398Z",
          "iopub.status.idle": "2025-03-04T02:23:21.106887Z",
          "shell.execute_reply": "2025-03-04T02:23:21.106300Z",
          "shell.execute_reply.started": "2025-03-04T02:22:59.128563Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "scrolled": true,
        "id": "6BdjyEwsP7wz"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install spacy==3.5.4\n",
        "\n",
        "!python -m spacy download en_core_web_lg\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T04:09:23.089955Z",
          "iopub.status.busy": "2025-03-04T04:09:23.089632Z",
          "iopub.status.idle": "2025-03-04T04:09:28.075293Z",
          "shell.execute_reply": "2025-03-04T04:09:28.074460Z",
          "shell.execute_reply.started": "2025-03-04T04:09:23.089935Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "sHzVwPmDP7w0"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "# Load the SpaCy language model with only essential components\n",
        "nlp = spacy.load('en_core_web_lg', disable=['ner', 'textcat'])\n",
        "\n",
        "# Convert reviews to a list of strings\n",
        "reviews = df['review_text'].astype(str).tolist()\n",
        "\n",
        "# Process reviews using nlp.pipe() for efficient batch processing\n",
        "docs = list(nlp.pipe(reviews[:500], batch_size=30, n_process=4))  # Limit to 500 reviews for speed\n",
        "\n",
        "# Extract linguistic features for the first 10 reviews\n",
        "for i, doc in enumerate(docs[:10]):\n",
        "    print(f\"Review {i+1}:\")\n",
        "    for token in doc[:8]:  # Analyze only the first 8 tokens per review\n",
        "        print(token.text, token.lemma_, token.pos_, token.dep_)\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# Visualize dependency parsing for the first 5 reviews\n",
        "for doc in docs[:5]:\n",
        "    displacy.render(doc, style='dep', jupyter=True, options={'distance': 70})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:23:48.974390Z",
          "iopub.status.busy": "2025-03-04T02:23:48.974018Z",
          "iopub.status.idle": "2025-03-04T02:23:49.163079Z",
          "shell.execute_reply": "2025-03-04T02:23:49.162534Z",
          "shell.execute_reply.started": "2025-03-04T02:23:48.974364Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "IpAL-hvqP7w0"
      },
      "outputs": [],
      "source": [
        "# Process the first few reviews for efficiency\n",
        "sample_reviews = df[\"review_text\"].head(10)\n",
        "\n",
        "# Initialize lists to store processed outputs\n",
        "sentence_list_spacy = []\n",
        "token_list_spacy = []\n",
        "\n",
        "# Process each review using SpaCy\n",
        "for review in sample_reviews:\n",
        "    nlp_doc = nlp(review)  # Process each review\n",
        "    sentences = [sentence.text for sentence in nlp_doc.sents]  # Extract sentences\n",
        "    tokens = [token.text for token in nlp_doc]  # Extract tokens\n",
        "\n",
        "    sentence_list_spacy.append(sentences)\n",
        "    token_list_spacy.append(tokens)\n",
        "\n",
        "# Display sample outputs\n",
        "processed_reviews_df = pd.DataFrame({\"Original Review\": sample_reviews,\n",
        "                                     \"Sentences (SpaCy)\": sentence_list_spacy,\n",
        "                                     \"Tokens (SpaCy)\": token_list_spacy})\n",
        "\n",
        "\n",
        "# Display the first few processed reviews\n",
        "print(processed_reviews_df.head())\n",
        "\n",
        "# Save results to a CSV file (optional)\n",
        "processed_reviews_df.to_csv(\"SpaCy_Processed_Reviews.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMGTsK5CP7w0"
      },
      "source": [
        "### 5.2 Part-Of-Speech Tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:23:49.165881Z",
          "iopub.status.busy": "2025-03-04T02:23:49.165665Z",
          "iopub.status.idle": "2025-03-04T02:25:48.815672Z",
          "shell.execute_reply": "2025-03-04T02:25:48.815107Z",
          "shell.execute_reply.started": "2025-03-04T02:23:49.165862Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "ntVcWc2sP7w0"
      },
      "outputs": [],
      "source": [
        "# Process the entire dataset for POS tagging using SpaCy\n",
        "pos_tag_results = []\n",
        "\n",
        "# Process each review using SpaCy\n",
        "for review in df[\"review_text\"]:  # Limiting to 10 for efficient display\n",
        "    nlp_doc = nlp(str(review))  # Convert to string and process each review\n",
        "    pos_tag_dict = {str(token): token.pos_ for token in nlp_doc}  # Extract POS tags\n",
        "    pos_tag_results.append(pos_tag_dict)\n",
        "\n",
        "# Create DataFrame for display\n",
        "pos_tag_df = pd.DataFrame({\"Original Review\": df[\"review_text\"], \"POS Tags (SpaCy)\": pos_tag_results})\n",
        "\n",
        "# Display the processed results\n",
        "from IPython.display import display\n",
        "display(pos_tag_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-24T02:01:56.283641Z",
          "iopub.status.busy": "2025-02-24T02:01:56.283326Z",
          "iopub.status.idle": "2025-02-24T02:01:56.286286Z",
          "shell.execute_reply": "2025-02-24T02:01:56.285801Z",
          "shell.execute_reply.started": "2025-02-24T02:01:56.283621Z"
        },
        "id": "kOxRC4H3P7w0"
      },
      "source": [
        "### 5.3 Named Entity Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:25:48.818105Z",
          "iopub.status.busy": "2025-03-04T02:25:48.817919Z",
          "iopub.status.idle": "2025-03-04T02:25:48.823907Z",
          "shell.execute_reply": "2025-03-04T02:25:48.823420Z",
          "shell.execute_reply.started": "2025-03-04T02:25:48.818087Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "tGnrvnLDP7w0"
      },
      "outputs": [],
      "source": [
        "# SpaCy\n",
        "\n",
        "from spacy import displacy\n",
        "for ent in nlp_doc.ents:\n",
        "\tprint(ent.text, ent.label_)\n",
        "displacy.render(nlp_doc, style='ent',jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-04T05:39:37.833377Z",
          "iopub.status.busy": "2025-03-04T05:39:37.833052Z",
          "iopub.status.idle": "2025-03-04T05:39:40.631333Z",
          "shell.execute_reply": "2025-03-04T05:39:40.630540Z",
          "shell.execute_reply.started": "2025-03-04T05:39:37.833358Z"
        },
        "id": "f6rhfZdSP7w0"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "# Load the SpaCy language model\n",
        "nlp = spacy.load('en_core_web_lg', disable=['ner', 'textcat'])  # Disable components not needed for speed\n",
        "\n",
        "# Process all reviews efficiently using nlp.pipe()\n",
        "reviews = df['review_text'].astype(str).tolist()  # Convert to list of strings\n",
        "docs = list(nlp.pipe(reviews[:5], batch_size=25, n_process=2))  # Process only 5 reviews\n",
        "\n",
        "# Extract linguistic features efficiently\n",
        "for i, doc in enumerate(docs):\n",
        "    print(f\"Review {i+1}:\")  # Show which review is being processed\n",
        "    for token in doc[:8]:  # Limit printing to the first 8 tokens for efficiency\n",
        "        print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
        "              token.shape_, token.is_alpha, token.is_stop)\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# Limit visualization to the first 4-5 reviews\n",
        "for doc in docs[:5]:\n",
        "    displacy.render(doc, style='dep', jupyter=True, options={'distance': 75})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "ZsnTNb_tP7w0"
      },
      "source": [
        "### 5.4 SpaCy X DataFrame = DframCy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:26:16.850022Z",
          "iopub.status.busy": "2025-03-04T02:26:16.849796Z",
          "iopub.status.idle": "2025-03-04T02:26:18.465327Z",
          "shell.execute_reply": "2025-03-04T02:26:18.464585Z",
          "shell.execute_reply.started": "2025-03-04T02:26:16.849996Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "oC-wYYraP7w0"
      },
      "outputs": [],
      "source": [
        "!pip install dframcy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-04T02:26:18.466686Z",
          "iopub.status.busy": "2025-03-04T02:26:18.466377Z",
          "iopub.status.idle": "2025-03-04T02:29:48.943075Z",
          "shell.execute_reply": "2025-03-04T02:29:48.942540Z",
          "shell.execute_reply.started": "2025-03-04T02:26:18.466664Z"
        },
        "id": "s4SSzG8sP7w0"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from dframcy import DframCy\n",
        "\n",
        "# Load the SpaCy model and initialize DframCy\n",
        "nlp = spacy.load('en_core_web_lg')\n",
        "dframcy = DframCy(nlp)\n",
        "\n",
        "# Assuming `df_1` contains the restaurant reviews with a 'text' column\n",
        "# Process each review and create a DataFrame of annotations\n",
        "annotation_dataframes = []\n",
        "\n",
        "for review in df[\"review_text\"]:\n",
        "    if isinstance(review, str):  # Ensure the review is a string\n",
        "        doc = dframcy.nlp(review)  # Process the review using DframCy\n",
        "        annotation_dataframe = dframcy.to_dataframe(doc)  # Convert to DataFrame\n",
        "        annotation_dataframes.append(annotation_dataframe)\n",
        "\n",
        "# Combine all individual annotation DataFrames into a single DataFrame for analysis\n",
        "combined_annotations = pd.concat(annotation_dataframes, ignore_index=True)\n",
        "\n",
        "# Display the combined DataFrame\n",
        "display(combined_annotations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.status.busy": "2025-02-24T06:08:08.373568Z",
          "iopub.status.idle": "2025-02-24T06:08:08.373772Z",
          "shell.execute_reply": "2025-02-24T06:08:08.373679Z",
          "shell.execute_reply.started": "2025-02-24T06:08:08.373670Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "0ai9BIpLP7w0"
      },
      "source": [
        "---\n",
        "\n",
        "## 5.5 Top 20 Nouns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:29:48.945624Z",
          "iopub.status.busy": "2025-03-04T02:29:48.945439Z",
          "iopub.status.idle": "2025-03-04T02:32:54.817471Z",
          "shell.execute_reply": "2025-03-04T02:32:54.816898Z",
          "shell.execute_reply.started": "2025-03-04T02:29:48.945607Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "C5gGzwcOP7w0"
      },
      "outputs": [],
      "source": [
        "# Function to extract nouns and count them\n",
        "def get_top_nouns(reviews):\n",
        "    nouns = []\n",
        "    for review in df[\"review_text\"]:\n",
        "        try:\n",
        "            doc = nlp(str(review))\n",
        "            for token in doc:\n",
        "                if token.pos_ == \"NOUN\":\n",
        "                    nouns.append(token.lemma_)  # Use the lemmatized form of the noun\n",
        "        except TypeError:\n",
        "            pass\n",
        "    return Counter(nouns).most_common(20)\n",
        "\n",
        "# Get the top 20 nouns from the entire dataset\n",
        "top_nouns = get_top_nouns(df)\n",
        "\n",
        "# Convert to DataFrame for better visualization\n",
        "top_nouns_df = pd.DataFrame(top_nouns, columns=[\"Noun\", \"Frequency\"])\n",
        "\n",
        "# Display results\n",
        "print(\"Top 20 Frequently Used Nouns:\")\n",
        "display(top_nouns_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRsglE42P7w0"
      },
      "source": [
        "---\n",
        "\n",
        "## 5.6 Top 20 Adjectives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:32:54.819821Z",
          "iopub.status.busy": "2025-03-04T02:32:54.819616Z",
          "iopub.status.idle": "2025-03-04T02:36:00.026780Z",
          "shell.execute_reply": "2025-03-04T02:36:00.026261Z",
          "shell.execute_reply.started": "2025-03-04T02:32:54.819802Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "vyORwY_YP7w0"
      },
      "outputs": [],
      "source": [
        "# Function to extract adjectives and count them\n",
        "def get_top_adjectives(reviews):\n",
        "    adjectives = []\n",
        "    for review in reviews[\"review_text\"]:\n",
        "        try:\n",
        "            doc = nlp(str(review))\n",
        "            for token in doc:\n",
        "                if token.pos_ == \"ADJ\":\n",
        "                    adjectives.append(token.lemma_)  # Use the lemmatized form of the adjective\n",
        "        except TypeError:\n",
        "            pass\n",
        "    return Counter(adjectives).most_common(20)\n",
        "\n",
        "# Get the top 20 adjectives from the entire dataset\n",
        "top_adjectives = get_top_adjectives(df)\n",
        "\n",
        "# Convert to DataFrame for better visualization\n",
        "top_adjectives_df = pd.DataFrame(top_adjectives, columns=[\"Adjective\", \"Frequency\"])\n",
        "\n",
        "# Display results\n",
        "print(\"Top 20 Frequently Used Adjectives:\")\n",
        "display(top_adjectives_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-24T07:10:02.068035Z",
          "iopub.status.busy": "2025-02-24T07:10:02.067700Z",
          "iopub.status.idle": "2025-02-24T07:10:02.070873Z",
          "shell.execute_reply": "2025-02-24T07:10:02.070297Z",
          "shell.execute_reply.started": "2025-02-24T07:10:02.068013Z"
        },
        "id": "h9GVwZc8P7w1"
      },
      "source": [
        "---\n",
        "\n",
        "## 5.7 Top 20 Verbs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:36:00.029202Z",
          "iopub.status.busy": "2025-03-04T02:36:00.029014Z",
          "iopub.status.idle": "2025-03-04T02:39:04.064478Z",
          "shell.execute_reply": "2025-03-04T02:39:04.063959Z",
          "shell.execute_reply.started": "2025-03-04T02:36:00.029183Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "fYRVFZDYP7w1"
      },
      "outputs": [],
      "source": [
        "def get_top_verbs(reviews):\n",
        "    verbs = []\n",
        "    for review in reviews[\"review_text\"]:\n",
        "        try:\n",
        "            doc = nlp(str(review))\n",
        "            for token in doc:\n",
        "                if token.pos_ == \"VERB\":\n",
        "                    verbs.append(token.lemma_)  # Use the lemmatized form of the verb\n",
        "        except TypeError:\n",
        "            pass\n",
        "    return Counter(verbs).most_common(20)\n",
        "\n",
        "# Get the top 20 verbs from the entire dataset\n",
        "top_verbs = get_top_verbs(df)\n",
        "\n",
        "# Convert to DataFrame for better visualization\n",
        "top_verbs_df = pd.DataFrame(top_verbs, columns=[\"Verb\", \"Frequency\"])\n",
        "\n",
        "# Display results\n",
        "print(\"Top 20 Frequently Used Verbs:\")\n",
        "display(top_verbs_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efwYsmirP7w1"
      },
      "source": [
        "---\n",
        "\n",
        "### Top 20 Named Entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:39:04.066781Z",
          "iopub.status.busy": "2025-03-04T02:39:04.066595Z",
          "iopub.status.idle": "2025-03-04T02:42:08.109799Z",
          "shell.execute_reply": "2025-03-04T02:42:08.109297Z",
          "shell.execute_reply.started": "2025-03-04T02:39:04.066762Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "JSlY84vPP7w1"
      },
      "outputs": [],
      "source": [
        "def get_top_named_entities(reviews):\n",
        "    named_entities = []\n",
        "    for review in reviews[\"review_text\"]:\n",
        "        try:\n",
        "            doc = nlp(str(review))\n",
        "            for ent in doc.ents:\n",
        "                named_entities.append(ent.text)  # Extract named entities\n",
        "        except TypeError:\n",
        "            pass\n",
        "    return Counter(named_entities).most_common(20)\n",
        "\n",
        "# Get the top 20 named entities from the entire dataset\n",
        "top_named_entities = get_top_named_entities(df)\n",
        "\n",
        "# Convert to DataFrame for better visualization\n",
        "top_named_entities_df = pd.DataFrame(top_named_entities, columns=[\"Named Entity\", \"Frequency\"])\n",
        "\n",
        "# Display results\n",
        "print(\"Top 20 Frequently Used Named Entities:\")\n",
        "display(top_named_entities_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-24T07:14:36.347723Z",
          "iopub.status.busy": "2025-02-24T07:14:36.347407Z",
          "iopub.status.idle": "2025-02-24T07:14:36.358769Z",
          "shell.execute_reply": "2025-02-24T07:14:36.358164Z",
          "shell.execute_reply.started": "2025-02-24T07:14:36.347700Z"
        },
        "id": "I8pjVXJUP7w1"
      },
      "source": [
        "---\n",
        "\n",
        "# Analysis & Interpretation\n",
        "\n",
        "1. Named Entities Analysis\n",
        "The named entities show the grocery stores and locations people mention most:\n",
        "- Target (2041) and Safeway (2018) are the top mentioned stores, indicating they attract lots of customers.\n",
        "- Trader Joe’s (656), TJ (628), and Joe (627) also show strong brand recognition for Trader Joe's.\n",
        "- Walmart (278) and Bashas (274) are mentioned less but are still important competitors.\n",
        "- Words like \"one,\" \"two,\" \"first,\" and \"five\" may point to rankings or preferences.\n",
        "\n",
        "Insights:\n",
        "High mentions of certain grocery stores suggest they are popular topics for customers, whether for positive or negative reasons. The difference between Fry’s (1098) and Frys (291) shows that people may refer to the same store differently. Tucson (705) suggests this data may focus on local areas.\n",
        "\n",
        "2. Verb Usage Analysis\n",
        "The most common verbs highlight customer actions and feelings:\n",
        "- Common actions: have (8560), go (4589), get (3674), find (2385), shop (2312) show that the reviews often focus on customer experiences while visiting and shopping.\n",
        "- Emotional verbs: love (2082), need (1947), ask (1168), buy (1148), try (1144) indicate strong feelings about products or services.\n",
        "- Decision-making verbs: know (1288), take (1384), use (1278), see (1227), look (1217) suggest that customers often examine products or store features before making a purchase.\n",
        "\n",
        "Insights:\n",
        "The high count of \"love\" (2082) shows that many customers feel positively about products, services, or stores. The words \"try\" (1144) and \"ask\" (1168) suggest customers are curious or interact with staff. Frequent use of “need” (1947) might mean customers are looking for essential items.\n",
        "\n",
        "3. Adjective Usage Analysis\n",
        "Common adjectives describe store qualities and experiences:\n",
        "- Positive words: good (2946), great (2469), friendly (1981), nice (1456), clean (1394), helpful (1268) show customers are generally satisfied.\n",
        "- Neutral adjectives: more (1293), other (1844), new (864), few (826), same (777), only (689) indicate comparisons in shopping choices.\n",
        "- Negative words: bad (1035), fresh (883), busy (763), last (628) suggest some customers have mixed feelings, particularly about crowded stores or poor service.\n",
        "\n",
        "Insights:\n",
        "The frequent mention of \"friendly\" (1981) and \"helpful\" (1268) highlights that good customer service is important. Mentions of \"busy\" (763) and \"bad\" (1035) may relate to long lines or delays. The word “favorite” (646) indicates strong brand loyalty.\n",
        "\n",
        "4. Noun Usage Analysis\n",
        "Common nouns focus on key topics in reviews:\n",
        "- Store-related nouns: store (7496), grocery (2497), location (1981), line (1398), parking (1194) show that customers care about their shopping experiences and store accessibility.\n",
        "- Service nouns: customer (2868), staff (2062), employee (2024), service (2337) emphasize customer interactions with store employees.\n",
        "- Product nouns: item (2422), selection (1566), price (1683), food (1600) indicate that shoppers often discuss product choices and costs.\n",
        "- Time-related nouns: time (3018), day (1268) may relate to shopping frequency or wait times.\n",
        "\n",
        "Insights:\n",
        "The high mention of \"store\" (7496) points to a focus on in-person shopping rather than online. Frequent mentions of “price” (1683) and “selection” (1566) highlight that cost and product variety are important to customers. Mentions of “line” (1398) and “parking” (1194) may signal issues with shopping logistics.\n",
        "\n",
        "## Overall Insights & Business Implications**\n",
        "\n",
        "- Brand Engagement: Target, Safeway, and Trader Joe’s are frequently discussed, suggesting they attract either many customers or strong opinions, both positive and negative. The presence of both \"Fry’s\" and \"Frys\" indicates possible confusion in how people perceive the brand.\n",
        "\n",
        "- Customer Experience Priorities: The focus on staff and service shows that customer interactions are crucial for satisfaction. Positive words like friendly, helpful, and clean point to good service experiences. Complaints often involve lines, prices, or parking issues, indicating frustration with logistics.\n",
        "\n",
        "- Product & Shopping Trends: Customers often mention price, selection, food, and item, showing that product choices and affordability matter. Words like \"buy,\" \"need,\" and \"try\" show that customers regularly evaluate new items.\n",
        "\n",
        "## Actionable Recommendations for Grocery Stores:\n",
        "- Enhance Customer Service: Since \"friendly\" and \"helpful\" appear often, training employees can improve customer satisfaction.\n",
        "- Optimize Pricing & Selection: Discussions about price and product variety indicate that competitive pricing and broad selections can boost customer loyalty.\n",
        "- Improve Store Logistics: Addressing issues related to lines and parking can enhance the overall shopping experience.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-24T23:16:58.057832Z",
          "iopub.status.busy": "2025-02-24T23:16:58.057523Z",
          "iopub.status.idle": "2025-02-24T23:16:58.060425Z",
          "shell.execute_reply": "2025-02-24T23:16:58.059941Z",
          "shell.execute_reply.started": "2025-02-24T23:16:58.057813Z"
        },
        "id": "bj-bSzrUP7w1"
      },
      "source": [
        "# 6. Sentiment classification with machine learning approaches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:42:08.119801Z",
          "iopub.status.busy": "2025-03-04T02:42:08.119453Z",
          "iopub.status.idle": "2025-03-04T02:42:08.127015Z",
          "shell.execute_reply": "2025-03-04T02:42:08.126546Z",
          "shell.execute_reply.started": "2025-03-04T02:42:08.119782Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "-k3DKADPP7w1"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import re\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:42:08.127795Z",
          "iopub.status.busy": "2025-03-04T02:42:08.127573Z",
          "iopub.status.idle": "2025-03-04T02:42:26.755501Z",
          "shell.execute_reply": "2025-03-04T02:42:26.754771Z",
          "shell.execute_reply.started": "2025-03-04T02:42:08.127778Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "V-F1hBc8P7w1"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download en_core_web_lg\n",
        "!pip install -q vaderSentiment\n",
        "!pip install s3fs==2023.9.2\n",
        "# Importing neccessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:42:26.756777Z",
          "iopub.status.busy": "2025-03-04T02:42:26.756470Z",
          "iopub.status.idle": "2025-03-04T02:45:33.663126Z",
          "shell.execute_reply": "2025-03-04T02:45:33.662568Z",
          "shell.execute_reply.started": "2025-03-04T02:42:26.756756Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "DD14GY1sP7w1"
      },
      "outputs": [],
      "source": [
        "def normalize(review, lowercase, remove_stopwords):\n",
        "    if lowercase:\n",
        "        review = review.lower()\n",
        "    doc = nlp(review)\n",
        "    lemmatized = list()\n",
        "    for token in doc:\n",
        "        if not remove_stopwords or (remove_stopwords and not token.is_stop):\n",
        "            lemmatized.append(token.lemma_)\n",
        "    return \" \".join(lemmatized)\n",
        "df['processed'] = df[\"review_text\"].apply(normalize, lowercase=True, remove_stopwords=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:45:33.664089Z",
          "iopub.status.busy": "2025-03-04T02:45:33.663826Z",
          "iopub.status.idle": "2025-03-04T02:45:38.706494Z",
          "shell.execute_reply": "2025-03-04T02:45:38.705944Z",
          "shell.execute_reply.started": "2025-03-04T02:45:33.664071Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "TUVy3ViCP7w1"
      },
      "outputs": [],
      "source": [
        "# Lexicon based approch with VaderSentiment\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "sentiment = SentimentIntensityAnalyzer()\n",
        "df['Vader_Sentiment'] = df[\"review_text\"].apply(lambda x: sentiment.polarity_scores(str(x))['compound'])\n",
        "df['Vader_Label'] = df['Vader_Sentiment'].apply(lambda score: 'Positive' if score > 0.05 else ('Negative' if score < -0.05 else 'Neutral'))\n",
        "print(df[[\"review_text\", 'Vader_Sentiment', 'Vader_Label']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:45:38.707435Z",
          "iopub.status.busy": "2025-03-04T02:45:38.707166Z",
          "iopub.status.idle": "2025-03-04T02:45:44.018327Z",
          "shell.execute_reply": "2025-03-04T02:45:44.017740Z",
          "shell.execute_reply.started": "2025-03-04T02:45:38.707417Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "TJ7PI0HsP7w1"
      },
      "outputs": [],
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "# Create sentiment scores\n",
        "df[\"Sentiment\"] = df[\"review_text\"].apply(lambda x: TextBlob(str(x)).sentiment.polarity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:45:44.019299Z",
          "iopub.status.busy": "2025-03-04T02:45:44.019031Z",
          "iopub.status.idle": "2025-03-04T02:45:44.025380Z",
          "shell.execute_reply": "2025-03-04T02:45:44.024751Z",
          "shell.execute_reply.started": "2025-03-04T02:45:44.019279Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "Dc7zdit2P7w1"
      },
      "outputs": [],
      "source": [
        "#Splitting the data into training and testing\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(df[\"review_text\"], df['Sentiment'], test_size=0.2, random_state=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:45:44.026294Z",
          "iopub.status.busy": "2025-03-04T02:45:44.026047Z",
          "iopub.status.idle": "2025-03-04T02:45:44.399670Z",
          "shell.execute_reply": "2025-03-04T02:45:44.399176Z",
          "shell.execute_reply.started": "2025-03-04T02:45:44.026275Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "wi9qRDtsP7w1"
      },
      "outputs": [],
      "source": [
        "#Pre-Prcoessing and Bag of Word Vectorization using Count Vectorizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "token = RegexpTokenizer(r'[a-zA-Z]+')\n",
        "cv = CountVectorizer(stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize, max_features = 1000)\n",
        "X_train_vect = cv.fit_transform(X_train)\n",
        "X_train_vect.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-02-24T23:23:01.003375Z",
          "iopub.status.busy": "2025-02-24T23:23:01.003070Z",
          "iopub.status.idle": "2025-02-24T23:23:01.006042Z",
          "shell.execute_reply": "2025-02-24T23:23:01.005543Z",
          "shell.execute_reply.started": "2025-02-24T23:23:01.003355Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "hp2wrloZP7w1"
      },
      "source": [
        "---\n",
        "## 6.1 Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:45:44.402066Z",
          "iopub.status.busy": "2025-03-04T02:45:44.401893Z",
          "iopub.status.idle": "2025-03-04T02:45:44.405257Z",
          "shell.execute_reply": "2025-03-04T02:45:44.404757Z",
          "shell.execute_reply.started": "2025-03-04T02:45:44.402049Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "dba_xG5BP7w1"
      },
      "outputs": [],
      "source": [
        "# a default list of stop words set by the Spacy language model\n",
        "stopwords = nlp.Defaults.stop_words\n",
        "print(stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:45:44.406130Z",
          "iopub.status.busy": "2025-03-04T02:45:44.405908Z",
          "iopub.status.idle": "2025-03-04T02:45:44.409470Z",
          "shell.execute_reply": "2025-03-04T02:45:44.408970Z",
          "shell.execute_reply.started": "2025-03-04T02:45:44.406114Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "Q4J7fSsyP7w1"
      },
      "outputs": [],
      "source": [
        "# variables to store term statistics\n",
        "num_of_comments = 0\n",
        "unique_word = set() # using the set-type variable since it does not allow duplicates > able to count the number of unique words\n",
        "num_of_token_per_comment = [] # using the list-type varailbe since we want to measure corpus-level statistics (e.g., avg, max, min, median, etc.)\n",
        "num_of_token_per_comment_without_stop_words = []\n",
        "total_number_of_tokens = 0 # in a corpus\n",
        "unique_user = set() # using the set-type variable since it does not allow duplicates > able to count the number of unique users\n",
        "date_list = [] # able to measure the number of comments by day, week, etc.\n",
        "vote_count = 0\n",
        "unique_submission = set() # using the set-type variable since it does not allow duplicates > able to count the number of unique submissions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:45:44.410367Z",
          "iopub.status.busy": "2025-03-04T02:45:44.410071Z",
          "iopub.status.idle": "2025-03-04T02:48:52.993534Z",
          "shell.execute_reply": "2025-03-04T02:48:52.992977Z",
          "shell.execute_reply.started": "2025-03-04T02:45:44.410351Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "M_DOOM38P7w1"
      },
      "outputs": [],
      "source": [
        "for index, row in df.iterrows():\n",
        "    text = row[\"review_text\"]\n",
        "    doc = nlp(text)\n",
        "    num_of_comments += 1\n",
        "\n",
        "    # statistics regarding words\n",
        "    num_of_tokens = len(doc)\n",
        "    total_number_of_tokens += num_of_tokens\n",
        "    token_count_without_stop_words = 0\n",
        "\n",
        "    for token in doc:\n",
        "        if token.is_stop is True:\n",
        "            pass\n",
        "        else:\n",
        "            unique_word.add(str(token).lower())\n",
        "            token_count_without_stop_words += 1\n",
        "\n",
        "    num_of_token_per_comment.append(num_of_tokens)\n",
        "    num_of_token_per_comment_without_stop_words.append(token_count_without_stop_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:48:52.994584Z",
          "iopub.status.busy": "2025-03-04T02:48:52.994326Z",
          "iopub.status.idle": "2025-03-04T02:48:52.997571Z",
          "shell.execute_reply": "2025-03-04T02:48:52.997104Z",
          "shell.execute_reply.started": "2025-03-04T02:48:52.994567Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "VJpAtczjP7w1"
      },
      "outputs": [],
      "source": [
        "# statistics regarding date\n",
        "date = row[\"review_date\"]\n",
        "date_list.append(date)\n",
        "\n",
        "# statistics regarding reviews\n",
        "review_id = row[\"review_id\"]\n",
        "unique_submission.add(review_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:48:52.998382Z",
          "iopub.status.busy": "2025-03-04T02:48:52.998163Z",
          "iopub.status.idle": "2025-03-04T02:48:53.007453Z",
          "shell.execute_reply": "2025-03-04T02:48:53.006924Z",
          "shell.execute_reply.started": "2025-03-04T02:48:52.998366Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "fewc0ggQP7w1"
      },
      "outputs": [],
      "source": [
        "# statistics\n",
        "print(\"number of comments:\", num_of_comments)\n",
        "print(\"number of unique words:\", len(unique_word))\n",
        "print(\"total number of words in the corpus:\", total_number_of_tokens)\n",
        "print(\"average number of words in comments:\", np.mean(np.asarray(num_of_token_per_comment)))\n",
        "print(\"average number of words in comments without stop words:\", np.mean(np.asarray(num_of_token_per_comment_without_stop_words)))\n",
        "print(\"maximum number of words in comments:\", np.max(np.asarray(num_of_token_per_comment)))\n",
        "print(\"maximum number of words in comments without stop words:\", np.max(np.asarray(num_of_token_per_comment_without_stop_words)))\n",
        "print(\"minimum number of words in comments:\", np.min(np.asarray(num_of_token_per_comment)))\n",
        "print(\"minimum number of words in comments without stop words:\", np.min(np.asarray(num_of_token_per_comment_without_stop_words)))\n",
        "print(\"median number of words in comments:\", np.median(np.asarray(num_of_token_per_comment)))\n",
        "print(\"median number of words in comments without stop words:\", np.median(np.asarray(num_of_token_per_comment_without_stop_words)))\n",
        "print(\"number of unique users:\", len(unique_user))\n",
        "print(\"number of sumbissions:\", len(unique_submission))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:48:53.008385Z",
          "iopub.status.busy": "2025-03-04T02:48:53.008123Z",
          "iopub.status.idle": "2025-03-04T02:48:53.049888Z",
          "shell.execute_reply": "2025-03-04T02:48:53.049338Z",
          "shell.execute_reply.started": "2025-03-04T02:48:53.008366Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "4-90EzPzP7w2"
      },
      "outputs": [],
      "source": [
        "df1 = pd.DataFrame(X_train_vect.toarray(), columns=cv.get_feature_names_out())\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:48:53.050807Z",
          "iopub.status.busy": "2025-03-04T02:48:53.050551Z",
          "iopub.status.idle": "2025-03-04T02:48:53.067598Z",
          "shell.execute_reply": "2025-03-04T02:48:53.067026Z",
          "shell.execute_reply.started": "2025-03-04T02:48:53.050789Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "KeLJDDbgP7w2"
      },
      "outputs": [],
      "source": [
        "cv.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:48:53.068530Z",
          "iopub.status.busy": "2025-03-04T02:48:53.068271Z",
          "iopub.status.idle": "2025-03-04T02:48:53.162292Z",
          "shell.execute_reply": "2025-03-04T02:48:53.161827Z",
          "shell.execute_reply.started": "2025-03-04T02:48:53.068511Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "9lUAkQvUP7w2"
      },
      "outputs": [],
      "source": [
        "X_test_vect= cv.transform(X_test)\n",
        "X_test_vect.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "lQjl8KjwP7w2"
      },
      "source": [
        "---\n",
        "\n",
        "## 6.2 Naive Bayes Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:48:53.164324Z",
          "iopub.status.busy": "2025-03-04T02:48:53.164164Z",
          "iopub.status.idle": "2025-03-04T02:48:53.170312Z",
          "shell.execute_reply": "2025-03-04T02:48:53.169840Z",
          "shell.execute_reply.started": "2025-03-04T02:48:53.164308Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "R8xOGkwHP7w2"
      },
      "outputs": [],
      "source": [
        "def categorize_sentiment(score):\n",
        "    if score > 0:\n",
        "        return 2  # Positive\n",
        "    elif score < 0:\n",
        "        return 0  # Negative\n",
        "    else:\n",
        "        return 1  # Neutral\n",
        "\n",
        "# Apply the function to convert Y_train and Y_test\n",
        "Y_train = np.array([categorize_sentiment(score) for score in Y_train])\n",
        "Y_test = np.array([categorize_sentiment(score) for score in Y_test])\n",
        "\n",
        "# Verify the unique values after conversion\n",
        "print(\"Unique values in Y_train after conversion:\", np.unique(Y_train))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:48:53.171207Z",
          "iopub.status.busy": "2025-03-04T02:48:53.170976Z",
          "iopub.status.idle": "2025-03-04T02:48:53.180863Z",
          "shell.execute_reply": "2025-03-04T02:48:53.180348Z",
          "shell.execute_reply.started": "2025-03-04T02:48:53.171189Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "bsPPA-3fP7w2"
      },
      "outputs": [],
      "source": [
        "#Training the model\n",
        "MNB = MultinomialNB()\n",
        "MNB.fit(X_train_vect, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:48:53.181801Z",
          "iopub.status.busy": "2025-03-04T02:48:53.181553Z",
          "iopub.status.idle": "2025-03-04T02:48:53.201009Z",
          "shell.execute_reply": "2025-03-04T02:48:53.200471Z",
          "shell.execute_reply.started": "2025-03-04T02:48:53.181784Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "8gJXdhzrP7w2"
      },
      "outputs": [],
      "source": [
        "#Evaluate the performance of the model\n",
        "from sklearn import metrics\n",
        "predicted = MNB.predict(X_test_vect)\n",
        "performance = metrics.classification_report(\n",
        "    Y_test, predicted, labels\n",
        "    =[\"0\", \"1\", \"2\"], target_names=[\"Negative\", \"Neutral\", \"Positive\"], zero_division=0\n",
        ")\n",
        "\n",
        "display(performance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:48:53.201957Z",
          "iopub.status.busy": "2025-03-04T02:48:53.201697Z",
          "iopub.status.idle": "2025-03-04T02:48:53.213117Z",
          "shell.execute_reply": "2025-03-04T02:48:53.212524Z",
          "shell.execute_reply.started": "2025-03-04T02:48:53.201939Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "qlA3TRAVP7w2"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "performance = metrics.classification_report(Y_test, predicted, labels=[0, 1, 2], target_names=['Negative', 'Neutral', 'Positive'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-25T00:32:24.367972Z",
          "iopub.status.busy": "2025-02-25T00:32:24.367654Z",
          "iopub.status.idle": "2025-02-25T00:32:24.370575Z",
          "shell.execute_reply": "2025-02-25T00:32:24.370081Z",
          "shell.execute_reply.started": "2025-02-25T00:32:24.367950Z"
        },
        "id": "iH6BfRGRP7w2"
      },
      "source": [
        "## 6.3 Support Vector Machines (SVM) classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:48:53.215327Z",
          "iopub.status.busy": "2025-03-04T02:48:53.215148Z",
          "iopub.status.idle": "2025-03-04T02:48:56.576567Z",
          "shell.execute_reply": "2025-03-04T02:48:56.576013Z",
          "shell.execute_reply.started": "2025-03-04T02:48:53.215310Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "SK431RAzP7w2"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm\n",
        "clf = svm.SVC()\n",
        "clf.fit(X_train_vect, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:48:56.577601Z",
          "iopub.status.busy": "2025-03-04T02:48:56.577330Z",
          "iopub.status.idle": "2025-03-04T02:48:57.342346Z",
          "shell.execute_reply": "2025-03-04T02:48:57.341831Z",
          "shell.execute_reply.started": "2025-03-04T02:48:56.577583Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "xbfo5C_JP7w2"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "predicted = clf.predict(X_test_vect)\n",
        "performance = metrics.classification_report(Y_test,predicted, target_names= [\"Negative\", \"Neutral\", \"Positive\"])\n",
        "display(performance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nluJndXiP7w2"
      },
      "source": [
        "## 6.4 TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:48:57.344692Z",
          "iopub.status.busy": "2025-03-04T02:48:57.344470Z",
          "iopub.status.idle": "2025-03-04T02:48:57.698095Z",
          "shell.execute_reply": "2025-03-04T02:48:57.697574Z",
          "shell.execute_reply.started": "2025-03-04T02:48:57.344674Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "DmO6LTGIP7w2"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "token = RegexpTokenizer(r'[a-zA-Z]+')\n",
        "vectorizer = TfidfVectorizer(stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize, max_features = 800)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_train_tfidf.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:48:57.699043Z",
          "iopub.status.busy": "2025-03-04T02:48:57.698769Z",
          "iopub.status.idle": "2025-03-04T02:48:57.758085Z",
          "shell.execute_reply": "2025-03-04T02:48:57.757575Z",
          "shell.execute_reply.started": "2025-03-04T02:48:57.699024Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "exFaMVHLP7w3"
      },
      "outputs": [],
      "source": [
        "df2 = pd.DataFrame(X_train_tfidf.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:48:57.758983Z",
          "iopub.status.busy": "2025-03-04T02:48:57.758728Z",
          "iopub.status.idle": "2025-03-04T02:48:57.847500Z",
          "shell.execute_reply": "2025-03-04T02:48:57.847016Z",
          "shell.execute_reply.started": "2025-03-04T02:48:57.758965Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "vRTKvId9P7w3"
      },
      "outputs": [],
      "source": [
        "X_test_tfidf= vectorizer.transform(X_test)\n",
        "X_test_tfidf.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "rlVae46VP7w3"
      },
      "source": [
        "## 6.5 Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:48:57.849560Z",
          "iopub.status.busy": "2025-03-04T02:48:57.849401Z",
          "iopub.status.idle": "2025-03-04T02:48:57.935944Z",
          "shell.execute_reply": "2025-03-04T02:48:57.935426Z",
          "shell.execute_reply.started": "2025-03-04T02:48:57.849545Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "NflpwSsYP7w3"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "LG = LogisticRegression()\n",
        "print(X_train_tfidf.shape)\n",
        "LG.fit(X_train_tfidf, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:48:57.936844Z",
          "iopub.status.busy": "2025-03-04T02:48:57.936592Z",
          "iopub.status.idle": "2025-03-04T02:48:57.948070Z",
          "shell.execute_reply": "2025-03-04T02:48:57.947582Z",
          "shell.execute_reply.started": "2025-03-04T02:48:57.936825Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "zWj5rWaKP7w3"
      },
      "outputs": [],
      "source": [
        "predicted = LG.predict(X_test_tfidf)\n",
        "performance = metrics.classification_report(Y_test,predicted, target_names= [\"Negative\", \"Neutral\", \"Positive\"])\n",
        "display(performance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "rdFU7x1SP7w3"
      },
      "source": [
        "## 6.6 Comparison with VaderSentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:48:57.950212Z",
          "iopub.status.busy": "2025-03-04T02:48:57.949999Z",
          "iopub.status.idle": "2025-03-04T02:48:57.954602Z",
          "shell.execute_reply": "2025-03-04T02:48:57.954157Z",
          "shell.execute_reply.started": "2025-03-04T02:48:57.950194Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "TWoIcSgEP7w3"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:48:57.955380Z",
          "iopub.status.busy": "2025-03-04T02:48:57.955166Z",
          "iopub.status.idle": "2025-03-04T02:48:58.973341Z",
          "shell.execute_reply": "2025-03-04T02:48:58.972791Z",
          "shell.execute_reply.started": "2025-03-04T02:48:57.955363Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "zR6E8vZuP7w3"
      },
      "outputs": [],
      "source": [
        "v_predicted = []\n",
        "for text in X_test:\n",
        "    sent = sentiment.polarity_scores(text)\n",
        "    if sent['compound'] > 0:\n",
        "        v_predicted.append(\"Positive\")\n",
        "    elif sent['compound'] < 0:\n",
        "        v_predicted.append(\"Negative\")\n",
        "    else:\n",
        "        v_predicted.append(\"Neutral\")  # Ensure \"Neutral\" is included"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:48:58.974185Z",
          "iopub.status.busy": "2025-03-04T02:48:58.973955Z",
          "iopub.status.idle": "2025-03-04T02:48:58.976818Z",
          "shell.execute_reply": "2025-03-04T02:48:58.976374Z",
          "shell.execute_reply.started": "2025-03-04T02:48:58.974169Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "v270ndx5P7w3"
      },
      "outputs": [],
      "source": [
        "label_mapping = {\"Negative\": 0, \"Neutral\": 1, \"Positive\": 2}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:48:58.977596Z",
          "iopub.status.busy": "2025-03-04T02:48:58.977392Z",
          "iopub.status.idle": "2025-03-04T02:48:58.980653Z",
          "shell.execute_reply": "2025-03-04T02:48:58.980215Z",
          "shell.execute_reply.started": "2025-03-04T02:48:58.977582Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "jJAPKEHWP7w3"
      },
      "outputs": [],
      "source": [
        "Y_test_numeric = [label_mapping[label] if isinstance(label, str) else label for label in Y_test]\n",
        "v_predicted_numeric = [label_mapping[label] for label in v_predicted]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:48:58.981391Z",
          "iopub.status.busy": "2025-03-04T02:48:58.981190Z",
          "iopub.status.idle": "2025-03-04T02:48:58.992581Z",
          "shell.execute_reply": "2025-03-04T02:48:58.992122Z",
          "shell.execute_reply.started": "2025-03-04T02:48:58.981377Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "oqDt8gHBP7w3"
      },
      "outputs": [],
      "source": [
        "v_performance = metrics.classification_report(\n",
        "    Y_test_numeric, v_predicted_numeric, target_names=[\"Negative\", \"Neutral\", \"Positive\"]\n",
        ")\n",
        "display(v_performance)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:48:58.993425Z",
          "iopub.status.busy": "2025-03-04T02:48:58.993180Z",
          "iopub.status.idle": "2025-03-04T02:48:58.996340Z",
          "shell.execute_reply": "2025-03-04T02:48:58.995854Z",
          "shell.execute_reply.started": "2025-03-04T02:48:58.993408Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "EfXZDsOMP7w3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert Y_test to a Pandas Series with an index\n",
        "Y_test_series = pd.Series(Y_test, index=range(len(Y_test)), name=\"Y_test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:48:58.997279Z",
          "iopub.status.busy": "2025-03-04T02:48:58.996995Z",
          "iopub.status.idle": "2025-03-04T02:49:00.818552Z",
          "shell.execute_reply": "2025-03-04T02:49:00.818027Z",
          "shell.execute_reply.started": "2025-03-04T02:48:58.997262Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "rd9k2VlXP7w3"
      },
      "outputs": [],
      "source": [
        "# Ensure Vader sentiment is only applied to the test set\n",
        "df_test = df.iloc[Y_test_series.index].copy()  # Use .copy() to avoid modification warnings\n",
        "\n",
        "# Initialize Vader SentimentIntensityAnalyzer\n",
        "sentiment = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Predict Vader sentiment for X_test\n",
        "v_predicted = []\n",
        "for text in X_test:\n",
        "    sent = sentiment.polarity_scores(text)\n",
        "    if sent['compound'] > 0:\n",
        "        v_predicted.append(\"Positive\")\n",
        "    elif sent['compound'] < 0:\n",
        "        v_predicted.append(\"Negative\")\n",
        "    else:\n",
        "        v_predicted.append(\"Neutral\")  # Ensure \"Neutral\" is included\n",
        "\n",
        "# Convert labels to numeric format for consistency\n",
        "label_mapping = {\"Negative\": 0, \"Neutral\": 1, \"Positive\": 2}\n",
        "Y_test_numeric = [label_mapping[label] if isinstance(label, str) else label for label in Y_test_series]\n",
        "v_predicted_numeric = [label_mapping[label] for label in v_predicted]\n",
        "\n",
        "# Compute Vader Sentiment Analysis Accuracy\n",
        "df_test[\"Vader_Label_Numeric\"] = v_predicted_numeric\n",
        "vader_accuracy = accuracy_score(Y_test_numeric, df_test[\"Vader_Label_Numeric\"])\n",
        "\n",
        "# Generate classification reports for all models\n",
        "vader_performance = classification_report(Y_test_numeric, v_predicted_numeric, output_dict=True)\n",
        "logistic_performance = classification_report(Y_test_numeric, LG.predict(X_test_tfidf), output_dict=True)\n",
        "svm_performance = classification_report(Y_test_numeric, clf.predict(X_test_vect), output_dict=True)\n",
        "naive_bayes_performance = classification_report(Y_test_numeric, MNB.predict(X_test_vect), output_dict=True)\n",
        "\n",
        "# Creating a refined comparison table\n",
        "comparison_df = pd.DataFrame({\n",
        "    \"Metric\": [\"Accuracy\", \"Precision (Positive)\", \"Recall (Positive)\", \"F1-Score (Positive)\"],\n",
        "    \"Vader\": [\n",
        "        vader_accuracy,\n",
        "        vader_performance[\"2\"][\"precision\"],\n",
        "        vader_performance[\"2\"][\"recall\"],\n",
        "        vader_performance[\"2\"][\"f1-score\"],\n",
        "    ],\n",
        "    \"Logistic Regression\": [\n",
        "        logistic_performance[\"accuracy\"],\n",
        "        logistic_performance[\"2\"][\"precision\"],\n",
        "        logistic_performance[\"2\"][\"recall\"],\n",
        "        logistic_performance[\"2\"][\"f1-score\"],\n",
        "    ],\n",
        "    \"SVM\": [\n",
        "        svm_performance[\"accuracy\"],\n",
        "        svm_performance[\"2\"][\"precision\"],\n",
        "        svm_performance[\"2\"][\"recall\"],\n",
        "        svm_performance[\"2\"][\"f1-score\"],\n",
        "    ],\n",
        "    \"Naive Bayes\": [\n",
        "        naive_bayes_performance[\"accuracy\"],\n",
        "        naive_bayes_performance[\"2\"][\"precision\"],\n",
        "        naive_bayes_performance[\"2\"][\"recall\"],\n",
        "        naive_bayes_performance[\"2\"][\"f1-score\"],\n",
        "    ],\n",
        "})\n",
        "\n",
        "# Display the refined comparison table\n",
        "display(comparison_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZXs2UpuP7w3"
      },
      "source": [
        "---\n",
        "\n",
        "## Comparison and Conclusion on Sentiment Analysis Approaches\n",
        "### 1. Accuracy and Performance Differences:\n",
        "The analysis shows that machine learning models, particularly Support Vector Machine (SVM) and Logistic Regression, significantly outperform VADER in sentiment classification. SVM achieves the highest accuracy, making it the most reliable model for this task. Logistic Regression follows closely behind, balancing performance and computational efficiency. Naive Bayes performs better than VADER but is not as effective as the other two machine learning models.\n",
        "\n",
        "VADER, a lexicon-based approach, is limited by its predefined word lists and rules. While it provides reasonable accuracy without requiring training data, it cannot learn from domain-specific language patterns, making it less effective compared to trained models.\n",
        "\n",
        "### 2. Strengths and Weaknesses of VADER:\n",
        "VADER is designed for quick sentiment analysis and does not require labeled training data. This makes it useful for real-time applications, such as monitoring social media sentiment or analyzing customer feedback without an extensive dataset. It performs well in predicting positive sentiment with high precision but struggles with recall, meaning it may fail to identify some positive sentiments correctly. The lack of contextual understanding also makes it susceptible to errors when handling negations, sarcasm, or domain-specific sentiment expressions.\n",
        "\n",
        "### 3. Strengths of Machine Learning Models:\n",
        "Machine learning models, particularly SVM and Logistic Regression, demonstrate superior performance due to their ability to learn from labeled data. They capture complex language patterns, making them highly effective in sentiment classification. SVM, in particular, stands out as the best-performing model, achieving the highest accuracy and F1 score. Logistic Regression provides comparable results while being computationally less intensive. These models excel in both precision and recall, ensuring a more balanced classification compared to VADER.\n",
        "\n",
        "Naive Bayes, while faster and computationally efficient, does not perform as well as the other machine learning models due to its assumption of feature independence. This limitation affects its ability to properly classify sentiment when contextual relationships between words are important.\n",
        "\n",
        "### 4. Choosing the Right Approach:\n",
        "The choice of sentiment analysis approach depends on the specific requirements of the task. If real-time sentiment analysis is needed and labeled data is not available, VADER is a suitable option. It provides reasonable accuracy without the need for model training. However, for tasks requiring higher accuracy and adaptability to domain-specific language, machine learning models such as SVM and Logistic Regression should be preferred.\n",
        "\n",
        "For applications where computational efficiency is a priority, Logistic Regression offers a good balance between accuracy and speed. If maximum accuracy is required, SVM is the best choice. Naive Bayes can be considered for simpler tasks but is generally outperformed by the other two machine learning models.\n",
        "\n",
        "### 5. Final Recommendation:\n",
        "VADER is useful for quick sentiment classification but lacks the contextual understanding required for more complex tasks. Machine learning models, particularly SVM and Logistic Regression, provide significantly better performance and should be used when labeled data is available. For applications where high accuracy is essential, SVM is the best option. If computational efficiency is a concern, Logistic Regression serves as a strong alternative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "LvR03YuqP7w3"
      },
      "source": [
        "---\n",
        "\n",
        "## 6.7 Train and evaluate SVM model on test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:49:00.822223Z",
          "iopub.status.busy": "2025-03-04T02:49:00.822045Z",
          "iopub.status.idle": "2025-03-04T02:49:00.825922Z",
          "shell.execute_reply": "2025-03-04T02:49:00.825423Z",
          "shell.execute_reply.started": "2025-03-04T02:49:00.822205Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "9K0fC_rlP7w3"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Convert sentiment labels into numerical values\n",
        "label_encoder = LabelEncoder()\n",
        "Y_train = label_encoder.fit_transform(Y_train)  # Convert labels\n",
        "Y_test = label_encoder.transform(Y_test)  # Convert labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:49:00.826864Z",
          "iopub.status.busy": "2025-03-04T02:49:00.826629Z",
          "iopub.status.idle": "2025-03-04T02:49:04.852466Z",
          "shell.execute_reply": "2025-03-04T02:49:04.851933Z",
          "shell.execute_reply.started": "2025-03-04T02:49:00.826846Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "0oXvzmdfP7w3"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Train SVM model\n",
        "SVM_model = SVC()\n",
        "SVM_model.fit(X_train_tfidf, Y_train)  # Ensure Y_train is numerical\n",
        "\n",
        "# Evaluate SVM model on test data\n",
        "predicted_svm = SVM_model.predict(X_test_tfidf)\n",
        "\n",
        "# Generate classification report with correct target names\n",
        "svm_performance = classification_report(\n",
        "    Y_test, predicted_svm, target_names=[\"Negative\", \"Neutral\", \"Positive\"]\n",
        ")\n",
        "print(\"SVM Performance on Test Data:\")\n",
        "display(svm_performance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycg7DBVaP7w3"
      },
      "source": [
        "---\n",
        "\n",
        "## Analysis of SVM Model Performance on Sentiment Analysis\n",
        "### 1. Overall Model Performance\n",
        "The Support Vector Machine (SVM) model achieves a high level of accuracy in classifying sentiment, demonstrating strong performance across all three sentiment categories: Negative, Neutral, and Positive. The overall accuracy is high, indicating that the model effectively distinguishes between different sentiments within the dataset.\n",
        "\n",
        "### 2. Precision, Recall, and F1-Score Evaluation\n",
        "The model maintains consistently high precision, recall, and F1-scores for all sentiment categories. Precision measures how many of the predicted sentiments were correct, recall reflects the model’s ability to capture all relevant instances, and the F1-score provides a balance between the two. The near-perfect values suggest that the model effectively minimizes misclassification.\n",
        "\n",
        "For the negative and positive sentiment classes, both precision and recall are close to perfect. This indicates that the model is highly confident in its predictions and accurately classifies these sentiments. The neutral sentiment class, however, shows slightly lower recall compared to precision, which suggests that the model might sometimes misclassify neutral sentiments as either negative or positive.\n",
        "\n",
        "### 3. Class Distribution and Model Balance\n",
        "The support values indicate the number of instances for each sentiment class. The model performs well across different class distributions, maintaining balanced predictions despite potential variations in dataset composition. The macro and weighted averages confirm that the model is not biased toward any particular sentiment class.\n",
        "\n",
        "### 4. Strengths of the SVM Model\n",
        "The high scores across all evaluation metrics indicate that the SVM model effectively captures linguistic patterns in the data. This is particularly beneficial for sentiment analysis, where subtle differences in wording can change the meaning of a statement. The model's robustness ensures that it performs well even with varying input structures.\n",
        "\n",
        "### 5. Areas for Further Improvement\n",
        "While the model performs exceptionally well, minor improvements could be made in recall for the neutral sentiment class. Additional training data, more refined feature engineering, or hyperparameter tuning may further enhance the model’s ability to correctly identify neutral sentiments. If class imbalance is present, techniques such as oversampling or class weighting could help balance performance across all sentiment categories.\n",
        "\n",
        "### 6. Conclusion\n",
        "The SVM model demonstrates excellent performance in sentiment classification, making it a reliable choice for sentiment analysis tasks. Its high accuracy and balanced evaluation metrics indicate that it effectively distinguishes between negative, neutral, and positive sentiments. While it slightly struggles with recall in the neutral category, its overall performance is strong and suitable for real-world sentiment analysis applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "hEPwFVzrP7w4"
      },
      "source": [
        "---\n",
        "# 6.8 Text Classification with Deep Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:49:04.856088Z",
          "iopub.status.busy": "2025-03-04T02:49:04.855880Z",
          "iopub.status.idle": "2025-03-04T02:49:47.812990Z",
          "shell.execute_reply": "2025-03-04T02:49:47.812279Z",
          "shell.execute_reply.started": "2025-03-04T02:49:04.856070Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "rC7S0nYaP7w4"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries, packages, and data.\n",
        "%pip install --upgrade keras\n",
        "!pip install pydot\n",
        "!pip install graphviz\n",
        "%pip install wordcloud spacy scikit-learn pandas matplotlib seaborn\n",
        "!pip install --force tensorflow\n",
        "!pip install numpy==1.26.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2Y6bT-EP7w4"
      },
      "source": [
        "---\n",
        "## 6.9 Artificial Neural Network with multiple hidden layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:49:47.815644Z",
          "iopub.status.busy": "2025-03-04T02:49:47.815450Z",
          "iopub.status.idle": "2025-03-04T02:49:48.126265Z",
          "shell.execute_reply": "2025-03-04T02:49:48.125738Z",
          "shell.execute_reply.started": "2025-03-04T02:49:47.815622Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "T2SksctdP7w4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define input layer (TF-IDF features with 5000 dimensions)\n",
        "input_layer = tf.keras.Input(shape=(5000,), name=\"input_layer\")\n",
        "\n",
        "# First hidden layer (ReLU activation for feature extraction)\n",
        "hidden_layer1 = tf.keras.layers.Dense(units=1024, activation=\"relu\", name=\"hidden_layer1\")(input_layer)\n",
        "\n",
        "# Second hidden layer (ReLU activation for deeper representation)\n",
        "hidden_layer2 = tf.keras.layers.Dense(units=512, activation=\"relu\", name=\"hidden_layer2\")(hidden_layer1)\n",
        "\n",
        "# Third hidden layer (ReLU activation for enhanced feature learning)\n",
        "hidden_layer3 = tf.keras.layers.Dense(units=256, activation=\"relu\", name=\"hidden_layer3\")(hidden_layer2)\n",
        "\n",
        "# Output layer (Softmax for multi-class classification)\n",
        "output_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\", name=\"output_layer\")(hidden_layer3)\n",
        "\n",
        "# Define ANN Model\n",
        "model = tf.keras.Model(inputs=input_layer, outputs=output_layer, name=\"ANN_Grocery_Store_Review\")\n",
        "\n",
        "# Compile model\n",
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\",  # Since we have 3 classes\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),  # Adaptive learning rate\n",
        "    metrics=[\n",
        "        tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
        "        tf.keras.metrics.Precision(name=\"precision\"),\n",
        "        tf.keras.metrics.Recall(name=\"recall\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Display model summary\n",
        "model.summary()\n",
        "\n",
        "# Plot model architecture\n",
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:49:48.127262Z",
          "iopub.status.busy": "2025-03-04T02:49:48.127017Z",
          "iopub.status.idle": "2025-03-04T02:50:24.113761Z",
          "shell.execute_reply": "2025-03-04T02:50:24.113220Z",
          "shell.execute_reply.started": "2025-03-04T02:49:48.127246Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "jW5YlmRrP7w4"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Ensure text data is vectorized\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Use top 5000 features\n",
        "X = tfidf_vectorizer.fit_transform(df['review_text']).toarray()  # Convert sparse matrix to dense array\n",
        "\n",
        "# Ensure target labels are numerical\n",
        "label_mapping = {\"Negative\": 0, \"Neutral\": 1, \"Positive\": 2}\n",
        "Y = df[\"sentiment\"].map(label_mapping).values  # Convert categorical labels to numbers\n",
        "\n",
        "# Convert labels to categorical (One-Hot Encoding) for multi-class classification\n",
        "Y_encoded = to_categorical(Y, num_classes=3)\n",
        "\n",
        "# Split the dataset into 75% training and 25% testing\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Define ModelCheckpoint to save the best model based on validation accuracy\n",
        "checkpoint = ModelCheckpoint(\"best_ann_model.h5\", monitor=\"val_accuracy\", save_best_only=True, mode=\"max\")\n",
        "\n",
        "# Train the ANN model\n",
        "history = model.fit(\n",
        "    x=X_train,\n",
        "    y=Y_train,\n",
        "    epochs=5,            # Running for 5 epochs for better learning\n",
        "    batch_size=16,       # Using batch size of 16 for stability\n",
        "    validation_data=(X_test, Y_test),\n",
        "    callbacks=[checkpoint]  # Save best model based on val_accuracy\n",
        ")\n",
        "\n",
        "# Print training results\n",
        "print(\"Model training complete. Best model saved as 'best_ann_model.h5'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "UwfcvJwxP7w4"
      },
      "source": [
        "---\n",
        "### 6.10 Evaluate the best Model on Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:50:24.115987Z",
          "iopub.status.busy": "2025-03-04T02:50:24.115817Z",
          "iopub.status.idle": "2025-03-04T02:50:24.187786Z",
          "shell.execute_reply": "2025-03-04T02:50:24.187199Z",
          "shell.execute_reply.started": "2025-03-04T02:50:24.115970Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "JmtRd9tNP7w4"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the best saved model\n",
        "best_model = load_model(\"best_ann_model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:50:24.188830Z",
          "iopub.status.busy": "2025-03-04T02:50:24.188570Z",
          "iopub.status.idle": "2025-03-04T02:50:24.561826Z",
          "shell.execute_reply": "2025-03-04T02:50:24.561261Z",
          "shell.execute_reply.started": "2025-03-04T02:50:24.188813Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "md9Clu-MP7w4"
      },
      "outputs": [],
      "source": [
        "# Get model predictions (probabilities for each class)\n",
        "Y_pred_probs = best_model.predict(X_test)\n",
        "\n",
        "# Convert probabilities to class labels (0, 1, or 2)\n",
        "Y_pred_classes = Y_pred_probs.argmax(axis=1)\n",
        "\n",
        "# Convert one-hot encoded Y_test back to class labels\n",
        "Y_true_classes = Y_test.argmax(axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:50:24.562818Z",
          "iopub.status.busy": "2025-03-04T02:50:24.562553Z",
          "iopub.status.idle": "2025-03-04T02:50:24.575935Z",
          "shell.execute_reply": "2025-03-04T02:50:24.575424Z",
          "shell.execute_reply.started": "2025-03-04T02:50:24.562799Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "Zm9HrkH1P7w4"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Print overall accuracy\n",
        "accuracy = accuracy_score(Y_true_classes, Y_pred_classes)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Print classification report (Precision, Recall, F1-Score)\n",
        "print(\"Classification Report:\")\n",
        "display(classification_report(Y_true_classes, Y_pred_classes, target_names=[\"Negative\", \"Neutral\", \"Positive\"]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "966B7Mq1P7w4"
      },
      "source": [
        "---\n",
        "\n",
        "#### Overall Performance:\n",
        "The Artificial Neural Network (ANN) model has demonstrated exceptional accuracy, achieving 99.25% test accuracy. This indicates that the model has effectively learned from the training data and generalizes well to unseen test data. Such a high accuracy suggests that the ANN can distinguish between different sentiment categories.\n",
        "\n",
        "#### Performance Across Sentiment Classes:\n",
        "The model performs well across all sentiment categories, with high precision, recall, and F1 scores. For negative sentiment, the precision is 98%, meaning that most of the reviews classified as negative are indeed negative. The recall for this class is 99%, indicating that nearly all actual negative reviews were correctly identified. The F1-score, which balances precision and recall, is 98%, confirming robust classification.\n",
        "\n",
        "For neutral sentiment, the precision is 100%, ensuring that when the model predicts a review as neutral, it is highly confident in its classification. However, the recall is 88%, suggesting that 12% of neutral reviews were misclassified as either positive or negative. This lower recall score indicates that some neutral sentiment cases are being overlooked, which may be due to the limited number of neutral samples in the dataset.\n",
        "\n",
        "For positive sentiment, the model achieves 100% precision and 99% recall, meaning that nearly all actual positive reviews are correctly classified. The F1-score of 100% confirms that the model is highly reliable in identifying positive sentiment.\n",
        "\n",
        "#### Macro and Weighted Averages:\n",
        "The macro average F1-score of 97% represents an overall balanced performance across all three sentiment classes. Meanwhile, the weighted average F1-score of 99% accounts for class imbalances and confirms that the model is not disproportionately favoring any particular sentiment category."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-26T09:08:12.798716Z",
          "iopub.status.busy": "2025-02-26T09:08:12.798379Z",
          "iopub.status.idle": "2025-02-26T09:08:12.801583Z",
          "shell.execute_reply": "2025-02-26T09:08:12.801085Z",
          "shell.execute_reply.started": "2025-02-26T09:08:12.798695Z"
        },
        "id": "RIfmgVFjP7w6"
      },
      "source": [
        "---\n",
        "\n",
        "## 6.11 RNN with word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:50:24.579487Z",
          "iopub.status.busy": "2025-03-04T02:50:24.579279Z",
          "iopub.status.idle": "2025-03-04T02:50:25.366567Z",
          "shell.execute_reply": "2025-03-04T02:50:25.366059Z",
          "shell.execute_reply.started": "2025-03-04T02:50:24.579470Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "NHbYWY10P7w6"
      },
      "outputs": [],
      "source": [
        "# Word embeddings\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Extract review text from the dataset\n",
        "review_corpus = df['review_text'].astype(str).tolist()  # Ensure all text is treated as string\n",
        "\n",
        "# Define tokenizer parameters specific to Grocery Store Arizona Data\n",
        "max_words = 7000  # Increased vocabulary size to accommodate grocery-related terms\n",
        "embedding_dim = 200  # Lower dimension to reduce computation while preserving meaning\n",
        "max_length = 75  # Adjusted to accommodate longer grocery reviews\n",
        "trunc_type = \"post\"  # Truncate from the end of reviews\n",
        "padding_type = \"post\"  # Pad shorter reviews at the end\n",
        "\n",
        "# Initialize and fit the tokenizer\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")  # Handle out-of-vocabulary words\n",
        "tokenizer.fit_on_texts(review_corpus)\n",
        "\n",
        "# Convert text to sequences\n",
        "sequences = tokenizer.texts_to_sequences(review_corpus)\n",
        "\n",
        "# Pad sequences to ensure uniform input size\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "# Convert to NumPy array for TensorFlow compatibility\n",
        "X_embedded = np.array(padded_sequences)\n",
        "\n",
        "# Convert embedded sequences to a DataFrame for inspection\n",
        "embedding_df = pd.DataFrame(X_embedded)\n",
        "\n",
        "# Display output\n",
        "print(\"Shape of Word Embedding Representation:\", embedding_df.shape)\n",
        "display(embedding_df.head())  # Shows the first few rows\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:50:25.367522Z",
          "iopub.status.busy": "2025-03-04T02:50:25.367250Z",
          "iopub.status.idle": "2025-03-04T02:50:25.434392Z",
          "shell.execute_reply": "2025-03-04T02:50:25.433918Z",
          "shell.execute_reply.started": "2025-03-04T02:50:25.367504Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "fChUODLhP7w6"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Input\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Define RNN Model\n",
        "input_layer = Input(shape=(max_length,), name=\"input_layer\")\n",
        "\n",
        "# Embedding Layer (Uses word embeddings processed earlier)\n",
        "embedding_layer = Embedding(\n",
        "    input_dim=max_words,  # Vocabulary size (7000, as per Grocery Store dataset)\n",
        "    output_dim=embedding_dim,  # Embedding dimensions (200)\n",
        "    input_length=max_length,  # Max sequence length (75)\n",
        "    name=\"embedding\"\n",
        ")(input_layer)\n",
        "\n",
        "# RNN Layer\n",
        "rnn_layer = SimpleRNN(\n",
        "    units=256,  # Optimized to 256 neurons for sequential text learning\n",
        "    activation=\"relu\",\n",
        "    return_sequences=False,  # We only need the final output\n",
        "    name=\"rnn_layer\"\n",
        ")(embedding_layer)\n",
        "\n",
        "# Fully Connected Hidden Layers\n",
        "hidden_layer1 = Dense(units=256, activation=\"relu\", name=\"hidden_layer1\")(rnn_layer)\n",
        "hidden_layer2 = Dense(units=128, activation=\"relu\", name=\"hidden_layer2\")(hidden_layer1)\n",
        "\n",
        "# Output Layer (Multi-class classification)\n",
        "output_layer = Dense(units=3, activation=\"softmax\", name=\"output_layer\")(hidden_layer2)\n",
        "\n",
        "# Create the RNN model\n",
        "model_rnn = Model(inputs=input_layer, outputs=output_layer, name=\"RNN_Model\")\n",
        "\n",
        "# Compile Model\n",
        "model_rnn.compile(\n",
        "    loss=\"categorical_crossentropy\",  # Multi-class classification loss function\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),  # Optimized learning rate\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Print Model Summary\n",
        "model_rnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:50:25.435237Z",
          "iopub.status.busy": "2025-03-04T02:50:25.435007Z",
          "iopub.status.idle": "2025-03-04T02:51:10.778685Z",
          "shell.execute_reply": "2025-03-04T02:51:10.778147Z",
          "shell.execute_reply.started": "2025-03-04T02:50:25.435221Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "c33vB3cvP7w6"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data into 75% training and 25% testing\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_embedded, Y_encoded, test_size=0.25, random_state=42)\n",
        "\n",
        "# Define ModelCheckpoint (Save in current directory)\n",
        "checkpoint = ModelCheckpoint(\"best_rnn_model.h5\", monitor=\"val_accuracy\", save_best_only=True, mode=\"max\")\n",
        "\n",
        "# Train the RNN model\n",
        "history = model_rnn.fit(\n",
        "    x=X_train,\n",
        "    y=Y_train,\n",
        "    epochs=5,            # Increased to 5 epochs for better learning\n",
        "    batch_size=16,       # Using batch size of 16 for more stable training\n",
        "    validation_data=(X_test, Y_test),\n",
        "    callbacks=[checkpoint]  # Save best model based on validation accuracy\n",
        ")\n",
        "\n",
        "# Print training results\n",
        "print(\"Model training complete. Best model saved as 'best_rnn_model.h5'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXaqqw1PP7w6"
      },
      "source": [
        "---\n",
        "\n",
        "### 6.12 Evaluation of RNN Model Performance on Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:51:10.780913Z",
          "iopub.status.busy": "2025-03-04T02:51:10.780742Z",
          "iopub.status.idle": "2025-03-04T02:51:11.786649Z",
          "shell.execute_reply": "2025-03-04T02:51:11.786079Z",
          "shell.execute_reply.started": "2025-03-04T02:51:10.780897Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "v5v44njqP7w6"
      },
      "outputs": [],
      "source": [
        "# Load the best saved model\n",
        "best_rnn_model = load_model(\"best_rnn_model.h5\")\n",
        "# Generate predictions (probabilities for each class)\n",
        "Y_pred_probs = best_rnn_model.predict(X_test)\n",
        "\n",
        "# Convert probabilities to class labels (0 = Negative, 1 = Neutral, 2 = Positive)\n",
        "Y_pred_classes = Y_pred_probs.argmax(axis=1)\n",
        "\n",
        "# Convert one-hot encoded Y_test back to class labels\n",
        "Y_true_classes = Y_test.argmax(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:51:11.787620Z",
          "iopub.status.busy": "2025-03-04T02:51:11.787342Z",
          "iopub.status.idle": "2025-03-04T02:51:11.800699Z",
          "shell.execute_reply": "2025-03-04T02:51:11.800174Z",
          "shell.execute_reply.started": "2025-03-04T02:51:11.787601Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "uRbk4MZvP7w6"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Print overall accuracy\n",
        "accuracy = accuracy_score(Y_true_classes, Y_pred_classes)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Generate classification report\n",
        "print(\"Classification Report:\")\n",
        "display(classification_report(Y_true_classes, Y_pred_classes, target_names=[\"Negative\", \"Neutral\", \"Positive\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4VPI-w9P7w6"
      },
      "source": [
        "---\n",
        "\n",
        "#### Overall Accuracy\n",
        "The RNN model achieved an overall accuracy of 89.40% on the test dataset. While this is a strong result, it is lower than the performance observed in the ANN model with TF-IDF, suggesting that the sequential nature of RNNs may not have been fully utilized in this case.\n",
        "\n",
        "#### Precision, Recall, and F1-Score Evaluation\n",
        "The classification report provides a breakdown of the model’s ability to classify each sentiment category:\n",
        "\n",
        "#### Negative Sentiment:\n",
        "\n",
        "- Precision: 0.98 (high confidence in negative predictions)\n",
        "- Recall: 0.46 (many actual negative reviews were misclassified)\n",
        "- F1-Score: 0.63 (suggests an imbalance in capturing negative sentiments effectively)\n",
        "- The model struggles to recall negative instances despite high precision.\n",
        "\n",
        "#### Neutral Sentiment:\n",
        "\n",
        "- Precision: 1.00 (perfect precision but on very few samples)\n",
        "- Recall: 0.06 (fails to correctly identify most neutral samples)\n",
        "- F1-Score: 0.11 (extremely low, indicating poor recognition of neutral sentiment)\n",
        "- The model performs poorly in detecting neutral sentiment, likely due to class imbalance in the dataset.\n",
        "    \n",
        "#### Positive Sentiment:\n",
        "\n",
        "- Precision: 0.89 (relatively high, meaning most predicted positives are correct)\n",
        "- Recall: 1.00 (captures all actual positive instances)\n",
        "- F1-Score: 0.94 (a strong balance between precision and recall)\n",
        "- The model is highly effective in recognizing positive sentiments, benefiting from a large sample size in the dataset.\n",
        "    \n",
        "#### Class Distribution and Model Bias\n",
        "The results suggest that the RNN model is heavily biased towards positive sentiment, likely due to the dominance of positive samples in the dataset. While it is highly precise in classifying negative sentiments, it struggles with recall, meaning it fails to correctly identify many actual negative reviews. The model's inability to recall neutral sentiments suggests that neutral samples are too few for the model to learn meaningful patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2Ut7t3iP7w6"
      },
      "source": [
        "---\n",
        "\n",
        "## 6.13 LSTM with word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:51:11.804338Z",
          "iopub.status.busy": "2025-03-04T02:51:11.804111Z",
          "iopub.status.idle": "2025-03-04T02:51:11.892315Z",
          "shell.execute_reply": "2025-03-04T02:51:11.891793Z",
          "shell.execute_reply.started": "2025-03-04T02:51:11.804319Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "RLZI9WAuP7w6"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define LSTM Model\n",
        "input_layer = tf.keras.Input(shape=(max_length,), name=\"input_layer\")\n",
        "\n",
        "# Embedding Layer (Convert word indices into word vectors)\n",
        "embedding_layer = Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_length, name=\"embedding\")(input_layer)\n",
        "\n",
        "# LSTM Layer (Increased Units for Better Feature Extraction)\n",
        "lstm_layer = LSTM(units=256, activation=\"tanh\", return_sequences=False, dropout=0.3, name=\"lstm_layer\")(embedding_layer)\n",
        "\n",
        "# Fully Connected Hidden Layers (Deeper Network for Enhanced Learning)\n",
        "hidden_layer1 = Dense(units=128, activation=\"relu\", name=\"hidden_layer1\")(lstm_layer)\n",
        "hidden_layer2 = Dense(units=64, activation=\"relu\", name=\"hidden_layer2\")(hidden_layer1)\n",
        "dropout_layer = Dropout(0.3)(hidden_layer2)  # Dropout to prevent overfitting\n",
        "\n",
        "# Output Layer (Binary classification)\n",
        "output_layer = Dense(units=1, activation=\"sigmoid\", name=\"output_layer\")(dropout_layer)\n",
        "\n",
        "# Create the LSTM model\n",
        "model_lstm = tf.keras.Model(inputs=input_layer, outputs=output_layer, name=\"LSTM_Model\")\n",
        "\n",
        "# Compile Model\n",
        "model_lstm.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=\"adam\",  # Adam optimizer is better for deep learning tasks\n",
        "    metrics=[\"accuracy\"]  # Track accuracy\n",
        ")\n",
        "\n",
        "# Print Model Summary\n",
        "model_lstm.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:51:11.893268Z",
          "iopub.status.busy": "2025-03-04T02:51:11.893016Z",
          "iopub.status.idle": "2025-03-04T02:52:55.287084Z",
          "shell.execute_reply": "2025-03-04T02:52:55.286538Z",
          "shell.execute_reply.started": "2025-03-04T02:51:11.893251Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "35cpo_AFP7w6"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data into 75% training and 25% testing\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_embedded, Y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Define ModelCheckpoint to save the best model based on validation accuracy\n",
        "checkpoint = ModelCheckpoint(\"best_lstm_model.h5\", monitor=\"val_accuracy\", save_best_only=True, mode=\"max\")\n",
        "\n",
        "# Train the LSTM model\n",
        "history = model_lstm.fit(\n",
        "    x=X_train,\n",
        "    y=Y_train,\n",
        "    epochs=5,            # Increased to 5 epochs for deeper training\n",
        "    batch_size=16,       # Increased batch size for stable learning\n",
        "    validation_data=(X_test, Y_test),\n",
        "    callbacks=[checkpoint]  # Save best model based on validation accuracy\n",
        ")\n",
        "\n",
        "# Print training results\n",
        "print(\"Model training complete. Best model saved as 'best_lstm_model.h5'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:52:55.288066Z",
          "iopub.status.busy": "2025-03-04T02:52:55.287814Z",
          "iopub.status.idle": "2025-03-04T02:52:59.448834Z",
          "shell.execute_reply": "2025-03-04T02:52:59.448248Z",
          "shell.execute_reply.started": "2025-03-04T02:52:55.288050Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "CzlCPVw5P7w7"
      },
      "outputs": [],
      "source": [
        "# Load the best LSTM model\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the saved best model\n",
        "best_lstm_model = load_model(\"best_lstm_model.h5\")\n",
        "\n",
        "# Make predictions on the test set\n",
        "Y_pred = best_lstm_model.predict(X_test)\n",
        "Y_pred_binary = (Y_pred > 0.5).astype(\"int32\")  # Convert probabilities to binary labels\n",
        "\n",
        "# Print test accuracy\n",
        "test_accuracy = best_lstm_model.evaluate(X_test, Y_test, verbose=0)[1]\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# Generate classification report\n",
        "lstm_classification_report = classification_report(Y_test, Y_pred_binary, target_names=[\"Negative\", \"Neutral\", \"Positive\"])\n",
        "print(\"Classification Report:\")\n",
        "print(lstm_classification_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KevPJeIKP7w7"
      },
      "source": [
        "---\n",
        "\n",
        "#### Possible Reasons for Poor LSTM Performance\n",
        "LSTM model is performing very poorly, with an overall accuracy of 2.8%, indicating that the model is failing to generalize. Below are the key reasons that could be causing this issue:\n",
        "\n",
        "#### Poor Word Representation in Embeddings\n",
        "- If the word embeddings are not well-trained, the model struggles to understand the context of words.\n",
        "- The embeddings might not capture enough semantic meaning, leading to incorrect classifications.\n",
        "\n",
        "#### Imbalanced Data Distribution\n",
        "- The model has zero recall and F1-score for the \"Positive\" class, which suggests it is biased towards other classes.\n",
        "- If there is an imbalance in training data, the model may not learn enough from underrepresented classes.\n",
        "\n",
        "#### Ineffective Model Hyperparameters\n",
        "- The activation function, number of layers, or number of units may not be optimized for text classification.\n",
        "- Using ReLU activation in LSTM could lead to vanishing gradient issues, especially for long text sequences.\n",
        "\n",
        "---                                                    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "eW2mWZc9P7w7"
      },
      "source": [
        "## 6.14 Improved LSTM Model with Pre-trained Word Embeddings and Optimized Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:52:59.452532Z",
          "iopub.status.busy": "2025-03-04T02:52:59.452351Z",
          "iopub.status.idle": "2025-03-04T02:52:59.456113Z",
          "shell.execute_reply": "2025-03-04T02:52:59.455545Z",
          "shell.execute_reply.started": "2025-03-04T02:52:59.452513Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "fp9fcSWtP7w7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "print(os.listdir('.'))  # Lists all files in the current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T02:52:59.456978Z",
          "iopub.status.busy": "2025-03-04T02:52:59.456709Z",
          "iopub.status.idle": "2025-03-04T03:01:20.545398Z",
          "shell.execute_reply": "2025-03-04T03:01:20.544553Z",
          "shell.execute_reply.started": "2025-03-04T02:52:59.456923Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "IpMV3HAXP7w7"
      },
      "outputs": [],
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T03:01:20.546617Z",
          "iopub.status.busy": "2025-03-04T03:01:20.546313Z",
          "iopub.status.idle": "2025-03-04T03:01:21.577519Z",
          "shell.execute_reply": "2025-03-04T03:01:21.576695Z",
          "shell.execute_reply.started": "2025-03-04T03:01:20.546594Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "sZSnAYxUP7w7"
      },
      "outputs": [],
      "source": [
        "!unzip glove.6B.zip glove.6B.300d.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T03:01:34.217777Z",
          "iopub.status.busy": "2025-03-04T03:01:34.217491Z",
          "iopub.status.idle": "2025-03-04T03:01:55.289722Z",
          "shell.execute_reply": "2025-03-04T03:01:55.289137Z",
          "shell.execute_reply.started": "2025-03-04T03:01:34.217758Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "py4BpdrzP7w7"
      },
      "outputs": [],
      "source": [
        "# Ensure the correct embedding dimension is set\n",
        "embedding_dim = 300  # Change to 200 if using glove.6B.200d.txt\n",
        "# Load GloVe embeddings\n",
        "embedding_index = {}\n",
        "with open(\"glove.6B.300d.txt\", encoding=\"utf8\") as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        embedding_index[word] = np.array(values[1:], dtype=\"float32\")\n",
        "\n",
        "# Create embedding matrix\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i < max_words:\n",
        "        embedding_vector = embedding_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T03:01:55.322623Z",
          "iopub.status.busy": "2025-03-04T03:01:55.322464Z",
          "iopub.status.idle": "2025-03-04T03:01:55.481385Z",
          "shell.execute_reply": "2025-03-04T03:01:55.480847Z",
          "shell.execute_reply.started": "2025-03-04T03:01:55.322606Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "6pOz1TmTP7w7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "\n",
        "# Define the LSTM model\n",
        "input_layer = tf.keras.Input(shape=(max_length,), name=\"input_layer\")\n",
        "\n",
        "# Embedding Layer with Pre-trained Weights\n",
        "embedding_layer = Embedding(input_dim=max_words,\n",
        "                            output_dim=embedding_dim,\n",
        "                            input_length=max_length,\n",
        "                            weights=[embedding_matrix],\n",
        "                            trainable=False,\n",
        "                            name=\"embedding\")(input_layer)\n",
        "\n",
        "# First LSTM Layer (Bidirectional for better learning)\n",
        "lstm_layer1 = Bidirectional(LSTM(units=256, activation=\"tanh\", return_sequences=True, name=\"lstm_layer1\"))(embedding_layer)\n",
        "dropout1 = Dropout(0.3)(lstm_layer1)  # Dropout for regularization\n",
        "\n",
        "# Second LSTM Layer\n",
        "lstm_layer2 = LSTM(units=128, activation=\"tanh\", return_sequences=False, name=\"lstm_layer2\")(dropout1)\n",
        "dropout2 = Dropout(0.3)(lstm_layer2)\n",
        "\n",
        "# Fully Connected Hidden Layers\n",
        "hidden_layer1 = Dense(units=128, activation=\"relu\", name=\"hidden_layer1\")(dropout2)\n",
        "hidden_layer2 = Dense(units=64, activation=\"relu\", name=\"hidden_layer2\")(hidden_layer1)\n",
        "\n",
        "# Output Layer (Binary classification)\n",
        "output_layer = Dense(units=1, activation=\"sigmoid\", name=\"output_layer\")(hidden_layer2)\n",
        "\n",
        "# Create the LSTM model\n",
        "model_lstm = tf.keras.Model(inputs=input_layer, outputs=output_layer, name=\"Optimized_LSTM_Model\")\n",
        "\n",
        "# Compile Model with Adam Optimizer\n",
        "model_lstm.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=\"adam\",  # Adam works better than SGD for text data\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Print Model Summary\n",
        "model_lstm.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T03:01:55.482712Z",
          "iopub.status.busy": "2025-03-04T03:01:55.482454Z",
          "iopub.status.idle": "2025-03-04T03:01:55.488282Z",
          "shell.execute_reply": "2025-03-04T03:01:55.487743Z",
          "shell.execute_reply.started": "2025-03-04T03:01:55.482694Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "n6r0fBFfP7w7"
      },
      "outputs": [],
      "source": [
        "# Handle Class Imbalance with Class Weights\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(Y_train), y=Y_train)\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "\n",
        "print(\"Class Weights:\", class_weights_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T05:12:38.330428Z",
          "iopub.status.busy": "2025-03-04T05:12:38.330097Z",
          "iopub.status.idle": "2025-03-04T05:12:38.335152Z",
          "shell.execute_reply": "2025-03-04T05:12:38.334638Z",
          "shell.execute_reply.started": "2025-03-04T05:12:38.330408Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "scrolled": true,
        "id": "h5WSYVlwP7w7"
      },
      "outputs": [],
      "source": [
        "# Train the Improved LSTM Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Split data into 75% training and 25% testing\n",
        "#X_train, X_test, Y_train, Y_test = train_test_split(X_embedded, Y, test_size=0.25, random_state=42)\n",
        "\n",
        "\n",
        "# Define ModelCheckpoint to save the best model based on validation accuracy\n",
        "#checkpoint = ModelCheckpoint(\"best_lstm_model.h5\", monitor=\"val_accuracy\", save_best_only=True, mode=\"max\")\n",
        "\n",
        "\n",
        "# Train the LSTM model\n",
        "'''history = model_lstm.fit(\n",
        "    x=X_train,\n",
        "    y=Y_train,\n",
        "    epochs=10,            # Increased to 10 epochs for better learning\n",
        "    batch_size=16,        # Increased batch size for stability\n",
        "    validation_data=(X_test, Y_test),\n",
        "    class_weight=class_weights_dict,  # Apply class weights\n",
        "    callbacks=[checkpoint]  # Save best model\n",
        ")'''\n",
        "\n",
        "# Print training results\n",
        "#print(\"Model training complete. Best model saved as '/mnt/data/best_optimized_lstm_model.h5'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "eWd7pm_sP7w7"
      },
      "source": [
        "---\n",
        "\n",
        "### 6.15 Evaluate LSTM Model Performance on Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "gabbXmzbP7w7"
      },
      "outputs": [],
      "source": [
        "# Load the best LSTM model\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the saved best model\n",
        "best_lstm_model = load_model(\"best_lstm_model.h5\")\n",
        "\n",
        "# Make predictions on the test set\n",
        "Y_pred = best_lstm_model.predict(X_test)\n",
        "Y_pred_binary = (Y_pred > 0.5).astype(\"int32\")  # Convert probabilities to binary labels\n",
        "\n",
        "# Print test accuracy\n",
        "test_accuracy = best_lstm_model.evaluate(X_test, Y_test, verbose=0)[1]\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# Generate classification report\n",
        "lstm_classification_report = classification_report(Y_test, Y_pred_binary, target_names=[\"Negative\", \"Neutral\", \"Positive\"])\n",
        "print(\"Classification Report:\")\n",
        "print(lstm_classification_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSB9_Pw8P7w7"
      },
      "source": [
        "#### Overall Performance\n",
        "The LSTM model performed poorly on the test dataset, achieving an overall test accuracy of only 8.35%. This indicates that the model is failing to correctly classify most instances, which suggests potential issues with the model architecture, data preprocessing, or hyperparameters.\n",
        "\n",
        "#### Precision, Recall, and F1-Score Analysis\n",
        "- Negative Sentiment: The model achieved a precision of 0.60 and a recall of 0.45, meaning it can somewhat identify negative reviews but still misclassifies a significant portion.\n",
        "- Neutral Sentiment: The model has a very low recall of 0.47 and almost no precision, indicating it struggles to distinguish neutral reviews from other categories.\n",
        "- Positive Sentiment: The model completely failed to predict positive sentiment, with precision, recall, and F1-score all at 0.00. This means that the model did not correctly classify any positive samples.\n",
        "\n",
        "#### Accuracy and Weighted Scores\n",
        "- The overall accuracy is extremely low (8%), meaning that the model is making incorrect predictions for the vast majority of the test data.\n",
        "- Macro and weighted averages are also very low, suggesting that the model is not learning meaningful patterns from the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "51RvgXNDP7w7"
      },
      "source": [
        "---\n",
        "\n",
        "## 6.16 One-Hot Vector Encoding + RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T03:24:03.360889Z",
          "iopub.status.busy": "2025-03-04T03:24:03.360558Z",
          "iopub.status.idle": "2025-03-04T03:24:05.770489Z",
          "shell.execute_reply": "2025-03-04T03:24:05.769919Z",
          "shell.execute_reply.started": "2025-03-04T03:24:03.360869Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "9AC3H_A3P7w7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# Define tokenizer parameters\n",
        "max_words = 5000  # Vocabulary size (adjusted for project)\n",
        "max_length = 50   # Max sequence length (fixed to 50 words)\n",
        "\n",
        "# Initialize Tokenizer\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(df['review_text'])  # Ensure to use the correct column from your dataset\n",
        "\n",
        "# Convert reviews to sequences\n",
        "sequences = tokenizer.texts_to_sequences(df[\"review_text\"])\n",
        "\n",
        "# Pad sequences to ensure uniform input size\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")\n",
        "\n",
        "# Convert to One-Hot Encoding\n",
        "X_onehot = np.zeros((len(padded_sequences), max_length, max_words))\n",
        "for i, sequence in enumerate(padded_sequences):\n",
        "    for j, word_index in enumerate(sequence):\n",
        "        if word_index < max_words:\n",
        "            X_onehot[i, j, word_index] = 1  # One-hot encode each word\n",
        "\n",
        "# Convert labels\n",
        "Y = np.array(df[\"Sentiment\"])  # Ensure sentiment labels are numeric (0/1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T03:24:08.278796Z",
          "iopub.status.busy": "2025-03-04T03:24:08.278479Z",
          "iopub.status.idle": "2025-03-04T03:24:08.509107Z",
          "shell.execute_reply": "2025-03-04T03:24:08.508563Z",
          "shell.execute_reply.started": "2025-03-04T03:24:08.278777Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "B0CXm6--P7w7"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "\n",
        "# Define the input layer with one-hot encoding (sequence length, vocabulary size)\n",
        "input_layer = tf.keras.Input(shape=(50, 5000), name=\"input_layer\")  # 50 words per review, vocabulary size of 5000\n",
        "\n",
        "# Simple RNN Layer\n",
        "rnn_layer = SimpleRNN(units=512, activation=\"tanh\", return_sequences=False, name=\"rnn_layer\")(input_layer)\n",
        "\n",
        "# Fully Connected Hidden Layers\n",
        "hidden_layer1 = Dense(units=256, activation=\"relu\", name=\"hidden_layer1\")(rnn_layer)\n",
        "hidden_layer2 = Dense(units=128, activation=\"relu\", name=\"hidden_layer2\")(hidden_layer1)\n",
        "\n",
        "# Output Layer (Binary classification)\n",
        "output_layer = Dense(units=1, activation=\"sigmoid\", name=\"output_layer\")(hidden_layer2)\n",
        "\n",
        "# Create the RNN model\n",
        "model_rnn_onehot = tf.keras.Model(inputs=input_layer, outputs=output_layer, name=\"RNN_OneHot_Model\")\n",
        "\n",
        "# Compile the Model\n",
        "model_rnn_onehot.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=\"adam\",  # Adam optimizer for better convergence\n",
        "    metrics=[\n",
        "        tf.keras.metrics.Precision(name=\"precision\"),\n",
        "        tf.keras.metrics.Recall(name=\"recall\"),\n",
        "        tf.keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Print Model Summary\n",
        "model_rnn_onehot.summary()\n",
        "\n",
        "# Visualize Model Architecture\n",
        "tf.keras.utils.plot_model(model_rnn_onehot, show_shapes=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T03:24:11.986265Z",
          "iopub.status.busy": "2025-03-04T03:24:11.985940Z",
          "iopub.status.idle": "2025-03-04T03:26:55.514468Z",
          "shell.execute_reply": "2025-03-04T03:26:55.513925Z",
          "shell.execute_reply.started": "2025-03-04T03:24:11.986245Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "IkhPATKZP7w7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data into 75% training and 25% testing\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_onehot, Y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Define ModelCheckpoint to save the best model based on validation accuracy\n",
        "checkpoint = ModelCheckpoint(\n",
        "    \"best_rnn_onehot_model.h5\", monitor=\"val_accuracy\", save_best_only=True, mode=\"max\"\n",
        ")\n",
        "\n",
        "# Train the RNN model with one-hot vector encoding\n",
        "history = model_rnn_onehot.fit(\n",
        "    x=X_train,\n",
        "    y=Y_train,\n",
        "    epochs=5,            # Running for 5 epochs for better learning\n",
        "    batch_size=16,       # Using batch size of 16 for stable training\n",
        "    validation_data=(X_test, Y_test),\n",
        "    callbacks=[checkpoint]  # Save best model based on validation accuracy\n",
        ")\n",
        "\n",
        "# Print training results\n",
        "print(\"Model training complete. Best model saved as 'best_rnn_onehot_model.h5'.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "CNnK4Y7dP7w7"
      },
      "source": [
        "#### Training Accuracy and Loss Behavior\n",
        "The training accuracy remains extremely low throughout all five epochs. Initially, the accuracy is 0.01 (1%), and it does not improve significantly, dropping further in later epochs. The loss values fluctuate, with some negative values appearing in later epochs, which is highly unusual for a binary classification model using cross-entropy loss. This suggests that the model is not learning effectively.\n",
        "\n",
        "#### Validation Performance\n",
        "The validation accuracy remains fixed at 0.0085 (0.85%), indicating that the model is essentially making random predictions. The validation loss fluctuates dramatically, with values turning negative and eventually reaching 56.6585, which is an extremely poor result. This instability suggests that the model parameters are diverging rather than converging.\n",
        "\n",
        "#### Precision and Recall Issues\n",
        "Precision and recall values for all epochs are 0.0000e+00, meaning that the model is not making any positive predictions. This is a strong indication of a model failure, potentially due to:\n",
        "\n",
        "- Vanishing gradients in the SimpleRNN layer, leading to ineffective weight updates.\n",
        "- Poorly initialized parameters or an unsuitable activation function for learning long-term dependencies.\n",
        "- Incompatibility with One-Hot Encoding where a large vocabulary size leads to inefficient learning.\n",
        "\n",
        "#### Possible Causes for Poor Performance\n",
        "1. Choice of SimpleRNN Instead of LSTM or GRU\n",
        "\n",
        "- SimpleRNN suffers from vanishing gradients, making it difficult to capture sequential dependencies in long text sequences.\n",
        "- LSTM or GRU models are better suited for this task.\n",
        "2. High Dimensionality in One-Hot Encoding\n",
        "\n",
        "- The model's input shape (50, 5000) results in very sparse and high-dimensional representations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gasfGj2YP7w7"
      },
      "source": [
        "---\n",
        "\n",
        "## 7. Bidrectional BiLSTM Model with Pre-trained GloVe Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T03:31:24.902908Z",
          "iopub.status.busy": "2025-03-04T03:31:24.902577Z",
          "iopub.status.idle": "2025-03-04T03:31:24.906961Z",
          "shell.execute_reply": "2025-03-04T03:31:24.906435Z",
          "shell.execute_reply.started": "2025-03-04T03:31:24.902886Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "bq3_n1RZP7w7"
      },
      "outputs": [],
      "source": [
        "print(\"Unique values in sentiment column:\", df[\"sentiment\"].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T03:31:25.744306Z",
          "iopub.status.busy": "2025-03-04T03:31:25.744006Z",
          "iopub.status.idle": "2025-03-04T03:31:25.749812Z",
          "shell.execute_reply": "2025-03-04T03:31:25.749198Z",
          "shell.execute_reply.started": "2025-03-04T03:31:25.744287Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "W70wx2xHP7w7"
      },
      "outputs": [],
      "source": [
        "df[\"sentiment\"] = df[\"sentiment\"].astype(str).str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T03:31:27.074473Z",
          "iopub.status.busy": "2025-03-04T03:31:27.074152Z",
          "iopub.status.idle": "2025-03-04T03:31:27.087478Z",
          "shell.execute_reply": "2025-03-04T03:31:27.086897Z",
          "shell.execute_reply.started": "2025-03-04T03:31:27.074452Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "kXPFhEk0P7w7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "# Ensure valid labels\n",
        "df = df[df[\"sentiment\"].isin([\"negative\", \"neutral\", \"positive\"])]\n",
        "\n",
        "# Convert labels to numeric values\n",
        "label_mapping = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
        "Y = df[\"sentiment\"].map(label_mapping).astype(int)  # Ensure correct data type\n",
        "\n",
        "# Convert to one-hot encoding\n",
        "Y = to_categorical(Y, num_classes=3)\n",
        "\n",
        "print(\"Shape of Y:\", Y.shape)  # Should be (num_samples, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T03:31:29.384318Z",
          "iopub.status.busy": "2025-03-04T03:31:29.383999Z",
          "iopub.status.idle": "2025-03-04T03:31:30.124052Z",
          "shell.execute_reply": "2025-03-04T03:31:30.123434Z",
          "shell.execute_reply.started": "2025-03-04T03:31:29.384297Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "ydob1cp0P7w7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "# Define tokenizer parameters\n",
        "max_words = 5000  # Vocabulary size\n",
        "max_length = 50   # Maximum sequence length\n",
        "\n",
        "# Initialize Tokenizer\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(df[\"review_text\"])  # Tokenize the text column\n",
        "\n",
        "# Convert text to sequences of integers\n",
        "sequences = tokenizer.texts_to_sequences(df[\"review_text\"])\n",
        "\n",
        "# Pad sequences to ensure uniform input size\n",
        "X_padded = pad_sequences(sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")\n",
        "\n",
        "# Convert labels to categorical format (One-Hot Encoding)\n",
        "label_mapping = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
        "Y = np.array(df[\"sentiment\"].map(label_mapping))  # Convert text labels to integers\n",
        "Y = to_categorical(Y, num_classes=3)  # Convert to one-hot encoding\n",
        "\n",
        "print(\"Shape of X_padded:\", X_padded.shape)  # Should be (num_samples, 50)\n",
        "print(\"Shape of Y:\", Y.shape)  # Should be (num_samples, 3) for three sentiment classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T03:31:31.404484Z",
          "iopub.status.busy": "2025-03-04T03:31:31.404157Z",
          "iopub.status.idle": "2025-03-04T03:31:31.463972Z",
          "shell.execute_reply": "2025-03-04T03:31:31.463450Z",
          "shell.execute_reply.started": "2025-03-04T03:31:31.404462Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "OlR-YtIYP7w9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Ensure embedding_matrix shape is correct\n",
        "embedding_matrix = embedding_matrix[:max_words]  # Adjust size to match input_dim\n",
        "\n",
        "# BiLSTM model with multi-class classification\n",
        "bilstm = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=max_words,  # Adjusted to match embedding_matrix\n",
        "        output_dim=300,  # GloVe embedding dimensions\n",
        "        input_length=max_length,  # Sequence length\n",
        "        weights=[embedding_matrix],  # Use pre-trained GloVe embeddings\n",
        "        trainable=False  # Keep embeddings fixed\n",
        "    ),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=128, dropout=0.3, return_sequences=True)),  # First BiLSTM Layer\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=64, dropout=0.3)),  # Second BiLSTM Layer\n",
        "    tf.keras.layers.Dense(64, activation=\"relu\"),  # Fully connected layer\n",
        "    tf.keras.layers.Dropout(0.3),  # Regularization\n",
        "    tf.keras.layers.Dense(32, activation=\"relu\"),  # Additional feature extraction layer\n",
        "    tf.keras.layers.Dense(3, activation=\"softmax\")  # Output Layer (3 classes: Negative, Neutral, Positive)\n",
        "])\n",
        "\n",
        "# Compile the model for multi-class classification\n",
        "bilstm.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\", tf.keras.metrics.Precision(name=\"precision\"), tf.keras.metrics.Recall(name=\"recall\")]\n",
        ")\n",
        "\n",
        "# Model summary\n",
        "bilstm.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T04:45:51.437844Z",
          "iopub.status.busy": "2025-03-04T04:45:51.437509Z",
          "iopub.status.idle": "2025-03-04T04:47:44.717573Z",
          "shell.execute_reply": "2025-03-04T04:47:44.717023Z",
          "shell.execute_reply.started": "2025-03-04T04:45:51.437822Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "981FXlfZP7w9"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data into 75% training and 25% testing\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_padded, Y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Define ModelCheckpoint to save the best model based on validation accuracy\n",
        "checkpoint = ModelCheckpoint(\n",
        "    \"best_bilstm_model_multiclass.h5\", monitor=\"val_accuracy\", save_best_only=True, mode=\"max\"\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = bilstm.fit(\n",
        "    x=X_train,\n",
        "    y=Y_train,\n",
        "    epochs=10,  # Increased epochs for small dataset training\n",
        "    batch_size=32,  # Adjusted batch size for stability\n",
        "    validation_data=(X_test, Y_test),\n",
        "    callbacks=[checkpoint]\n",
        ")\n",
        "\n",
        "# Print training completion message\n",
        "print(\"Model training complete. Best model saved as 'best_bilstm_model_multiclass.h5'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T04:49:01.179013Z",
          "iopub.status.busy": "2025-03-04T04:49:01.178693Z",
          "iopub.status.idle": "2025-03-04T04:49:03.898419Z",
          "shell.execute_reply": "2025-03-04T04:49:03.897853Z",
          "shell.execute_reply.started": "2025-03-04T04:49:01.178992Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "xEK2Gb8IP7w9"
      },
      "outputs": [],
      "source": [
        "# Evaluate the BiLSTM Model on Test Data\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load the best saved model\n",
        "best_bilstm_model = load_model(\"best_bilstm_model_multiclass.h5\")\n",
        "\n",
        "# Make predictions on test data\n",
        "Y_pred_probs = best_bilstm_model.predict(X_test)\n",
        "\n",
        "# Convert probabilities to class labels (argmax for multi-class classification)\n",
        "Y_pred = Y_pred_probs.argmax(axis=1)\n",
        "Y_true = Y_test.argmax(axis=1)  # Convert one-hot encoded labels back to class numbers\n",
        "\n",
        "# Compute accuracy\n",
        "test_accuracy = accuracy_score(Y_true, Y_pred)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# Generate classification report\n",
        "bilstm_classification_report = classification_report(Y_true, Y_pred, target_names=[\"Negative\", \"Neutral\", \"Positive\"])\n",
        "print(\"Classification Report:\\n\", bilstm_classification_report)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iuzzmd92P7w9"
      },
      "source": [
        "#### Overall Model Performance\n",
        "The Bidirectional LSTM (BiLSTM) model has achieved an outstanding test accuracy of 99.15%, indicating that it is highly effective in classifying sentiment into Negative, Neutral, and Positive categories. This level of accuracy suggests that the model has learned strong representations of the input text and is making highly reliable predictions.\n",
        "\n",
        "#### Precision, Recall, and F1-Score\n",
        "The model exhibits exceptionally high precision across all classes. Precision refers to how many of the predicted instances of a class are actually correct. The Neutral class achieved perfect precision (1.00), meaning that whenever the model predicted a review as Neutral, it was indeed Neutral. The Negative and Positive classes also show high precision scores of 0.98 and 0.99, respectively.\n",
        "\n",
        "The recall, which measures how well the model captures all actual instances of a class, is slightly lower for Neutral (0.88) compared to Negative (0.97) and Positive (1.00). This suggests that some Neutral examples may have been misclassified as either Negative or Positive. However, the model correctly identified all Positive reviews, with a recall of 1.00.\n",
        "\n",
        "The F1-score, which balances precision and recall, is extremely high for all classes. The Negative and Positive classes both have nearly perfect F1-scores, while the Neutral class has a slightly lower score of 0.94 due to its recall drop.\n",
        "\n",
        "#### Macro and Weighted Averages\n",
        "The macro average (which gives equal weight to each class) results in a recall of 0.96, reflecting the slight recall drop in the Neutral category. The weighted average, which accounts for class distribution, remains at 0.99, confirming the model’s strong overall performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXQ-qAEVP7w9"
      },
      "source": [
        "## Predict Customer Sentiment Under Business Changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T04:49:28.199651Z",
          "iopub.status.busy": "2025-03-04T04:49:28.199337Z",
          "iopub.status.idle": "2025-03-04T04:49:29.250245Z",
          "shell.execute_reply": "2025-03-04T04:49:29.249717Z",
          "shell.execute_reply.started": "2025-03-04T04:49:28.199629Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "20TCnQGFP7w9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Get unique store names\n",
        "stores = df[\"name\"].unique()\n",
        "\n",
        "# Define expanded scenario reviews\n",
        "scenario_reviews_template = {\n",
        "    \"Original\": [\n",
        "        \"The store has good deals and fresh produce.\",\n",
        "        \"The prices are decent and staff is friendly.\",\n",
        "        \"I like the variety but sometimes items are missing.\",\n",
        "        \"A decent shopping experience, but could improve in some areas.\",\n",
        "        \"Love the cleanliness and organization of the store.\",\n",
        "        \"Fresh vegetables and meat are always available.\",\n",
        "        \"I can find almost everything I need, great selection!\",\n",
        "        \"Service is okay, but checkout lines can be long.\",\n",
        "        \"The store layout makes it easy to find products.\",\n",
        "        \"A reliable place to shop for groceries every week.\"\n",
        "    ],\n",
        "    \"Price Increase\": [\n",
        "        \"The store increased prices and now it’s too expensive.\",\n",
        "        \"Everything is overpriced now, not worth it.\",\n",
        "        \"Higher prices but same quality, not fair!\",\n",
        "        \"I used to shop here often, but now it’s just too expensive.\",\n",
        "        \"Price hikes are ridiculous, I’m looking for alternatives.\",\n",
        "        \"They raised prices on essential items, very disappointing.\",\n",
        "        \"The quality is still good, but the prices are frustrating.\",\n",
        "        \"Why are prices increasing every few weeks?\",\n",
        "        \"It used to be affordable, now it’s just too costly.\",\n",
        "        \"I don’t shop here as much anymore due to the price jumps.\"\n",
        "    ],\n",
        "    \"Price Decrease\": [\n",
        "        \"The store lowered prices, now it’s much more affordable!\",\n",
        "        \"Great discounts, love shopping here now.\",\n",
        "        \"Prices went down and I can buy more for the same budget.\",\n",
        "        \"This place just became my go-to store for groceries!\",\n",
        "        \"More savings means I can get extra items every visit.\",\n",
        "        \"Happy to see better deals and fair pricing again.\",\n",
        "        \"Affordable groceries make a big difference, love it.\",\n",
        "        \"Shopping here now feels like a bargain.\",\n",
        "        \"The discounts on fresh produce are a great improvement.\",\n",
        "        \"Finally, a store that values its customers with fair pricing!\"\n",
        "    ],\n",
        "    \"Inventory Issues\": [\n",
        "        \"They are always out of stock on essential items.\",\n",
        "        \"I can never find what I need, shelves are empty.\",\n",
        "        \"Stock issues are frustrating, they need better supply.\",\n",
        "        \"Why is milk always out of stock?\",\n",
        "        \"I came here for a few basics and left empty-handed.\",\n",
        "        \"This store needs better inventory management.\",\n",
        "        \"Out of stock signs everywhere, so frustrating.\",\n",
        "        \"It’s impossible to do weekly shopping here anymore.\",\n",
        "        \"I went to three different locations and still no stock!\",\n",
        "        \"If they don’t fix inventory issues, I’m switching stores.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Process each store separately\n",
        "for store in stores:\n",
        "    print(f\"\\n🔍 Simulating Business Scenarios for {store}...\\n\")\n",
        "\n",
        "    # Tokenize and pad the scenario reviews\n",
        "    scenario_sequences = tokenizer.texts_to_sequences(\n",
        "        sum(scenario_reviews_template.values(), [])\n",
        "    )\n",
        "    scenario_padded = pad_sequences(scenario_sequences, maxlen=max_length, padding=\"post\")\n",
        "\n",
        "    # Predict sentiment using the trained BiLSTM model\n",
        "    scenario_probs = best_bilstm_model.predict(scenario_padded)\n",
        "    scenario_preds = scenario_probs.argmax(axis=1)\n",
        "\n",
        "    # Map numeric predictions back to labels\n",
        "    label_mapping_inv = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
        "    scenario_sentiments = [label_mapping_inv[pred] for pred in scenario_preds]\n",
        "\n",
        "    # Organize results into a dictionary\n",
        "    scenario_results = {}\n",
        "    index = 0\n",
        "    for scenario, reviews in scenario_reviews_template.items():\n",
        "        scenario_results[scenario] = [scenario_sentiments[index + i] for i in range(len(reviews))]\n",
        "        index += len(reviews)\n",
        "\n",
        "    # Count sentiment distribution per scenario\n",
        "    sentiment_counts = {scenario: {\"Negative\": 0, \"Neutral\": 0, \"Positive\": 0} for scenario in scenario_results}\n",
        "    for scenario, sentiments in scenario_results.items():\n",
        "        for sentiment in sentiments:\n",
        "            sentiment_counts[scenario][sentiment] += 1\n",
        "\n",
        "    # Convert results into a visualization\n",
        "    fig, ax = plt.subplots(figsize=(10, 5))\n",
        "    scenarios = list(sentiment_counts.keys())\n",
        "    negative_counts = [sentiment_counts[sc][\"Negative\"] for sc in scenarios]\n",
        "    neutral_counts = [sentiment_counts[sc][\"Neutral\"] for sc in scenarios]\n",
        "    positive_counts = [sentiment_counts[sc][\"Positive\"] for sc in scenarios]\n",
        "\n",
        "    bar_width = 0.4\n",
        "    x = np.arange(len(scenarios))\n",
        "\n",
        "    ax.bar(x - bar_width, negative_counts, bar_width, label=\"Negative\", color=\"red\")\n",
        "    ax.bar(x, neutral_counts, bar_width, label=\"Neutral\", color=\"gray\")\n",
        "    ax.bar(x + bar_width, positive_counts, bar_width, label=\"Positive\", color=\"green\")\n",
        "\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(scenarios, rotation=15)\n",
        "    ax.set_ylabel(\"Sentiment Count\")\n",
        "    ax.set_title(f\"Predicted Sentiment Shift Under Business Changes - {store}\")\n",
        "    ax.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWbBoJogP7w9"
      },
      "source": [
        "---\n",
        "\n",
        "## 7.1 Comparison of results we got by evaluating the models on test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T04:49:54.495082Z",
          "iopub.status.busy": "2025-03-04T04:49:54.494754Z",
          "iopub.status.idle": "2025-03-04T04:49:54.505465Z",
          "shell.execute_reply": "2025-03-04T04:49:54.504812Z",
          "shell.execute_reply.started": "2025-03-04T04:49:54.495061Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "XY15TGEhP7w9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a dictionary with model performance metrics\n",
        "comparison_data = {\n",
        "    \"Model\": [\n",
        "        \"ANN + TF-IDF\",\n",
        "        \"RNN + Word Embeddings\",\n",
        "        \"LSTM + Word Embeddings\",\n",
        "        \"Improved LSTM + GloVe\",\n",
        "        \"One-Hot Encoding + RNN\",\n",
        "        \"BiLSTM + GloVe\"\n",
        "    ],\n",
        "    \"Accuracy\": [99.25, 89.40, 2.80, 8.35, 0.85, 99.15],\n",
        "    \"Precision\": [99, 90, 97, 60, 0, 99],\n",
        "    \"Recall\": [99, 89, 11, 45, 0, 99],\n",
        "    \"F1-Score\": [99, 88, 20, 51, 0, 99]\n",
        "}\n",
        "\n",
        "# Convert to DataFrame\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "\n",
        "# Display results\n",
        "from IPython.display import display\n",
        "display(comparison_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oApQZBftP7w-"
      },
      "source": [
        "### Analysis of Model Performance\n",
        "Based on the results from the comparison table, we can analyze the performance of each model in terms of accuracy, precision, recall, and F1-score.\n",
        "\n",
        "#### Best Performing Models\n",
        "1. ANN + TF-IDF\n",
        "\n",
        "- Accuracy: 99.25% | Precision: 99 | Recall: 99 | F1-Score: 99\n",
        "- This model performed exceptionally well across all metrics. Combining Artificial Neural Networks (ANN) with Term Frequency-Inverse Document Frequency (TF-IDF) effectively captured patterns in the data.\n",
        "- This method is fast and efficient for structured text classification, making it a strong candidate for further tasks like topic modeling if supplemented with topic extraction techniques.\n",
        "\n",
        "2. BiLSTM + GloVe\n",
        "\n",
        "- Accuracy: 99.15% | Precision: 99 | Recall: 99 | F1-Score: 99\n",
        "- The Bidirectional Long Short-Term Memory (BiLSTM) with Pre-trained GloVe Embeddings also achieved outstanding results, slightly behind ANN + TF-IDF.\n",
        "- The BiLSTM model, leveraging GloVe embeddings, can capture contextual word meanings and dependencies, making it ideal for tasks involving sequential text dependencies.\n",
        "                                                                                                                       \n",
        "#### Poor Performing Models\n",
        "1. LSTM + Word Embeddings (Accuracy: 2.80%)\n",
        "\n",
        "- Despite using word embeddings, this model struggled significantly, likely due to poor training convergence, incorrect parameter tuning, or a dataset too small for LSTM to generalize properly.\n",
        "- Not suitable for topic modeling due to its very low recall and accuracy.\n",
        "              \n",
        "2. One-Hot Encoding + RNN (Accuracy: 0.85%)\n",
        "\n",
        "- This model also failed, as it cannot capture rich semantic relationships between words.\n",
        "- One-hot encoding does not retain word meanings, making it ineffective for deep learning models like RNNs.\n",
        "                                                \n",
        "#### Top 2 Models for Topic Modeling\n",
        "For topic modeling, we need models that can accurately capture the structure and meaning of text, ensuring strong contextual understanding.\n",
        "\n",
        "1. BiLSTM + GloVe\n",
        "\n",
        "- Since topic modeling often requires context-aware text representations, BiLSTM is an excellent choice as it captures both past and future word dependencies.\n",
        "- GloVe embeddings help with semantic representation, which is crucial for distinguishing topics.\n",
        "    \n",
        "2. ANN + TF-IDF\n",
        "\n",
        "- While ANN is a simple and effective model, TF-IDF provides a robust way to extract important words from the text.\n",
        "- This method is fast, efficient, and works well for topic modeling, especially when combined with clustering techniques like LDA (Latent Dirichlet Allocation) or NMF (Non-negative Matrix Factorization)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbY255x0P7w-"
      },
      "source": [
        "---\n",
        "\n",
        "## 7.2 Sentiment classification for each store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T03:52:55.460152Z",
          "iopub.status.busy": "2025-03-04T03:52:55.459829Z",
          "iopub.status.idle": "2025-03-04T03:53:05.206468Z",
          "shell.execute_reply": "2025-03-04T03:53:05.205885Z",
          "shell.execute_reply.started": "2025-03-04T03:52:55.460133Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "dhA7pbYqP7w-"
      },
      "outputs": [],
      "source": [
        "# Load the best trained BiLSTM model\n",
        "best_bilstm_model = tf.keras.models.load_model(\"best_bilstm_model_multiclass.h5\")\n",
        "\n",
        "# Define tokenizer and padding parameters (same as used during training)\n",
        "max_length = 50  # Ensure this matches your training setting\n",
        "\n",
        "\n",
        "# Tokenize and pad sequences\n",
        "sequences = tokenizer.texts_to_sequences(df[\"review_text\"])\n",
        "X_padded = pad_sequences(sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")\n",
        "\n",
        "# Predict sentiment probabilities\n",
        "Y_pred_probs = best_bilstm_model.predict(X_padded)\n",
        "\n",
        "# Convert probabilities to class labels (argmax for multi-class)\n",
        "Y_pred = Y_pred_probs.argmax(axis=1)  # 0: Negative, 1: Neutral, 2: Positive\n",
        "\n",
        "# Map predictions to labels\n",
        "sentiment_labels = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
        "df[\"Predicted_Sentiment\"] = [sentiment_labels[label] for label in Y_pred]\n",
        "\n",
        "# Split data by store\n",
        "stores = [\"Fry's\", \"Safeway\", \"Target\", \"Trader Joe's\"]\n",
        "store_dfs = {store: df[df[\"name\"] == store] for store in stores}\n",
        "\n",
        "# Save sentiment-labeled datasets per store\n",
        "for store, store_df in store_dfs.items():\n",
        "    store_df.to_csv(f\"{store}_sentiment_labeled.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T03:53:25.218705Z",
          "iopub.status.busy": "2025-03-04T03:53:25.218358Z",
          "iopub.status.idle": "2025-03-04T03:53:25.844890Z",
          "shell.execute_reply": "2025-03-04T03:53:25.844316Z",
          "shell.execute_reply.started": "2025-03-04T03:53:25.218683Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "mzsdmh63P7w-"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Plot sentiment distribution per store (with percentage labels)\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, store in enumerate(store_dfs.keys()):\n",
        "    store_df = store_dfs[store]\n",
        "    sentiment_counts = store_df[\"Predicted_Sentiment\"].value_counts(normalize=True) * 100  # Convert to percentages\n",
        "\n",
        "    ax = sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values, palette=\"coolwarm\", ax=axes[i])\n",
        "    axes[i].set_title(f\"Sentiment Distribution - {store}\")\n",
        "    axes[i].set_xlabel(\"Sentiment\")\n",
        "    axes[i].set_ylabel(\"Percentage\")\n",
        "\n",
        "    # Adding percentage labels on bars\n",
        "    for p in ax.patches:\n",
        "        ax.annotate(f'{p.get_height():.1f}%', (p.get_x() + p.get_width() / 2, p.get_height()),\n",
        "                    ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FG8hQ2bzP7w-"
      },
      "source": [
        "---\n",
        "\n",
        "### 7.3 Sentiment Trend Over Time (Time Series Analysis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T03:53:30.354275Z",
          "iopub.status.busy": "2025-03-04T03:53:30.353955Z",
          "iopub.status.idle": "2025-03-04T03:53:31.083401Z",
          "shell.execute_reply": "2025-03-04T03:53:31.082779Z",
          "shell.execute_reply.started": "2025-03-04T03:53:30.354253Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "uABpPm2qP7w-"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Convert review_date to datetime format\n",
        "df[\"review_date\"] = pd.to_datetime(df[\"review_date\"])\n",
        "\n",
        "# Aggregate sentiment counts over time (monthly)\n",
        "df[\"month\"] = df[\"review_date\"].dt.to_period(\"M\")  # Convert to month format\n",
        "\n",
        "# Plot sentiment trends per store\n",
        "plt.figure(figsize=(12, 6))\n",
        "for store in stores:\n",
        "    store_df = df[df[\"name\"] == store]\n",
        "    sentiment_trend = store_df.groupby([\"month\", \"Predicted_Sentiment\"]).size().unstack()\n",
        "    sentiment_trend.plot(kind=\"line\", marker=\"o\", title=f\"Sentiment Trend - {store}\")\n",
        "    plt.xlabel(\"Month\")\n",
        "    plt.ylabel(\"Review Count\")\n",
        "    plt.legend(title=\"Sentiment\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2pb2FeHP7w-"
      },
      "source": [
        "---\n",
        "\n",
        "### 7.4 Word Cloud for Each Sentiment Category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T03:53:35.513251Z",
          "iopub.status.busy": "2025-03-04T03:53:35.512878Z",
          "iopub.status.idle": "2025-03-04T03:53:43.233850Z",
          "shell.execute_reply": "2025-03-04T03:53:43.233259Z",
          "shell.execute_reply.started": "2025-03-04T03:53:35.513228Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "rPuV9CytP7w-"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define stores\n",
        "stores = [\"Fry's\", \"Safeway\", \"Target\", \"Trader Joe's\"]\n",
        "\n",
        "# Generate word clouds for each sentiment within each store\n",
        "for store in stores:\n",
        "    store_df = df[df[\"name\"] == store]  # Filter data for the specific store\n",
        "\n",
        "    for sentiment in [\"Positive\", \"Neutral\", \"Negative\"]:\n",
        "        text = \" \".join(store_df[store_df[\"Predicted_Sentiment\"] == sentiment][\"review_text\"])\n",
        "\n",
        "        if text.strip():  # Only generate word cloud if text is available\n",
        "            wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(text)\n",
        "\n",
        "            # Plot\n",
        "            plt.figure(figsize=(10, 5))\n",
        "            plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "            plt.axis(\"off\")\n",
        "            plt.title(f\"Word Cloud - {sentiment} Reviews ({store})\")\n",
        "            plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mldQyqTP7w-"
      },
      "source": [
        "---\n",
        "\n",
        "### 7.5 Predicting Future Store Ratings Using Past Sentiment Trends"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T03:53:46.176513Z",
          "iopub.status.busy": "2025-03-04T03:53:46.176210Z",
          "iopub.status.idle": "2025-03-04T03:53:48.336577Z",
          "shell.execute_reply": "2025-03-04T03:53:48.335855Z",
          "shell.execute_reply.started": "2025-03-04T03:53:46.176494Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "WON0yLz4P7w-"
      },
      "outputs": [],
      "source": [
        "!pip install prophet\n",
        "from prophet import Prophet\n",
        "\n",
        "# Convert review_date to datetime\n",
        "df[\"review_date\"] = pd.to_datetime(df[\"review_date\"])\n",
        "df[\"month\"] = df[\"review_date\"].dt.to_period(\"M\").astype(str)\n",
        "\n",
        "# Aggregate sentiment scores over time\n",
        "df[\"sentiment_score\"] = df[\"Predicted_Sentiment\"].map({\"Negative\": -1, \"Neutral\": 0, \"Positive\": 1})\n",
        "monthly_sentiment = df.groupby(\"month\")[\"sentiment_score\"].mean().reset_index()\n",
        "\n",
        "# Prepare data for Prophet model\n",
        "monthly_sentiment.columns = [\"ds\", \"y\"]  # Prophet requires column names 'ds' (date) and 'y' (value)\n",
        "\n",
        "# Train Prophet model\n",
        "model = Prophet()\n",
        "model.fit(monthly_sentiment)\n",
        "\n",
        "# Make future predictions\n",
        "future = model.make_future_dataframe(periods=6, freq=\"M\")  # Predict next 6 months\n",
        "forecast = model.predict(future)\n",
        "\n",
        "# Plot forecast\n",
        "model.plot(forecast)\n",
        "plt.title(\"Predicted Sentiment Trend for Future Months\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T03:53:51.412526Z",
          "iopub.status.busy": "2025-03-04T03:53:51.412191Z",
          "iopub.status.idle": "2025-03-04T03:53:52.666122Z",
          "shell.execute_reply": "2025-03-04T03:53:52.665426Z",
          "shell.execute_reply.started": "2025-03-04T03:53:51.412503Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "8Yy_HFR9P7w-"
      },
      "outputs": [],
      "source": [
        "from prophet import Prophet\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Convert review_date to datetime\n",
        "df[\"review_date\"] = pd.to_datetime(df[\"review_date\"])\n",
        "df[\"month\"] = df[\"review_date\"].dt.to_period(\"M\").astype(str)\n",
        "\n",
        "# Map sentiment labels to numeric scores\n",
        "df[\"sentiment_score\"] = df[\"Predicted_Sentiment\"].map({\"Negative\": -1, \"Neutral\": 0, \"Positive\": 1})\n",
        "\n",
        "# Define store names\n",
        "stores = [\"Fry's\", \"Safeway\", \"Target\", \"Trader Joe's\"]\n",
        "\n",
        "# Define colors for actual and predicted trends\n",
        "actual_color = \"blue\"\n",
        "predicted_color = \"red\"\n",
        "\n",
        "# Initialize figure for multiple plots\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "# Loop through each store\n",
        "for i, store in enumerate(stores):\n",
        "    store_df = df[df[\"name\"] == store]  # Filter data for store\n",
        "    monthly_sentiment = store_df.groupby(\"month\")[\"sentiment_score\"].mean().reset_index()\n",
        "\n",
        "    # Convert 'ds' column to datetime format for Prophet\n",
        "    monthly_sentiment[\"month\"] = pd.to_datetime(monthly_sentiment[\"month\"])\n",
        "    monthly_sentiment.columns = [\"ds\", \"y\"]\n",
        "\n",
        "    # Train Prophet model\n",
        "    model = Prophet()\n",
        "    model.fit(monthly_sentiment)\n",
        "\n",
        "    # Predict next 6 months\n",
        "    future = model.make_future_dataframe(periods=6, freq=\"M\")\n",
        "\n",
        "    # Ensure future 'ds' is in datetime format\n",
        "    future[\"ds\"] = pd.to_datetime(future[\"ds\"])\n",
        "\n",
        "    forecast = model.predict(future)\n",
        "\n",
        "    # Ensure forecast 'ds' is also in datetime format\n",
        "    forecast[\"ds\"] = pd.to_datetime(forecast[\"ds\"])\n",
        "\n",
        "    # Plot results\n",
        "    axes[i].plot(monthly_sentiment[\"ds\"], monthly_sentiment[\"y\"], marker=\"o\", linestyle=\"-\", color=actual_color, label=\"Actual Sentiment Trend\")\n",
        "    axes[i].plot(forecast[\"ds\"], forecast[\"yhat\"], linestyle=\"dashed\", color=predicted_color, label=\"Predicted Trend\")\n",
        "\n",
        "    # Formatting\n",
        "    axes[i].set_title(f\"Sentiment Forecast for {store}\")\n",
        "    axes[i].set_xlabel(\"Month\")\n",
        "    axes[i].set_ylabel(\"Average Sentiment Score\")\n",
        "    axes[i].legend()\n",
        "    axes[i].tick_params(axis=\"x\", rotation=45)\n",
        "\n",
        "# Adjust layout and display\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QB65w-K0P7w-"
      },
      "source": [
        "1. Fry’s Sentiment Analysis\n",
        "- The actual sentiment fluctuates drastically, showing extreme positive and negative spikes.\n",
        "- The predicted sentiment trend shows a more stable decline over time.\n",
        "- Sentiment volatility suggests that customer experiences have been inconsistent over time.\n",
        "- There could be seasonal changes or external factors affecting sentiment at different times.\n",
        "- The trend suggests a potential decline in positive reviews over the years.\n",
        "    \n",
        "Potential Business Insight:\n",
        "\n",
        "- Fry’s may need to analyze periods with extreme negative sentiment to identify specific causes (e.g., product availability, service issues).\n",
        "- Addressing customer pain points during periods of sentiment dips could help improve long-term perception.\n",
        "    \n",
        "2. Safeway Sentiment Analysis\n",
        "- The actual sentiment is also highly volatile, similar to Fry’s.\n",
        "- The predicted trend suggests an upward movement followed by a gradual decline.\n",
        "- While positive sentiment dominates, there are multiple deep negative spikes.\n",
        "- A recurrent pattern of fluctuations indicates that customer satisfaction is not stable over time.\n",
        "    \n",
        "Potential Business Insight:\n",
        "\n",
        "- Safeway should focus on periods where negative sentiment increased to analyze customer complaints.\n",
        "- Loyalty programs or quality assurance initiatives could help maintain consistent positive sentiment.\n",
        "    \n",
        "3. Target Sentiment Analysis\n",
        "- The predicted sentiment trend is relatively stable and leans towards positivity.\n",
        "- However, actual sentiment data shows major drops in certain timeframes.\n",
        "- Unlike Fry’s and Safeway, Target appears to have a relatively higher baseline sentiment, meaning more positive reviews overall.\n",
        "- The negative dips could correspond to specific events like policy changes, product issues, or economic downturns.\n",
        "    \n",
        "Potential Business Insight:\n",
        "\n",
        "- Target has a stronger positive sentiment base, but needs to focus on periods of major sentiment drops.\n",
        "- Investigating key timeframes where customer dissatisfaction spiked can help prevent similar future occurrences.\n",
        "    \n",
        "4. Trader Joe’s Sentiment Analysis\n",
        "- Trader Joe’s has the most consistently positive sentiment trend among all stores.\n",
        "- The predicted sentiment trend remains stable, showing that customers generally have a positive experience.\n",
        "- The actual sentiment trend has occasional dips but remains largely positive over the years.\n",
        "- This indicates strong brand loyalty and a high level of customer satisfaction.\n",
        "    \n",
        "Potential Business Insight:\n",
        "\n",
        "- Trader Joe’s should maintain their current customer service and product quality.\n",
        "- Identifying what drives loyalty and ensuring high-quality customer engagement can help sustain this strong sentiment trend.\n",
        "- Periodic analysis of the negative dips can help improve operational efficiencies.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGFsWl1FP7w-"
      },
      "source": [
        "---\n",
        "\n",
        "### 7.6 Sentiment Comparison Across Stores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T03:53:56.886565Z",
          "iopub.status.busy": "2025-03-04T03:53:56.886230Z",
          "iopub.status.idle": "2025-03-04T03:53:57.060586Z",
          "shell.execute_reply": "2025-03-04T03:53:57.059981Z",
          "shell.execute_reply.started": "2025-03-04T03:53:56.886545Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "RndmZxq6P7w-"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Create a pivot table for heatmap\n",
        "heatmap_data = df.pivot_table(index=\"name\", columns=\"Predicted_Sentiment\", aggfunc=\"size\", fill_value=0)\n",
        "\n",
        "# Normalize by row (percentage per store)\n",
        "heatmap_data = heatmap_data.div(heatmap_data.sum(axis=1), axis=0) * 100\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(heatmap_data, annot=True, fmt=\".1f\", cmap=\"coolwarm\")\n",
        "plt.title(\"Sentiment Comparison Across Stores\")\n",
        "plt.xlabel(\"Sentiment\")\n",
        "plt.ylabel(\"Store\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-02T08:46:07.209369Z",
          "iopub.status.busy": "2025-03-02T08:46:07.209042Z",
          "iopub.status.idle": "2025-03-02T08:46:07.216752Z",
          "shell.execute_reply": "2025-03-02T08:46:07.216061Z",
          "shell.execute_reply.started": "2025-03-02T08:46:07.209343Z"
        },
        "id": "Jl6qIlvgP7w-"
      },
      "source": [
        "1. Fry’s Sentiment Distribution\n",
        "- Negative Sentiment: 26.8% – Fry’s has a relatively high level of dissatisfaction among customers compared to other stores.\n",
        "- Neutral Sentiment: 0.8% – Very few reviews are neutral, indicating strong polarizing opinions.\n",
        "- Positive Sentiment: 72.5% – Although a majority of reviews are positive, the lower positivity compared to Target and Trader Joe’s signals potential areas for improvement.\n",
        "- Business Insight: Fry’s needs to analyze recurring customer complaints and focus on service improvements to reduce the high proportion of negative reviews. Operational inefficiencies, product availability, or customer service issues could be contributing to the dissatisfaction.\n",
        "\n",
        "2. Safeway Sentiment Distribution\n",
        "- Negative Sentiment: 22.4% – Slightly lower negative sentiment than Fry’s but still significant.\n",
        "- Neutral Sentiment: 1.2% – Minimal neutral responses, indicating strong customer opinions.\n",
        "- Positive Sentiment: 76.4% – Higher customer satisfaction compared to Fry’s but lower than Trader Joe’s and Target.\n",
        "- Business Insight: Safeway has a relatively strong brand reputation but should focus on reducing negative sentiment further. Addressing customer complaints related to product quality, pricing, or service delays could help improve brand perception.\n",
        "\n",
        "3. Target Sentiment Distribution\n",
        "- Negative Sentiment: 16.4% – The lowest among Fry’s and Safeway, showing better customer satisfaction.\n",
        "- Neutral Sentiment: 0.7% – Very few neutral responses.\n",
        "- Positive Sentiment: 83.0% – High customer satisfaction, showing that Target maintains a strong customer experience and service standards.\n",
        "- Business Insight: Target stands out with high positive sentiment, reflecting strong customer loyalty. However, addressing the remaining 16.4% negative sentiment could further enhance its reputation.\n",
        "\n",
        "4. Trader Joe’s Sentiment Distribution\n",
        "- Negative Sentiment: 6.0% – The lowest among all stores, indicating an overwhelmingly positive reputation.\n",
        "- Neutral Sentiment: 0.6% – Very few neutral responses, meaning customers either love or dislike their experience.\n",
        "- Positive Sentiment: 93.4% – The highest customer satisfaction, showing strong brand loyalty and an exceptional shopping experience.\n",
        "- Business Insight: Trader Joe’s has an outstanding customer approval rating, which could be linked to its niche product selection, customer service, and unique shopping experience. Maintaining consistent quality and service will be key to sustaining this strong reputation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxGQGZhvP7w-"
      },
      "source": [
        "---\n",
        "\n",
        "# 8. Topic Modeling using BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T03:54:01.065229Z",
          "iopub.status.busy": "2025-03-04T03:54:01.064876Z",
          "iopub.status.idle": "2025-03-04T03:55:51.373924Z",
          "shell.execute_reply": "2025-03-04T03:55:51.373285Z",
          "shell.execute_reply.started": "2025-03-04T03:54:01.065207Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "hiCPw-4tP7w-"
      },
      "outputs": [],
      "source": [
        "# Install required packages if not installed\n",
        "!pip install bertopic umap-learn hdbscan wordcloud matplotlib seaborn pandas\n",
        "\n",
        "from bertopic import BERTopic\n",
        "from umap import UMAP\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "\n",
        "# Ensure 'date' column is converted to datetime format\n",
        "if \"date\" in df.columns:\n",
        "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
        "    df[\"month\"] = df[\"date\"].dt.to_period(\"M\")  # Convert date to monthly period for trend analysis\n",
        "\n",
        "# List of grocery stores\n",
        "stores = [\"Fry's\", \"Safeway\", \"Target\", \"Trader Joe's\"]\n",
        "\n",
        "# Dictionary to store topic models and results\n",
        "topic_models = {}\n",
        "topic_results = {}\n",
        "\n",
        "# Loop through each store and apply BERTopic\n",
        "for store in stores:\n",
        "    print(f\"\\nProcessing Topic Modeling for {store}...\")\n",
        "\n",
        "    # Filter reviews for the store\n",
        "    store_reviews = df[df[\"name\"] == store][\"review_text\"].dropna().tolist()\n",
        "\n",
        "    if len(store_reviews) < 10:\n",
        "        print(f\" Not enough reviews for {store}, skipping topic modeling.\\n\")\n",
        "        continue  # Skip stores with insufficient reviews\n",
        "\n",
        "    # Reduce dimensions for effective clustering\n",
        "    umap_model = UMAP(n_neighbors=15, n_components=5, metric='cosine', random_state=42)\n",
        "\n",
        "    # Initialize BERTopic model\n",
        "    topic_model = BERTopic(language=\"english\", umap_model=umap_model)\n",
        "\n",
        "    # Fit and transform the model\n",
        "    topics, probs = topic_model.fit_transform(store_reviews)\n",
        "\n",
        "    # Store results\n",
        "    topic_models[store] = topic_model\n",
        "    topic_results[store] = topics\n",
        "\n",
        "    # Display top topics\n",
        "    print(f\" Top Topics for {store}:\")\n",
        "    print(topic_model.get_topic_info().head())\n",
        "\n",
        "    # ** Visualize Top Words in Each Topic (Bar Chart)**\n",
        "    fig1 = topic_model.visualize_barchart(top_n_topics=10)\n",
        "    fig1.show()\n",
        "\n",
        "    # ** Generate Word Clouds for Top Topics**\n",
        "    fig, axes = plt.subplots(3, 3, figsize=(15, 10))\n",
        "    for i, ax in enumerate(axes.flatten()):\n",
        "        if i >= len(topic_model.get_topic_info()):\n",
        "            break  # Avoid extra empty topics\n",
        "        words_freq = dict(topic_model.get_topic(i))\n",
        "        wordcloud = WordCloud(width=400, height=400, background_color='white').generate_from_frequencies(words_freq)\n",
        "        ax.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "        ax.set_title(f\"Topic {i} - {store}\")\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # **Intertopic Distance Map**\n",
        "    topic_model.visualize_topics()\n",
        "\n",
        "    # **Sentiment-Based Topic Analysis**\n",
        "    if \"rating\" in df.columns:\n",
        "        df[\"sentiment\"] = df[\"rating\"].apply(lambda x: \"positive\" if x >= 4 else \"negative\")\n",
        "\n",
        "        # Add topic assignments to the dataframe\n",
        "        store_df = df[df[\"name\"] == store].copy()\n",
        "        store_df[\"topic\"] = topics\n",
        "\n",
        "        # Count topics for positive and negative reviews\n",
        "        topic_counts = store_df.groupby([\"topic\", \"sentiment\"]).size().unstack().fillna(0)\n",
        "\n",
        "        # Plot topic distribution\n",
        "        topic_counts.plot(kind=\"bar\", stacked=True, figsize=(12, 6), colormap=\"coolwarm\")\n",
        "        plt.title(f\"Topic Distribution among Positive & Negative Reviews for {store}\")\n",
        "        plt.xlabel(\"Topics\")\n",
        "        plt.ylabel(\"Number of Reviews\")\n",
        "        plt.legend([\"Negative\", \"Positive\"])\n",
        "        plt.show()\n",
        "\n",
        "    # **Optimized Time-Based Topic Trend Analysis**\n",
        "    if \"month\" in df.columns:\n",
        "        try:\n",
        "            print(f\"Processing time-based topic analysis for {store}...\")\n",
        "\n",
        "            # Filter store-specific data\n",
        "            store_df = df[df[\"name\"] == store].copy()\n",
        "\n",
        "            # Drop any rows where 'month' is missing\n",
        "            store_df = store_df.dropna(subset=[\"month\"])\n",
        "\n",
        "            # Ensure there are multiple unique months\n",
        "            if store_df[\"month\"].nunique() > 5:  # Requires at least 5 unique months\n",
        "                print(f\"Found {store_df['month'].nunique()} unique months for {store}, proceeding with time-based trends...\")\n",
        "\n",
        "                # Extract topics over time with reduced bins for performance\n",
        "                topics_over_time = topic_model.topics_over_time(\n",
        "                    store_df[\"review_text\"].tolist(),\n",
        "                    store_df[\"month\"].astype(str).tolist(),  # Convert to string format to prevent errors\n",
        "                    nr_bins=20  # Adjust to optimize performance\n",
        "                )\n",
        "\n",
        "                # Visualize topics evolving over time\n",
        "                topic_model.visualize_topics_over_time(topics_over_time).show()\n",
        "            else:\n",
        "                print(f\" Not enough month variability for {store} ({store_df['month'].nunique()} unique months), skipping time-based topic trends.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌Error in time-based topic analysis for {store}: {e}\")\n",
        "\n",
        "    print(f\"✅ Completed Topic Modeling for {store}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T03:55:51.375325Z",
          "iopub.status.busy": "2025-03-04T03:55:51.375043Z",
          "iopub.status.idle": "2025-03-04T03:55:51.390899Z",
          "shell.execute_reply": "2025-03-04T03:55:51.390372Z",
          "shell.execute_reply.started": "2025-03-04T03:55:51.375304Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "aMvtfNWZP7w_"
      },
      "outputs": [],
      "source": [
        "# Display top topics\n",
        "topic_model.get_topic_info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T03:55:57.698494Z",
          "iopub.status.busy": "2025-03-04T03:55:57.698160Z",
          "iopub.status.idle": "2025-03-04T03:55:58.461809Z",
          "shell.execute_reply": "2025-03-04T03:55:58.461215Z",
          "shell.execute_reply.started": "2025-03-04T03:55:57.698474Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "Ymid6vFdP7w_"
      },
      "outputs": [],
      "source": [
        "# Prepare topic distribution data\n",
        "topic_distribution = {}\n",
        "for store, topics in topic_results.items():\n",
        "    topic_distribution[store] = pd.Series(topics).value_counts()\n",
        "\n",
        "# Convert to DataFrame for plotting\n",
        "topic_df = pd.DataFrame(topic_distribution).fillna(0)\n",
        "\n",
        "# Plot topic distribution across stores\n",
        "plt.figure(figsize=(12, 6))\n",
        "topic_df.plot(kind='bar', stacked=True, colormap='viridis', figsize=(14,6))\n",
        "plt.title(\"Topic Distribution Across Grocery Stores\")\n",
        "plt.xlabel(\"Topic Number\")\n",
        "plt.ylabel(\"Number of Reviews\")\n",
        "plt.legend(title=\"Store\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T03:56:03.758217Z",
          "iopub.status.busy": "2025-03-04T03:56:03.757896Z",
          "iopub.status.idle": "2025-03-04T03:56:03.798740Z",
          "shell.execute_reply": "2025-03-04T03:56:03.798183Z",
          "shell.execute_reply.started": "2025-03-04T03:56:03.758196Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "Ttgxv5aXP7w_"
      },
      "outputs": [],
      "source": [
        "# Combine topics from all stores\n",
        "all_topics = {}\n",
        "\n",
        "for store, model in topic_models.items():\n",
        "    all_topics[store] = model.get_topic_info().head(6)  # Get top 6 topics\n",
        "\n",
        "# Convert to DataFrame for easy comparison\n",
        "topic_comparison_df = pd.concat(all_topics, axis=1)\n",
        "\n",
        "# Display results\n",
        "import IPython.display as display\n",
        "display.display(topic_comparison_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T03:56:06.586260Z",
          "iopub.status.busy": "2025-03-04T03:56:06.585933Z",
          "iopub.status.idle": "2025-03-04T03:56:06.765570Z",
          "shell.execute_reply": "2025-03-04T03:56:06.764976Z",
          "shell.execute_reply.started": "2025-03-04T03:56:06.586236Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "Eg0ARjSvP7w_"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Count positive vs. negative reviews per store\n",
        "sentiment_counts = df.groupby([\"name\", \"sentiment\"]).size().unstack().fillna(0)\n",
        "\n",
        "# Plot sentiment distribution across stores\n",
        "plt.figure(figsize=(10, 5))\n",
        "sentiment_counts.plot(kind=\"bar\", stacked=True, colormap=\"coolwarm\", figsize=(10, 6))\n",
        "plt.title(\"Sentiment Comparison Across Stores\")\n",
        "plt.xlabel(\"Store Name\")\n",
        "plt.ylabel(\"Number of Reviews\")\n",
        "plt.legend([\"Negative\", \"Positive\"])\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T03:56:09.296581Z",
          "iopub.status.busy": "2025-03-04T03:56:09.296022Z",
          "iopub.status.idle": "2025-03-04T03:56:15.179736Z",
          "shell.execute_reply": "2025-03-04T03:56:15.179205Z",
          "shell.execute_reply.started": "2025-03-04T03:56:09.296560Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "VovVQMg_P7w_"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Ensure sentiment labels are correctly assigned\n",
        "if \"rating\" in df.columns:\n",
        "    df[\"sentiment\"] = df[\"rating\"].apply(lambda x: \"positive\" if x >= 4 else \"negative\")\n",
        "\n",
        "# List of grocery stores\n",
        "stores = [\"Fry's\", \"Safeway\", \"Target\", \"Trader Joe's\"]\n",
        "\n",
        "# Loop through each store and generate word clouds\n",
        "for store in stores:\n",
        "    print(f\"\\n🔍 Generating word clouds for {store}...\")\n",
        "\n",
        "    # Filter positive and negative reviews for the store\n",
        "    positive_reviews = df[(df[\"name\"] == store) & (df[\"sentiment\"] == \"positive\")][\"review_text\"].dropna()\n",
        "    negative_reviews = df[(df[\"name\"] == store) & (df[\"sentiment\"] == \"negative\")][\"review_text\"].dropna()\n",
        "\n",
        "    # Combine text for word clouds\n",
        "    positive_text = \" \".join(positive_reviews)\n",
        "    negative_text = \" \".join(negative_reviews)\n",
        "\n",
        "    # Generate word clouds\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "    # Positive word cloud\n",
        "    wordcloud_positive = WordCloud(width=600, height=400, background_color=\"white\").generate(positive_text)\n",
        "    axes[0].imshow(wordcloud_positive, interpolation=\"bilinear\")\n",
        "    axes[0].set_title(f\"Positive Reviews - {store}\")\n",
        "    axes[0].axis(\"off\")\n",
        "\n",
        "    # Negative word cloud\n",
        "    wordcloud_negative = WordCloud(width=600, height=400, background_color=\"black\", colormap=\"Reds\").generate(negative_text)\n",
        "    axes[1].imshow(wordcloud_negative, interpolation=\"bilinear\")\n",
        "    axes[1].set_title(f\"Negative Reviews - {store}\")\n",
        "    axes[1].axis(\"off\")\n",
        "\n",
        "    # Display word clouds\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T03:58:08.675192Z",
          "iopub.status.busy": "2025-03-04T03:58:08.674857Z",
          "iopub.status.idle": "2025-03-04T03:58:12.078486Z",
          "shell.execute_reply": "2025-03-04T03:58:12.077912Z",
          "shell.execute_reply.started": "2025-03-04T03:58:08.675171Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "uo1PGp5nP7w_"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Prepare data\n",
        "X = df[\"review_text\"].dropna()\n",
        "y = df[\"sentiment\"].dropna()\n",
        "\n",
        "# Convert text into TF-IDF features\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_tfidf = vectorizer.fit_transform(X)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Random Forest classifier\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T03:58:15.558531Z",
          "iopub.status.busy": "2025-03-04T03:58:15.558208Z",
          "iopub.status.idle": "2025-03-04T03:58:15.589904Z",
          "shell.execute_reply": "2025-03-04T03:58:15.589366Z",
          "shell.execute_reply.started": "2025-03-04T03:58:15.558512Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "WZ0c1gBkP7w_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a report dictionary\n",
        "report_data = []\n",
        "\n",
        "for store in stores:\n",
        "    if store in topic_models:\n",
        "        # Get top 6 topics\n",
        "        top_topics = topic_models[store].get_topic_info().head(6)\n",
        "        sentiment_distribution = df[df[\"name\"] == store][\"sentiment\"].value_counts()\n",
        "\n",
        "        report_data.append({\n",
        "            \"Store\": store,\n",
        "            \"Top Topics\": top_topics[\"Name\"].tolist(),\n",
        "            \"Positive Reviews\": sentiment_distribution.get(\"positive\", 0),\n",
        "            \"Negative Reviews\": sentiment_distribution.get(\"negative\", 0)\n",
        "        })\n",
        "\n",
        "# Convert report to DataFrame\n",
        "report_df = pd.DataFrame(report_data)\n",
        "\n",
        "# Display to user\n",
        "display.display(report_df )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T03:58:18.174446Z",
          "iopub.status.busy": "2025-03-04T03:58:18.174123Z",
          "iopub.status.idle": "2025-03-04T03:58:20.881239Z",
          "shell.execute_reply": "2025-03-04T03:58:20.880665Z",
          "shell.execute_reply.started": "2025-03-04T03:58:18.174427Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "MBtrkYb1P7w_"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Improved visualization for better readability\n",
        "for store in stores:\n",
        "    topic_info = topic_models[store].get_topic_info()\n",
        "\n",
        "    # Filter out the outlier topic \"-1\" (which represents outliers in BERTopic)\n",
        "    topic_info = topic_info[topic_info[\"Topic\"] != -1]\n",
        "\n",
        "    # Sort topics by frequency\n",
        "    topic_info = topic_info.sort_values(by=\"Count\", ascending=False).head(15)  # Show top 15 topics for better clarity\n",
        "\n",
        "    topic_counts = topic_info[\"Count\"].values\n",
        "    topic_labels = [f\"Topic {i}\" for i in topic_info[\"Topic\"].values]\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.barplot(x=topic_counts, y=topic_labels, palette=\"coolwarm\")\n",
        "    plt.xlabel(\"Number of Reviews\")\n",
        "    plt.ylabel(\"Topics\")\n",
        "    plt.title(f\"Top 15 Topic Distribution for {store}\")\n",
        "\n",
        "    # Show topic labels clearly\n",
        "    for index, value in enumerate(topic_counts):\n",
        "        plt.text(value + 1, index, str(value), va='center', fontsize=10)\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T03:58:21.148037Z",
          "iopub.status.busy": "2025-03-04T03:58:21.147742Z",
          "iopub.status.idle": "2025-03-04T03:58:21.167249Z",
          "shell.execute_reply": "2025-03-04T03:58:21.166681Z",
          "shell.execute_reply.started": "2025-03-04T03:58:21.148017Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "-ll_fznGP7w_"
      },
      "outputs": [],
      "source": [
        "# Extract top keywords for each topic per store\n",
        "for store in stores:\n",
        "    topic_info = topic_models[store].get_topic_info()\n",
        "\n",
        "    # Remove outlier topic (-1)\n",
        "    topic_info = topic_info[topic_info[\"Topic\"] != -1]\n",
        "\n",
        "    print(f\"\\nTop Keywords for {store}:\")\n",
        "    for topic in topic_info[\"Topic\"].values[:10]:  # Show top 10 topics\n",
        "        keywords = topic_models[store].get_topic(topic)\n",
        "        keyword_list = [word for word, _ in keywords[:10]]  # Get top 10 keywords\n",
        "        print(f\"Topic {topic}: {', '.join(keyword_list)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T03:58:23.998539Z",
          "iopub.status.busy": "2025-03-04T03:58:23.998206Z",
          "iopub.status.idle": "2025-03-04T03:59:11.160884Z",
          "shell.execute_reply": "2025-03-04T03:59:11.160125Z",
          "shell.execute_reply.started": "2025-03-04T03:58:23.998519Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "4vrKLv6lP7w_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame to store topic sentiment distribution for each store\n",
        "topic_sentiment_distribution = []\n",
        "\n",
        "for store in stores:\n",
        "    store_df = store_dfs[store]\n",
        "\n",
        "    # Assign topics to reviews\n",
        "    topics_per_review = topic_models[store].transform(store_df[\"review_text\"].tolist())[0]\n",
        "\n",
        "    # Assign topics to the store dataframe\n",
        "    store_df[\"Topic\"] = topics_per_review\n",
        "\n",
        "    # Remove outlier topics (-1)\n",
        "    store_df = store_df[store_df[\"Topic\"] != -1]\n",
        "\n",
        "    # Count sentiment distribution per topic\n",
        "    topic_sentiment_counts = store_df.groupby([\"Topic\", \"Predicted_Sentiment\"]).size().unstack(fill_value=0)\n",
        "\n",
        "    # Convert to percentage format\n",
        "    topic_sentiment_percentages = topic_sentiment_counts.div(topic_sentiment_counts.sum(axis=1), axis=0) * 100\n",
        "\n",
        "    # Store results\n",
        "    for topic, row in topic_sentiment_percentages.iterrows():\n",
        "        topic_sentiment_distribution.append({\n",
        "            \"Store\": store,\n",
        "            \"Topic\": topic,\n",
        "            \"Negative (%)\": round(row.get(\"Negative\", 0), 2),\n",
        "            \"Neutral (%)\": round(row.get(\"Neutral\", 0), 2),\n",
        "            \"Positive (%)\": round(row.get(\"Positive\", 0), 2),\n",
        "        })\n",
        "\n",
        "# Convert to DataFrame for better readability\n",
        "topic_sentiment_df = pd.DataFrame(topic_sentiment_distribution)\n",
        "\n",
        "# Display DataFrame\n",
        "import IPython.display as display\n",
        "display.display(topic_sentiment_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T03:59:15.876491Z",
          "iopub.status.busy": "2025-03-04T03:59:15.876154Z",
          "iopub.status.idle": "2025-03-04T03:59:15.898688Z",
          "shell.execute_reply": "2025-03-04T03:59:15.898087Z",
          "shell.execute_reply.started": "2025-03-04T03:59:15.876470Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "utrAxN75P7w_"
      },
      "outputs": [],
      "source": [
        "# Extract top keywords for each store's topics\n",
        "topic_keywords = {}\n",
        "\n",
        "for store in stores:\n",
        "    print(f\"Extracting top keywords for {store}...\")\n",
        "\n",
        "    # Get the most important words per topic\n",
        "    topic_info = topic_models[store].get_topic_info()\n",
        "    top_topics = topic_info[['Topic', 'Name']].head(10)  # Extract top 10 topics\n",
        "\n",
        "    # Store in dictionary\n",
        "    topic_keywords[store] = top_topics\n",
        "\n",
        "    print(f\"Extracted top topics for {store}\")\n",
        "\n",
        "# Display results\n",
        "import pandas as pd\n",
        "for store, topics in topic_keywords.items():\n",
        "    print(f\"\\n🔹 **Top Topics for {store}**\")\n",
        "    print(topics.to_string(index=False))  # Display neatly formatted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T03:59:25.396562Z",
          "iopub.status.busy": "2025-03-04T03:59:25.396125Z",
          "iopub.status.idle": "2025-03-04T03:59:25.423123Z",
          "shell.execute_reply": "2025-03-04T03:59:25.422554Z",
          "shell.execute_reply.started": "2025-03-04T03:59:25.396540Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "t76-WL_zP7w_"
      },
      "outputs": [],
      "source": [
        "# Create dictionary to store sentiment distribution per topic\n",
        "topic_sentiments = {}\n",
        "\n",
        "for store in stores:\n",
        "    print(f\"Analyzing sentiment distribution for {store}...\")\n",
        "\n",
        "    # Merge topic assignments with predicted sentiments\n",
        "    store_df = store_dfs[store][['Predicted_Sentiment', 'cleaned_review_text']]\n",
        "    store_df['Topic'] = topic_models[store].topics_\n",
        "\n",
        "    # Count sentiment per topic\n",
        "    sentiment_distribution = store_df.groupby([\"Topic\", \"Predicted_Sentiment\"]).size().unstack(fill_value=0)\n",
        "\n",
        "    # Normalize to percentage\n",
        "    sentiment_distribution_percentage = sentiment_distribution.div(sentiment_distribution.sum(axis=1), axis=0) * 100\n",
        "\n",
        "    # Store in dictionary\n",
        "    topic_sentiments[store] = sentiment_distribution_percentage\n",
        "\n",
        "    print(f\"Completed sentiment analysis for {store}\")\n",
        "\n",
        "# Display results\n",
        "for store, sentiment_data in topic_sentiments.items():\n",
        "    print(f\"\\n **Sentiment Distribution by Topic for {store}**\")\n",
        "    print(sentiment_data.head(10).to_string())  # Display top 10 topics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T03:59:30.714245Z",
          "iopub.status.busy": "2025-03-04T03:59:30.713906Z",
          "iopub.status.idle": "2025-03-04T03:59:33.094904Z",
          "shell.execute_reply": "2025-03-04T03:59:33.094261Z",
          "shell.execute_reply.started": "2025-03-04T03:59:30.714223Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "scrolled": true,
        "id": "7bh9sEImP7w_"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for store, sentiment_data in topic_sentiments.items():\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.heatmap(sentiment_data.T, annot=True, fmt=\".1f\", cmap=\"coolwarm\")\n",
        "    plt.title(f\"Sentiment Distribution Across Topics - {store}\")\n",
        "    plt.xlabel(\"Topic\")\n",
        "    plt.ylabel(\"Sentiment\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T04:00:08.228690Z",
          "iopub.status.busy": "2025-03-04T04:00:08.228359Z",
          "iopub.status.idle": "2025-03-04T04:00:45.612926Z",
          "shell.execute_reply": "2025-03-04T04:00:45.612370Z",
          "shell.execute_reply.started": "2025-03-04T04:00:08.228670Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "o7eUcsOJP7w_"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import os\n",
        "\n",
        "# Ensure sentiment labels are correctly assigned\n",
        "if \"rating\" in df.columns:\n",
        "    df[\"sentiment\"] = df[\"rating\"].apply(lambda x: \"positive\" if x >= 4 else \"negative\")\n",
        "\n",
        "# List of grocery stores\n",
        "stores = [\"Fry's\", \"Safeway\", \"Target\", \"Trader Joe's\"]\n",
        "\n",
        "# Define product categories and associated keywords\n",
        "categories = {\n",
        "    \"Bakery\": [\"bread\", \"cake\", \"pastry\", \"bakery\", \"cookies\", \"doughnut\"],\n",
        "    \"Produce\": [\"fruits\", \"vegetables\", \"organic\", \"fresh\", \"produce\", \"greens\"],\n",
        "    \"Checkout Experience\": [\"cashier\", \"checkout\", \"register\", \"line\", \"self-checkout\"],\n",
        "    \"Deli\": [\"deli\", \"meat\", \"cheese\", \"sandwich\", \"sliced\"],\n",
        "    \"Customer Service\": [\"staff\", \"service\", \"employee\", \"rude\", \"helpful\", \"manager\"]\n",
        "}\n",
        "\n",
        "# Create output directory for word cloud images\n",
        "output_dir = \"store_category_wordclouds\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Custom stopwords for cleaner analysis\n",
        "custom_stopwords = set(STOPWORDS).union({\"store\", \"grocery\", \"food\", \"customer\", \"shop\", \"shopping\", \"buy\", \"purchase\"})\n",
        "\n",
        "# Dictionary to store word frequencies\n",
        "word_frequencies = {\"Store\": [], \"Category\": [], \"Sentiment\": [], \"Word\": [], \"Count\": []}\n",
        "\n",
        "# Function to get word frequencies\n",
        "def get_word_frequencies(text, store, category, sentiment):\n",
        "    words = text.lower().split()\n",
        "    words = [word for word in words if word not in custom_stopwords]\n",
        "    word_counts = Counter(words).most_common(10)  # Get top 10 words\n",
        "    for word, count in word_counts:\n",
        "        word_frequencies[\"Store\"].append(store)\n",
        "        word_frequencies[\"Category\"].append(category)\n",
        "        word_frequencies[\"Sentiment\"].append(sentiment)\n",
        "        word_frequencies[\"Word\"].append(word)\n",
        "        word_frequencies[\"Count\"].append(count)\n",
        "\n",
        "# Loop through each store and category\n",
        "for store in stores:\n",
        "    for category, keywords in categories.items():\n",
        "        print(f\"\\n🔍 Generating word clouds for {store} - {category}...\")\n",
        "\n",
        "        # Filter reviews mentioning category keywords & belonging to the store\n",
        "        category_reviews = df[(df[\"name\"] == store) & (df[\"review_text\"].str.contains('|'.join(keywords), case=False, na=False))]\n",
        "\n",
        "        # Separate positive and negative reviews\n",
        "        positive_reviews = category_reviews[category_reviews[\"sentiment\"] == \"positive\"][\"review_text\"].dropna()\n",
        "        negative_reviews = category_reviews[category_reviews[\"sentiment\"] == \"negative\"][\"review_text\"].dropna()\n",
        "\n",
        "        # Combine text for word clouds\n",
        "        positive_text = \" \".join(positive_reviews)\n",
        "        negative_text = \" \".join(negative_reviews)\n",
        "\n",
        "        # Generate word clouds\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "        # Positive word cloud\n",
        "        if positive_text.strip():\n",
        "            wordcloud_positive = WordCloud(width=600, height=400, background_color=\"white\", stopwords=custom_stopwords).generate(positive_text)\n",
        "            axes[0].imshow(wordcloud_positive, interpolation=\"bilinear\")\n",
        "        else:\n",
        "            axes[0].text(0.5, 0.5, \"No Positive Reviews\", fontsize=15, ha=\"center\", va=\"center\", bbox=dict(facecolor=\"white\", edgecolor=\"black\"))\n",
        "        axes[0].set_title(f\"Positive Reviews - {store} ({category})\")\n",
        "        axes[0].axis(\"off\")\n",
        "\n",
        "        # Negative word cloud\n",
        "        if negative_text.strip():\n",
        "            wordcloud_negative = WordCloud(width=600, height=400, background_color=\"black\", colormap=\"Reds\", stopwords=custom_stopwords).generate(negative_text)\n",
        "            axes[1].imshow(wordcloud_negative, interpolation=\"bilinear\")\n",
        "        else:\n",
        "            axes[1].text(0.5, 0.5, \"No Negative Reviews\", fontsize=15, ha=\"center\", va=\"center\", bbox=dict(facecolor=\"black\", edgecolor=\"red\", alpha=0.5), color=\"white\")\n",
        "        axes[1].set_title(f\"Negative Reviews - {store} ({category})\")\n",
        "        axes[1].axis(\"off\")\n",
        "\n",
        "        # Save images\n",
        "        positive_img_path = os.path.join(output_dir, f\"{store}_{category}_positive_wordcloud.png\")\n",
        "        negative_img_path = os.path.join(output_dir, f\"{store}_{category}_negative_wordcloud.png\")\n",
        "        plt.savefig(positive_img_path)\n",
        "        plt.savefig(negative_img_path)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"Word clouds saved for {store} - {category}:\")\n",
        "        print(f\"   - {positive_img_path}\")\n",
        "        print(f\"   - {negative_img_path}\")\n",
        "\n",
        "        # Compute word frequencies for positive and negative reviews\n",
        "        get_word_frequencies(positive_text, store, category, \"Positive\")\n",
        "        get_word_frequencies(negative_text, store, category, \"Negative\")\n",
        "\n",
        "# Convert word frequency dictionary to DataFrame\n",
        "word_freq_df = pd.DataFrame(word_frequencies)\n",
        "\n",
        "# Display word frequencies table\n",
        "# Display word frequencies table\n",
        "display.display(word_freq_df)\n",
        "\n",
        "print(\"\\n Category-based word frequency table saved as 'store_category_word_frequencies.xlsx'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T04:01:03.021606Z",
          "iopub.status.busy": "2025-03-04T04:01:03.021286Z",
          "iopub.status.idle": "2025-03-04T04:01:03.624747Z",
          "shell.execute_reply": "2025-03-04T04:01:03.624143Z",
          "shell.execute_reply.started": "2025-03-04T04:01:03.021586Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "WRMFmrynP7w_"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Select the category to compare (e.g., Bakery)\n",
        "selected_category = \"Bakery\"\n",
        "\n",
        "# Filter dataset for the selected category across all stores\n",
        "category_data = df[df[\"review_text\"].str.contains('|'.join(categories[selected_category]), case=False, na=False)]\n",
        "\n",
        "# Group by store and sentiment to count reviews\n",
        "store_comparison = category_data.groupby([\"name\", \"sentiment\"]).size().unstack().fillna(0)\n",
        "\n",
        "# Get average business_stars per store\n",
        "avg_ratings = df.groupby(\"name\")[\"business_stars\"].mean().round(2)\n",
        "\n",
        "# Create figure and axes\n",
        "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "# Bar chart for sentiment distribution\n",
        "store_comparison.plot(kind=\"bar\", stacked=True, colormap=\"coolwarm\", ax=ax1)\n",
        "ax1.set_title(f\"Comparison of '{selected_category}' Sentiment Across Stores (w/ Business Stars)\")\n",
        "ax1.set_xlabel(\"Store\")\n",
        "ax1.set_ylabel(\"Number of Reviews\")\n",
        "ax1.legend([\"Negative\", \"Positive\"])\n",
        "ax1.set_xticklabels(store_comparison.index, rotation=45)\n",
        "\n",
        "# Create second y-axis for business ratings\n",
        "ax2 = ax1.twinx()\n",
        "ax2.set_ylabel(\"Average Business Stars (Rating)\")\n",
        "\n",
        "# Scatter plot for business stars\n",
        "ax2.scatter(avg_ratings.index, avg_ratings.values, color=\"gold\", s=200, label=\"Avg Rating\", marker=\"*\")\n",
        "\n",
        "# Annotate ratings\n",
        "for store, rating in avg_ratings.items():\n",
        "    ax2.text(store, rating + 0.1, f\"{rating}★\", ha=\"center\", fontsize=12, color=\"gold\")\n",
        "\n",
        "ax2.set_ylim(0, 5)  # Set y-axis limit for ratings\n",
        "ax2.legend(loc=\"upper right\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T04:02:04.986310Z",
          "iopub.status.busy": "2025-03-04T04:02:04.985973Z",
          "iopub.status.idle": "2025-03-04T04:02:07.932011Z",
          "shell.execute_reply": "2025-03-04T04:02:07.931435Z",
          "shell.execute_reply.started": "2025-03-04T04:02:04.986289Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "1DeUE1RuP7w_"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define categories to compare\n",
        "selected_categories = [\"Bakery\", \"Produce\", \"Checkout Experience\", \"Deli\", \"Customer Service\"]\n",
        "\n",
        "# Create a subplot for each category\n",
        "fig, axes = plt.subplots(len(selected_categories), 1, figsize=(12, 5 * len(selected_categories)))\n",
        "\n",
        "for i, category in enumerate(selected_categories):\n",
        "    # Filter dataset for the category\n",
        "    category_data = df[df[\"review_text\"].str.contains('|'.join(categories[category]), case=False, na=False)]\n",
        "\n",
        "    # Group by store and sentiment to count reviews\n",
        "    store_comparison = category_data.groupby([\"name\", \"sentiment\"]).size().unstack().fillna(0)\n",
        "\n",
        "    # Get average business_stars per store\n",
        "    avg_ratings = df.groupby(\"name\")[\"business_stars\"].mean().round(2)\n",
        "\n",
        "    # Bar chart for sentiment distribution\n",
        "    store_comparison.plot(kind=\"bar\", stacked=True, colormap=\"coolwarm\", ax=axes[i])\n",
        "    axes[i].set_title(f\"'{category}' Sentiment Across Stores (w/ Business Stars)\")\n",
        "    axes[i].set_xlabel(\"Store\")\n",
        "    axes[i].set_ylabel(\"Number of Reviews\")\n",
        "    axes[i].legend([\"Negative\", \"Positive\"])\n",
        "    axes[i].set_xticklabels(store_comparison.index, rotation=45)\n",
        "\n",
        "    # Create second y-axis for business ratings\n",
        "    ax2 = axes[i].twinx()\n",
        "    ax2.set_ylabel(\"Average Business Stars (Rating)\")\n",
        "\n",
        "    # Scatter plot for business stars\n",
        "    ax2.scatter(avg_ratings.index, avg_ratings.values, color=\"gold\", s=200, label=\"Avg Rating\", marker=\"*\")\n",
        "\n",
        "    # Annotate ratings\n",
        "    for store, rating in avg_ratings.items():\n",
        "        ax2.text(store, rating + 0.1, f\"{rating}★\", ha=\"center\", fontsize=12, color=\"gold\")\n",
        "\n",
        "    ax2.set_ylim(0, 5)  # Set y-axis limit for ratings\n",
        "    ax2.legend(loc=\"upper right\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T04:35:09.238252Z",
          "iopub.status.busy": "2025-03-04T04:35:09.237925Z",
          "iopub.status.idle": "2025-03-04T04:35:09.784301Z",
          "shell.execute_reply": "2025-03-04T04:35:09.783723Z",
          "shell.execute_reply.started": "2025-03-04T04:35:09.238232Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "bEI4LeT6P7w_"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Ensure 'month' column is in datetime format\n",
        "df[\"month\"] = pd.to_datetime(df[\"month\"], errors=\"coerce\")\n",
        "\n",
        "# Convert to year for yearly aggregation\n",
        "df[\"year\"] = df[\"month\"].dt.year\n",
        "\n",
        "# Group by year and store\n",
        "trend_data = df.groupby([\"year\", \"name\"]).agg({\n",
        "    \"sentiment\": lambda x: (x == \"positive\").sum() / len(x),  # % of positive reviews\n",
        "    \"business_stars\": \"mean\"  # Average rating per year\n",
        "}).reset_index()\n",
        "\n",
        "# Apply rolling average (2-year window) for smoothing\n",
        "trend_data[\"sentiment_smooth\"] = trend_data.groupby(\"name\")[\"sentiment\"].transform(lambda x: x.rolling(2, min_periods=1).mean())\n",
        "trend_data[\"business_stars_smooth\"] = trend_data.groupby(\"name\")[\"business_stars\"].transform(lambda x: x.rolling(2, min_periods=1).mean())\n",
        "\n",
        "# Plot smoothed sentiment trends (Yearly)\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.lineplot(data=trend_data, x=\"year\", y=\"sentiment_smooth\", hue=\"name\", marker=\"o\", linewidth=2, palette=\"coolwarm\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel(\"Smoothed % of Positive Reviews\")\n",
        "plt.xlabel(\"Year\")\n",
        "plt.title(\"Smoothed Sentiment Trend Over Time Across Stores (2-Year Avg.)\")\n",
        "plt.legend(title=\"Store\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plot smoothed business stars trend (Yearly)\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.lineplot(data=trend_data, x=\"year\", y=\"business_stars_smooth\", hue=\"name\", marker=\"*\", linewidth=2)\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel(\"Smoothed Business Stars\")\n",
        "plt.xlabel(\"Year\")\n",
        "plt.title(\"Smoothed Business Stars Trend Over Time Across Stores (2-Year Avg.)\")\n",
        "plt.legend(title=\"Store\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T04:37:27.160561Z",
          "iopub.status.busy": "2025-03-04T04:37:27.160240Z",
          "iopub.status.idle": "2025-03-04T04:37:27.994712Z",
          "shell.execute_reply": "2025-03-04T04:37:27.994156Z",
          "shell.execute_reply.started": "2025-03-04T04:37:27.160540Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "38m9JA6sP7w_"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Select the category to analyze (e.g., \"Bakery\")\n",
        "selected_category = \"Bakery\"\n",
        "\n",
        "# Filter reviews related to this category\n",
        "category_trend_data = df[df[\"review_text\"].str.contains('|'.join(categories[selected_category]), case=False, na=False)]\n",
        "\n",
        "# Ensure 'month' column is in datetime format and extract the year\n",
        "category_trend_data[\"year\"] = pd.to_datetime(category_trend_data[\"month\"], errors=\"coerce\").dt.year\n",
        "\n",
        "# Group by year and store\n",
        "category_trend = category_trend_data.groupby([\"year\", \"name\"]).agg({\n",
        "    \"sentiment\": lambda x: (x == \"positive\").sum() / len(x),  # % of positive reviews\n",
        "    \"business_stars\": \"mean\"  # Average rating per year\n",
        "}).reset_index()\n",
        "\n",
        "# Apply rolling average (2-year window) for smoothing\n",
        "category_trend[\"sentiment_smooth\"] = category_trend.groupby(\"name\")[\"sentiment\"].transform(lambda x: x.rolling(2, min_periods=1).mean())\n",
        "category_trend[\"business_stars_smooth\"] = category_trend.groupby(\"name\")[\"business_stars\"].transform(lambda x: x.rolling(2, min_periods=1).mean())\n",
        "\n",
        "# Plot smoothed sentiment trends (Yearly)\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.lineplot(data=category_trend, x=\"year\", y=\"sentiment_smooth\", hue=\"name\", marker=\"o\", linewidth=2, palette=\"coolwarm\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel(f\"Smoothed % of Positive Reviews for {selected_category}\")\n",
        "plt.xlabel(\"Year\")\n",
        "plt.title(f\"Sentiment Trend Over Time for '{selected_category}' (2-Year Avg.)\")\n",
        "plt.legend(title=\"Store\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plot smoothed business stars trend (Yearly)\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.lineplot(data=category_trend, x=\"year\", y=\"business_stars_smooth\", hue=\"name\", marker=\"*\", linewidth=2)\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel(f\"Smoothed Business Stars for {selected_category}\")\n",
        "plt.xlabel(\"Year\")\n",
        "plt.title(f\"Business Stars Trend Over Time for '{selected_category}' (2-Year Avg.)\")\n",
        "plt.legend(title=\"Store\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T04:02:24.856540Z",
          "iopub.status.busy": "2025-03-04T04:02:24.856217Z",
          "iopub.status.idle": "2025-03-04T04:02:26.600755Z",
          "shell.execute_reply": "2025-03-04T04:02:26.600157Z",
          "shell.execute_reply.started": "2025-03-04T04:02:24.856521Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "fUZkfzUrP7xA"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Select the store to analyze\n",
        "selected_store = \"Fry's\"  # Change to other stores as needed\n",
        "\n",
        "# Create a dataframe for category comparison\n",
        "category_sentiment_data = []\n",
        "\n",
        "# Loop through categories and calculate sentiment distribution\n",
        "for category, keywords in categories.items():\n",
        "    # Filter dataset for the selected category within the selected store\n",
        "    category_data = df[\n",
        "        (df[\"name\"] == selected_store) &\n",
        "        (df[\"review_text\"].str.contains('|'.join(keywords), case=False, na=False))\n",
        "    ]\n",
        "\n",
        "    # Count positive and negative reviews\n",
        "    positive_count = (category_data[\"sentiment\"] == \"positive\").sum()\n",
        "    negative_count = (category_data[\"sentiment\"] == \"negative\").sum()\n",
        "\n",
        "    # Store results\n",
        "    category_sentiment_data.append({\n",
        "        \"Category\": category,\n",
        "        \"Positive Reviews\": positive_count,\n",
        "        \"Negative Reviews\": negative_count\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame\n",
        "category_sentiment_df = pd.DataFrame(category_sentiment_data)\n",
        "\n",
        "# Plot stacked bar chart for sentiment distribution across categories\n",
        "plt.figure(figsize=(10, 6))\n",
        "category_sentiment_df.set_index(\"Category\").plot(kind=\"bar\", stacked=True, colormap=\"coolwarm\", figsize=(10, 6))\n",
        "plt.title(f\"Sentiment Comparison Across Categories - {selected_store}\")\n",
        "plt.xlabel(\"Category\")\n",
        "plt.ylabel(\"Number of Reviews\")\n",
        "plt.legend([\"Negative\", \"Positive\"])\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-03-04T04:39:46.973944Z",
          "iopub.status.busy": "2025-03-04T04:39:46.973624Z",
          "iopub.status.idle": "2025-03-04T04:39:48.831582Z",
          "shell.execute_reply": "2025-03-04T04:39:48.831041Z",
          "shell.execute_reply.started": "2025-03-04T04:39:46.973924Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "x7w4t-4PP7xA"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Select store to analyze\n",
        "selected_store = \"Fry's\"\n",
        "\n",
        "# Create an empty dataframe for category trends\n",
        "category_trend_data = pd.DataFrame()\n",
        "\n",
        "# Ensure 'month' column is in datetime format and extract the year\n",
        "df[\"year\"] = pd.to_datetime(df[\"month\"], errors=\"coerce\").dt.year\n",
        "\n",
        "# Loop through categories to calculate sentiment trends over time\n",
        "for category, keywords in categories.items():\n",
        "    # Filter dataset for the selected store and category\n",
        "    category_df = df[\n",
        "        (df[\"name\"] == selected_store) &\n",
        "        (df[\"review_text\"].str.contains('|'.join(keywords), case=False, na=False))\n",
        "    ]\n",
        "\n",
        "    # Aggregate sentiment over time by year\n",
        "    category_trend = category_df.groupby(category_df[\"year\"]).agg({\n",
        "        \"sentiment\": lambda x: (x == \"positive\").sum() / len(x) if len(x) > 0 else None  # % positive reviews\n",
        "    }).reset_index()\n",
        "\n",
        "    # Add category column\n",
        "    category_trend[\"Category\"] = category\n",
        "\n",
        "    # Append to main dataframe\n",
        "    category_trend_data = pd.concat([category_trend_data, category_trend])\n",
        "\n",
        "# Apply rolling average (2-year smoothing)\n",
        "category_trend_data[\"sentiment_smooth\"] = category_trend_data.groupby(\"Category\")[\"sentiment\"].transform(lambda x: x.rolling(2, min_periods=1).mean())\n",
        "\n",
        "# Plot sentiment trend for different categories (Yearly)\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.lineplot(data=category_trend_data, x=\"year\", y=\"sentiment_smooth\", hue=\"Category\", marker=\"o\", linewidth=2, palette=\"tab10\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel(\"Smoothed % of Positive Reviews\")\n",
        "plt.xlabel(\"Year\")\n",
        "plt.title(f\"Sentiment Trends Across Categories - {selected_store} (2-Year Avg.)\")\n",
        "plt.legend(title=\"Category\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "hXaie6CdP7xA"
      },
      "source": [
        "---\n",
        "# Conclusion\n",
        "This project aimed to analyze Yelp reviews of grocery stores (Target, Fry’s, Safeway, Trader Joe’s) to extract actionable insights on customer satisfaction and business performance. By leveraging natural language processing (NLP), sentiment analysis, and machine learning models, the study explored customer perceptions through textual reviews and rating distributions.\n",
        "\n",
        "The analysis involved several key steps:\n",
        "1. *Data Preprocessing & Cleaning*  \n",
        "   - Addressed missing values, removed duplicates, and corrected data types such as review dates and geographical information.  \n",
        "   - Processed review text using tokenization, stopword removal, and lemmatization for improved analysis.  \n",
        "\n",
        "2. *Exploratory Data Analysis (EDA)*  \n",
        "   - Visualized rating distributions and customer experiences across stores.  \n",
        "   - Analyzed review length, review count per user, and useful votes to assess customer engagement.  \n",
        "\n",
        "3. *Sentiment Analysis*  \n",
        "   - Classified reviews as Positive, Negative, or Neutral using Vader and machine learning models.  \n",
        "   - Examined sentiment trends over time to identify fluctuations in customer satisfaction.  \n",
        "\n",
        "4. *Machine Learning Classification*  \n",
        "   - Built and evaluated models (Logistic Regression, SVM, Naïve Bayes, and Vader) for sentiment classification.  \n",
        "   - SVM demonstrated the highest classification accuracy and F1-score.  \n",
        "\n",
        "5. *Interpretation & Business Impact*  \n",
        "   - Identified sentiment trends, store-specific performance, and key factors influencing satisfaction.  \n",
        "   - Suggested improvements in customer service, product offerings, and business operations based on sentiment insights.  \n",
        "\n",
        "---\n",
        "\n",
        "# Key Insights from the Analysis\n",
        "\n",
        "## Sentiment Trends & Customer Satisfaction  \n",
        "- Customer sentiment fluctuates over time, with positive sentiment peaking at certain periods and declining at others.  \n",
        "- Trader Joe’s has the highest positive sentiment, while Safeway and Fry’s show a more polarized distribution with significant 1-star and 5-star reviews.  \n",
        "- The sentiment distribution follows a slightly positive skew, indicating that most customers have neutral to positive experiences, but negative reviews highlight areas for improvement.  \n",
        "\n",
        "## Review Length & Engagement  \n",
        "- The majority of reviews are short, with fewer than 50 words, suggesting that most customers leave brief feedback.  \n",
        "- Some longer reviews exceeding 100 words provide detailed experiences, but they are relatively rare.  \n",
        "- Useful votes are generally low, indicating that reviews are not highly engaged with or upvoted by other customers.  \n",
        "\n",
        "## Store-Specific Insights  \n",
        "\n",
        "| Store        | Sentiment Analysis | Customer Engagement | Review Highlights |\n",
        "|-------------|-------------------|--------------------|------------------|\n",
        "| *Trader Joe’s* | Highest positive sentiment (4-5 star reviews dominant) | Higher engagement, more useful votes | Customers highlight customer service, product quality, and store environment. |\n",
        "| *Target* | Balanced sentiment, occasional negative spikes | Medium engagement, some useful votes | Customers mention store layout and stock availability issues. |\n",
        "| *Safeway* | High 1-star and 4-star reviews (polarized) | Lower engagement, few useful votes | Complaints about pricing and checkout experiences. |\n",
        "| *Fry’s* | Mixed sentiment (1-star and 5-star peaks) | Low engagement, lowest useful votes | Complaints about customer service, pricing, and product availability. |\n",
        "\n",
        "## Machine Learning Model Performance  \n",
        "\n",
        "| Metric  | Vader  | Logistic Regression | SVM  | Naïve Bayes  |\n",
        "|---------|--------|--------------------|------|-------------|\n",
        "| *Accuracy* | 87.06% | 95.25% | *98.38%* | 87.93% |\n",
        "| *Precision (Positive Sentiment)* | 94.49% | 95.89% | *98.48%* | 96.10% |\n",
        "| *Recall (Positive Sentiment)* | 89.76% | 98.61% | *99.85%* | 89.15% |\n",
        "| *F1-Score (Positive Sentiment)* | 92.07% | 97.23% | *99.16%* | 92.49% |\n",
        "\n",
        "- SVM achieved the best overall performance, followed by Logistic Regression.  \n",
        "- Naïve Bayes and Vader underperformed, likely due to their simplistic assumptions about text distribution.  \n",
        "- Deep learning techniques such as LSTMs and Transformers could further improve sentiment classification accuracy.  \n",
        "\n",
        "---\n",
        "\n",
        "# Recommendations for Business Improvements\n",
        "\n",
        "## Address Negative Reviews & Improve Customer Experience  \n",
        "- Safeway and Fry’s should analyze common issues in 1-star reviews to identify recurring problems in pricing, checkout experience, and customer service.  \n",
        "- Implement real-time feedback systems to address customer concerns immediately.  \n",
        "- Trader Joe’s should maintain its high service quality while identifying areas for minor improvements.  \n",
        "\n",
        "## Enhance Review Engagement & Encourage Detailed Feedback  \n",
        "- Most reviews are short and not very detailed. Stores should incentivize customers to write longer, more informative reviews, such as offering small discounts for detailed feedback.  \n",
        "- Introduce \"Most Helpful Review\" sections to highlight valuable reviews and encourage users to vote for useful ones.  \n",
        "\n",
        "## Improve Sentiment Classification Accuracy  \n",
        "- Implement more advanced deep learning models such as BERT, GPT, and LSTMs to improve sentiment classification.  \n",
        "- Utilize topic modeling (LDA) to understand common themes in negative and positive reviews.  \n",
        "\n",
        "## Leverage Sentiment Trends for Business Strategy  \n",
        "- Track seasonal sentiment fluctuations to align marketing campaigns and promotions with customer expectations.  \n",
        "- Analyze spikes in negative sentiment to proactively address issues before they escalate.  \n",
        "\n",
        "## Store-Specific Actionable Insights  \n",
        "\n",
        "| Store | Actionable Recommendations |\n",
        "|--------|-------------------------|\n",
        "| *Trader Joe’s* | Maintain high-quality service and product variety while enhancing store convenience. |\n",
        "| *Target* | Improve stock availability, customer flow, and checkout speed to reduce customer frustration. |\n",
        "| *Safeway* | Address pricing complaints and optimize self-checkout systems for a smoother experience. |\n",
        "| *Fry’s* | Enhance customer service training, improve inventory consistency, and offer better pricing transparency. |\n",
        "\n",
        "---\n",
        "\n",
        "# Final Thoughts  \n",
        "This project successfully extracted valuable insights from customer reviews using machine learning, sentiment analysis, and NLP techniques. The analysis provided data-driven recommendations to improve grocery store experiences and highlighted the best-performing ML models for sentiment classification.\n",
        "\n",
        "## Key Takeaways  \n",
        "- SVM is the best sentiment classification model, achieving the highest accuracy and F1-score.  \n",
        "- Trader Joe’s leads in positive sentiment, while Fry’s and Safeway face inconsistent reviews.  \n",
        "- Short reviews dominate, and engagement with reviews is low, meaning stores should encourage more detailed feedback.  \n",
        "- Stores can use sentiment analysis trends to predict customer satisfaction and optimize their operations.  \n",
        "\n",
        "By implementing these recommendations, grocery stores can enhance customer satisfaction, improve business operations, and increase customer retention using data-driven decision-making.  \n",
        "\n",
        "## Next Steps  \n",
        "1. Deploy ML models into a real-time review monitoring system.  \n",
        "2. Expand the dataset to include more grocery stores and locations for broader insights.  \n",
        "3. Apply deep learning techniques to further enhance sentiment classification accuracy.  \n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}